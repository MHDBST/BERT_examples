{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyBert_document_TPU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MHDBST/BERT_examples/blob/master/MyBert_document_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN2obM4ocF_p",
        "colab_type": "code",
        "outputId": "4d618a78-f9f6-49c3-a5e6-b7f8a288aeff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "!pip install bert-tensorflow\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python2.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "('TPU address is', 'grpc://10.88.90.82:8470')\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 17678923446312692754),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14210206664694484166),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 452904397831288903),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 11348960205687008368),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6243088658886492502),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 9713071699269903529),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 5930330639922856949),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 826992274161466135),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 16851061742547753784),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16319281005985954650),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 7466763508169249785)]\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYYgxPTVc5u7",
        "colab_type": "code",
        "outputId": "e65f0eba-288f-4ffc-a57b-0af1ffe744cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "import sys\n",
        "\n",
        "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "  sys.path += ['bert_repo']\n",
        "\n",
        "# import python modules defined by BERT\n",
        "from bert import modeling\n",
        "# import optimization\n",
        "# import run_classifier\n",
        "from bert import run_classifier_with_tfhub\n",
        "# import tokenization\n",
        "\n",
        "# import tfhub \n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0516 14:47:29.752722 140083176642432 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yIQhrSUdE-H",
        "colab_type": "code",
        "outputId": "dcd90e01-6fc0-43c6-cf90-14ed10acd52d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "BUCKET = 'bert_example' #@param {type:\"string\"}\n",
        "TASK = 'MASKED_DOCUMENT'\n",
        "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
        "OUTPUT_DIR = 'gs://{}/bert-tfhub/models/{}/trainable/layerwise/all_layers/deleteME/smallBERT-docLevel-seq512'.format(BUCKET,TASK)\n",
        "# OUTPUT_DIR = 'gs://{}/bert-tfhub/models/nontrainable/smallBERT-docLevel-seq512'.format(BUCKET)\n",
        "\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "# Available pretrained model checkpoints:\n",
        "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
        "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
        "#   cased_L-12_H-768_A-12: cased BERT large model\n",
        "BERT_MODEL = 'uncased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
        "BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: gs://bert_example/bert-tfhub/models/MASKED_DOCUMENT/trainable/layerwise/all_layers/deleteME/smallBERT-docLevel-seq512 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VLhRyWYdPN-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "0cb73514-5ee2-4a7a-ff4f-5d14be47ee2d"
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization\n",
        "\n",
        "# BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\" ##Small Bert\n",
        "# BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-24_H-1024_A-16/1\" ##Big Bert\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0516 14:47:32.093066 140083176642432 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:34.522897 140083176642432 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eLjuUqLdR_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BATCH_SIZE = 32\n",
        "EVAL_BATCH_SIZE = 8\n",
        "PREDICT_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 15.0  ## Activate if ** is ACTIVATED\n",
        "MAX_SEQ_LENGTH = 512\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 200\n",
        "SAVE_SUMMARY_STEPS = 100\n",
        "trainable=True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yAPypEOdgpq",
        "colab_type": "code",
        "outputId": "01ac121c-c25f-4f99-88e2-80f4b553d841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# data_train = pd.read_csv('/content/alldata_3Dec_7Dec_PS_reindex_train_v3.csv', encoding='latin-1')\n",
        "# data_dev = pd.read_csv('/content/alldata_3Dec_7Dec_PS_reindex_dev_v3.csv', encoding='latin-1')\n",
        "# data_test = pd.read_csv('/content/alldata_3Dec_7Dec_PS_reindex_random_test_v3.csv', encoding='latin-1')\n",
        "# data_test_fixed = pd.read_csv('/content/alldata_3Dec_7Dec_PS_reindex_fixed_test_v3.csv', encoding='latin-1')\n",
        "\n",
        "data_train = pd.read_csv('/content/alldata_3Dec_7Dec_PS_reindex_enclosed_masked_train_v3.csv', encoding='latin-1')\n",
        "data_dev = pd.read_csv('/content/alldata_3Dec_7Dec_PS_reindex_enclosed_masked_dev_v3.csv', encoding='latin-1')\n",
        "data_test = pd.read_csv('/content/alldata_3Dec_7Dec_PS_reindex_enclosed_masked_random_test_v3.csv', encoding='latin-1')\n",
        "data_test_fixed = pd.read_csv('/content/alldata_3Dec_7Dec_PS_reindex_enclosed_masked_fixed_test_v3.csv', encoding='latin-1')\n",
        "# data_summary = pd.read_csv('/content/dev_summary.csv', encoding='latin-1')\n",
        "\n",
        "# data_train = pd.read_csv('/content/train_v5.csv', encoding='latin-1')\n",
        "# data_dev = pd.read_csv('/content/dev_v5.csv', encoding='latin-1')\n",
        "# data_test = pd.read_csv('/content/random_test_v5.csv', encoding='latin-1')\n",
        "# data_test_fixed = pd.read_csv('/content/fixed_test_v5.csv', encoding='latin-1')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Load all files from a directory in a DataFrame.\n",
        "def load_directory_data(df,sentence_column):\n",
        "  data = {}\n",
        "  data[\"sentence\"] = df[TASK] ## could be DOCUMENT, ENCLOSED_DOCUMENT, MASKED_DOCUMENT\n",
        "#   data[\"sentence\"] = df[sentence_column]\n",
        "  data[\"sentiment\"] =df[\"TRUE_SENTIMENT\"]\n",
        "#   data['document'] = df['DOCUMENT']\n",
        "  return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(df,sentence_column='DOCUMENT',index = None):\n",
        "  df_new = load_directory_data(df[:index],sentence_column)\n",
        "  pos_df = df_new[df_new['sentiment'] == 'Positive']\n",
        "  neg_df = df_new[df_new['sentiment'] == 'Negative']\n",
        "  neu_df = df_new[df_new['sentiment'] == 'Neutral']\n",
        "  pos_df[\"polarity\"] = 1\n",
        "  neg_df[\"polarity\"] = -1\n",
        "  neu_df[\"polarity\"] = 0\n",
        "  return pd.concat([pos_df, neg_df,neu_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "train = load_dataset(data_train)\n",
        "test = load_dataset(data_test)\n",
        "dev = load_dataset(data_dev)#,sentence_column='DOCUMENT')\n",
        "test_fixed = load_dataset(data_test_fixed)\n",
        "# dev_summary = load_dataset(data_summary,sentence_column='summary')\n",
        "print(train[:5])\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                            sentence sentiment  polarity\n",
            "0  James Damore   an ex-Google employee who wrote...  Positive         1\n",
            "1  Comedian Louis C .  K  . is being accused of s...  Negative        -1\n",
            "2  âStaff are working at a pace that is unheard...   Neutral         0\n",
            "3  [TGT] said [TGT] was installing a fence on the...   Neutral         0\n",
            "4  Hong Hai Group Chairman Terry Gou said Tuesday...  Positive         1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fMNSsUHdsbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_COLUMN = 'sentence'\n",
        "LABEL_COLUMN = 'polarity'\n",
        "label_list = [-1, 0, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HjkshmOdyI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "dev_InputExamples = dev.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "\n",
        "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "test_InputExamples_fixed = test_fixed.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "# dev_summary_InputExamples_fixed = dev_summary.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "#                                                                    text_a = x[DATA_COLUMN], \n",
        "#                                                                    text_b = None, \n",
        "#                                                                    label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "\n",
        "\n",
        "## These two lines should be activated if ** is not activated\n",
        "num_train_steps = int(len(train_InputExamples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "# Setup TPU related config\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "NUM_TPU_CORES = 8\n",
        "# ITERATIONS_PER_LOOP = 1000 # I don't know what it is doing just decrease it to smaller value\n",
        "ITERATIONS_PER_LOOP = int(len(train_InputExamples) / TRAIN_BATCH_SIZE) ## set as the number of iterations in each epoch \n",
        "\n",
        "def get_run_config(output_dir):\n",
        "  return tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=output_dir,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2YQqQZjJj3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import modeling\n",
        "# import run_classifier\n",
        "import tokenization\n",
        "\n",
        "# coding=utf-8\n",
        "# Copyright 2018 The Google AI Language Team Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"Functions and classes related to optimization (weight updates).\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import re\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def create_optimizer(loss, init_lr, num_train_steps, num_warmup_steps, use_tpu):\n",
        "  \"\"\"Creates an optimizer training op.\"\"\"\n",
        "  global_step = tf.train.get_or_create_global_step()\n",
        "\n",
        "  learning_rate = tf.constant(value=init_lr, shape=[], dtype=tf.float32)\n",
        "\n",
        "  # Implements linear decay of the learning rate.\n",
        "  learning_rate = tf.train.polynomial_decay(\n",
        "      learning_rate,\n",
        "      global_step,\n",
        "      num_train_steps,\n",
        "      end_learning_rate=0.0,\n",
        "      power=1.0,\n",
        "      cycle=False)\n",
        "\n",
        "  # Implements linear warmup. I.e., if global_step < num_warmup_steps, the\n",
        "  # learning rate will be `global_step/num_warmup_steps * init_lr`.\n",
        "  if num_warmup_steps:\n",
        "    global_steps_int = tf.cast(global_step, tf.int32)\n",
        "    warmup_steps_int = tf.constant(num_warmup_steps, dtype=tf.int32)\n",
        "\n",
        "    global_steps_float = tf.cast(global_steps_int, tf.float32)\n",
        "    warmup_steps_float = tf.cast(warmup_steps_int, tf.float32)\n",
        "\n",
        "    warmup_percent_done = global_steps_float / warmup_steps_float\n",
        "    warmup_learning_rate = init_lr * warmup_percent_done\n",
        "\n",
        "    is_warmup = tf.cast(global_steps_int < warmup_steps_int, tf.float32)\n",
        "    learning_rate = (\n",
        "        (1.0 - is_warmup) * learning_rate + is_warmup * warmup_learning_rate)\n",
        "\n",
        "  # It is recommended that you use this optimizer for fine tuning, since this\n",
        "  # is how the model was trained (note that the Adam m/v variables are NOT\n",
        "  # loaded from init_checkpoint.)\n",
        "  optimizer = AdamWeightDecayOptimizer(\n",
        "      learning_rate=learning_rate,\n",
        "      weight_decay_rate=0.01,\n",
        "      beta_1=0.9,\n",
        "      beta_2=0.999,\n",
        "      epsilon=1e-6,\n",
        "      exclude_from_weight_decay=[\"LayerNorm\", \"layer_norm\", \"bias\"])\n",
        "\n",
        "  if use_tpu:\n",
        "    optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n",
        "\n",
        "  pre_tvars = tf.trainable_variables()\n",
        "#   print('all trainable variables: >>',pre_tvars)\n",
        "#   tvars = pre_tvars\n",
        "  tvars = [item for item in pre_tvars]\n",
        "#   if not '/layer_0/'  in item.name and\n",
        "#            not '/layer_1/'  in item.name and not '/layer_2/'  in item.name\n",
        "#           and not '/layer_3/'  in item.name and not '/layer_4/'  in item.name and\n",
        "#            not '/layer_5/'  in item.name and not '/layer_6/'  in item.name \n",
        "#           and not '/layer_7/'  in item.name and not '/layer_8/'  in item.name and \n",
        "#            not '/layer_9/'  in item.name ]\n",
        "  print('excluded trainable variables: >>',tvars)\n",
        "  grads = tf.gradients(loss, tvars)\n",
        "\n",
        "  # This is how the model was pre-trained.\n",
        "  (grads, _) = tf.clip_by_global_norm(grads, clip_norm=1.0)\n",
        "\n",
        "  train_op = optimizer.apply_gradients(\n",
        "      zip(grads, tvars), global_step=global_step)\n",
        "\n",
        "  # Normally the global step update is done inside of `apply_gradients`.\n",
        "  # However, `AdamWeightDecayOptimizer` doesn't do this. But if you use\n",
        "  # a different optimizer, you should probably take this line out.\n",
        "  new_global_step = global_step + 1\n",
        "  train_op = tf.group(train_op, [global_step.assign(new_global_step)])\n",
        "  return train_op\n",
        "\n",
        "\n",
        "class AdamWeightDecayOptimizer(tf.train.Optimizer):\n",
        "  \"\"\"A basic Adam optimizer that includes \"correct\" L2 weight decay.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               learning_rate,\n",
        "               weight_decay_rate=0.0,\n",
        "               beta_1=0.9,\n",
        "               beta_2=0.999,\n",
        "               epsilon=1e-6,\n",
        "               exclude_from_weight_decay=None,\n",
        "               name=\"AdamWeightDecayOptimizer\"):\n",
        "    \"\"\"Constructs a AdamWeightDecayOptimizer.\"\"\"\n",
        "    super(AdamWeightDecayOptimizer, self).__init__(False, name)\n",
        "\n",
        "    self.learning_rate = learning_rate\n",
        "    self.weight_decay_rate = weight_decay_rate\n",
        "    self.beta_1 = beta_1\n",
        "    self.beta_2 = beta_2\n",
        "    self.epsilon = epsilon\n",
        "    self.exclude_from_weight_decay = exclude_from_weight_decay\n",
        "\n",
        "  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    assignments = []\n",
        "    for (grad, param) in grads_and_vars:\n",
        "      if grad is None or param is None:\n",
        "        continue\n",
        "\n",
        "      param_name = self._get_variable_name(param.name)\n",
        "\n",
        "      m = tf.get_variable(\n",
        "          name=param_name + \"/adam_m\",\n",
        "          shape=param.shape.as_list(),\n",
        "          dtype=tf.float32,\n",
        "          trainable=False,\n",
        "          initializer=tf.zeros_initializer())\n",
        "      v = tf.get_variable(\n",
        "          name=param_name + \"/adam_v\",\n",
        "          shape=param.shape.as_list(),\n",
        "          dtype=tf.float32,\n",
        "          trainable=False,\n",
        "          initializer=tf.zeros_initializer())\n",
        "\n",
        "      # Standard Adam update.\n",
        "      next_m = (\n",
        "          tf.multiply(self.beta_1, m) + tf.multiply(1.0 - self.beta_1, grad))\n",
        "      next_v = (\n",
        "          tf.multiply(self.beta_2, v) + tf.multiply(1.0 - self.beta_2,\n",
        "                                                    tf.square(grad)))\n",
        "\n",
        "      update = next_m / (tf.sqrt(next_v) + self.epsilon)\n",
        "\n",
        "      # Just adding the square of the weights to the loss function is *not*\n",
        "      # the correct way of using L2 regularization/weight decay with Adam,\n",
        "      # since that will interact with the m and v parameters in strange ways.\n",
        "      #\n",
        "      # Instead we want ot decay the weights in a manner that doesn't interact\n",
        "      # with the m/v parameters. This is equivalent to adding the square\n",
        "      # of the weights to the loss with plain (non-momentum) SGD.\n",
        "      if self._do_use_weight_decay(param_name):\n",
        "        update += self.weight_decay_rate * param\n",
        "\n",
        "      update_with_lr = self.learning_rate * update\n",
        "\n",
        "      next_param = param - update_with_lr\n",
        "\n",
        "      assignments.extend(\n",
        "          [param.assign(next_param),\n",
        "           m.assign(next_m),\n",
        "           v.assign(next_v)])\n",
        "    return tf.group(*assignments, name=name)\n",
        "\n",
        "  def _do_use_weight_decay(self, param_name):\n",
        "    \"\"\"Whether to use L2 weight decay for `param_name`.\"\"\"\n",
        "    if not self.weight_decay_rate:\n",
        "      return False\n",
        "    if self.exclude_from_weight_decay:\n",
        "      for r in self.exclude_from_weight_decay:\n",
        "        if re.search(r, param_name) is not None:\n",
        "          return False\n",
        "    return True\n",
        "\n",
        "  def _get_variable_name(self, param_name):\n",
        "    \"\"\"Get the variable name from the tensor name.\"\"\"\n",
        "    m = re.match(\"^(.*):\\\\d+$\", param_name)\n",
        "    if m is not None:\n",
        "      param_name = m.group(1)\n",
        "    return param_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WEcWYt6jjaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weight_loss = \n",
        "# neg_w = 1./len(dev_par[dev_par['label']==0])\n",
        "# pos_w = 1./len(dev_par[dev_par['label']==1])\n",
        "# class_weights_arr = [neg_w/(neg_w+pos_w),pos_w/(neg_w+pos_w)]\n",
        "def create_model(is_training, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels, bert_hub_module_handle):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "  tags = set()\n",
        "  if is_training:\n",
        "    tags.add(\"train\")\n",
        "  bert_module = hub.Module(bert_hub_module_handle, tags=tags, trainable=trainable)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # In the demo, we are doing a simple classification task on the entire\n",
        "  # segment.\n",
        "  #\n",
        "  # If you want to use the token-level output, use\n",
        "  # bert_outputs[\"sequence_output\"] instead.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "    if is_training:\n",
        "      # I.e., 0.1 dropout\n",
        "      output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)# * weight_loss)\n",
        "\n",
        "    return (loss, per_example_loss, logits, probabilities)\n",
        "\n",
        "\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps, use_tpu, bert_hub_module_handle):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    tf.logging.info(\"*** Features ***\")\n",
        "    for name in sorted(features.keys()):\n",
        "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    (total_loss, per_example_loss, logits, probabilities) = create_model(\n",
        "        is_training, input_ids, input_mask, segment_ids, label_ids, num_labels,\n",
        "        bert_hub_module_handle)\n",
        "\n",
        "    output_spec = None\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      train_op =create_optimizer(\n",
        "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          train_op=train_op)\n",
        "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "\n",
        "      def metric_fn(per_example_loss, label_ids, logits):\n",
        "        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predictions)\n",
        "        loss = tf.metrics.mean(per_example_loss)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"eval_loss\": loss,\n",
        "        }\n",
        "\n",
        "      eval_metrics = (metric_fn, [per_example_loss, label_ids, logits])\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          eval_metrics=eval_metrics)\n",
        "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode, predictions={\"probabilities\": probabilities})\n",
        "    else:\n",
        "      raise ValueError(\n",
        "          \"Only TRAIN, EVAL and PREDICT modes are supported: %s\" % (mode))\n",
        "\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROg74SGti91n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "10c1136f-d65c-4406-d41e-6ee7b20ebe58"
      },
      "source": [
        "# Force TF Hub writes to the GS bucket we provide.\n",
        "os.environ['TFHUB_CACHE_DIR'] = OUTPUT_DIR\n",
        "### Activate it if ** part is not activated \n",
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps,\n",
        "  use_tpu=True,\n",
        "  bert_hub_module_handle=BERT_MODEL_HUB\n",
        ")\n",
        "\n",
        "estimator_from_tfhub = tf.contrib.tpu.TPUEstimator(\n",
        "  use_tpu=True,\n",
        "  model_fn=model_fn,\n",
        "  config=get_run_config(OUTPUT_DIR),\n",
        "  train_batch_size=TRAIN_BATCH_SIZE,\n",
        "  eval_batch_size=EVAL_BATCH_SIZE,\n",
        "  predict_batch_size=PREDICT_BATCH_SIZE,\n",
        ")\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7f676a2e3050>) includes params argument, but params are not passed to Estimator.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0516 14:47:37.979712 140083176642432 estimator.py:1924] Estimator's model_fn (<function model_fn at 0x7f676a2e3050>) includes params argument, but params are not passed to Estimator.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.88.90.82:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f67688cf150>, '_model_dir': 'gs://bert_example/bert-tfhub/models/MASKED_DOCUMENT/trainable/layerwise/all_layers/deleteME/smallBERT-docLevel-seq512', '_protocol': None, '_save_checkpoints_steps': 200, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tpu_config': TPUConfig(iterations_per_loop=46, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f6766a96190>, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': None, '_evaluation_master': 'grpc://10.88.90.82:8470', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': 'grpc://10.88.90.82:8470'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:37.983692 140083176642432 estimator.py:201] Using config: {'_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.88.90.82:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f67688cf150>, '_model_dir': 'gs://bert_example/bert-tfhub/models/MASKED_DOCUMENT/trainable/layerwise/all_layers/deleteME/smallBERT-docLevel-seq512', '_protocol': None, '_save_checkpoints_steps': 200, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tpu_config': TPUConfig(iterations_per_loop=46, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f6766a96190>, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': None, '_evaluation_master': 'grpc://10.88.90.82:8470', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': 'grpc://10.88.90.82:8470'}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:37.986439 140083176642432 tpu_context.py:202] _TPUContext: eval_on_tpu True\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl-M_8L7sL40",
        "colab_type": "code",
        "outputId": "5d66eb7b-34e7-4baf-8213-793fdcf32dee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4933
        }
      },
      "source": [
        "train_features = run_classifier.convert_examples_to_features(\n",
        "      train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "eval_features = run_classifier.convert_examples_to_features(\n",
        "      dev_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = run_classifier.convert_examples_to_features(\n",
        "      test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n",
        "test_features_fixed = run_classifier.convert_examples_to_features(\n",
        "      test_InputExamples_fixed, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 1501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.001710 140083176642432 run_classifier.py:774] Writing example 0 of 1501\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.036850 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.039545 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] james dam ##ore an ex - google employee who wrote a controversial memo arguing the merits of gender and diversity programs was interviewed by two youtube ##rs . ( j ##ha ##an elk ##er / the washington post ) a week ago [ t ##gt ] worked at google . now [ t ##gt ] as sitting for portraits with peter duke the photographer the new york times dubbed at ##he annie lei ##bo ##vi ##tz of the alt - right . a in one photograph a the user image for an un ##ver ##ified twitter account believed to be his a [ t ##gt ] sits in front of a blue background holding a laptop . he ##as wearing a t - shirt that has one word printed on the chest in google ##as font . it reads : ago ##ola ##g . a the memo went viral at google and then became news when its existence was leaked to mother ##board . [ t ##gt ] was fired for ape ##rp ##et ##uating gender stereotypes . a but [ t ##gt ] quickly became a hero on the right - wing internet where a coalition of anti - politically - correct online personalities trump supporters and the alt - right believed that dam ##ore as firing was proof that silicon valley was hostile to conservatives a and that something was about to change . as his duke portraits show that is a role that dam ##ore has embraced . below is a look at how he got there . [ t ##gt ] did nothing wrong # google ##mani ##fest ##o a jack po ##so ##bie ##c ( @ jack ##po ##so ##bie ##c ) august 8 2017 each component of the [ t ##gt ] as story read like a fulfilled prophecy for the right - wing internet which has spent years accusing silicon valley companies of con ##sp ##iring to silence conservatives . many of the things [ t ##gt ] argued in that memo were more or less aligned with this viewpoint : for instance that ago ##og ##lea ##s left bias has created a politically correct mono ##culture that maintains [ t ##gt ] hold by sham ##ing dissent ##ers into silence a and later that awe have extensive government and google programs fields of study and legal and social norms to protect women but when a man complain ##s about a gender issue affecting men he ##as labeled as a mis ##ogy ##nist and a w ##hine ##r . a the left is at war with reality . [ t ##gt ] told the truth . for that [ t ##gt ] was witch hunted do ##xx ##ed & fired . # je ##su ##is ##ja ##mes ##dam ##ore a paul joseph watson ( @ prison ##plane ##t ) august 8 2017 [ t ##gt ] has previously said that [ t ##gt ] believes progressive ##s have a monopoly on every major silicon valley company and has built ga ##b as an [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.043097 140083176642432 run_classifier.py:464] tokens: [CLS] james dam ##ore an ex - google employee who wrote a controversial memo arguing the merits of gender and diversity programs was interviewed by two youtube ##rs . ( j ##ha ##an elk ##er / the washington post ) a week ago [ t ##gt ] worked at google . now [ t ##gt ] as sitting for portraits with peter duke the photographer the new york times dubbed at ##he annie lei ##bo ##vi ##tz of the alt - right . a in one photograph a the user image for an un ##ver ##ified twitter account believed to be his a [ t ##gt ] sits in front of a blue background holding a laptop . he ##as wearing a t - shirt that has one word printed on the chest in google ##as font . it reads : ago ##ola ##g . a the memo went viral at google and then became news when its existence was leaked to mother ##board . [ t ##gt ] was fired for ape ##rp ##et ##uating gender stereotypes . a but [ t ##gt ] quickly became a hero on the right - wing internet where a coalition of anti - politically - correct online personalities trump supporters and the alt - right believed that dam ##ore as firing was proof that silicon valley was hostile to conservatives a and that something was about to change . as his duke portraits show that is a role that dam ##ore has embraced . below is a look at how he got there . [ t ##gt ] did nothing wrong # google ##mani ##fest ##o a jack po ##so ##bie ##c ( @ jack ##po ##so ##bie ##c ) august 8 2017 each component of the [ t ##gt ] as story read like a fulfilled prophecy for the right - wing internet which has spent years accusing silicon valley companies of con ##sp ##iring to silence conservatives . many of the things [ t ##gt ] argued in that memo were more or less aligned with this viewpoint : for instance that ago ##og ##lea ##s left bias has created a politically correct mono ##culture that maintains [ t ##gt ] hold by sham ##ing dissent ##ers into silence a and later that awe have extensive government and google programs fields of study and legal and social norms to protect women but when a man complain ##s about a gender issue affecting men he ##as labeled as a mis ##ogy ##nist and a w ##hine ##r . a the left is at war with reality . [ t ##gt ] told the truth . for that [ t ##gt ] was witch hunted do ##xx ##ed & fired . # je ##su ##is ##ja ##mes ##dam ##ore a paul joseph watson ( @ prison ##plane ##t ) august 8 2017 [ t ##gt ] has previously said that [ t ##gt ] believes progressive ##s have a monopoly on every major silicon valley company and has built ga ##b as an [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2508 5477 5686 2019 4654 1011 8224 7904 2040 2626 1037 6801 24443 9177 1996 22617 1997 5907 1998 8906 3454 2001 10263 2011 2048 7858 2869 1012 1006 1046 3270 2319 18995 2121 1013 1996 2899 2695 1007 1037 2733 3283 1031 1056 13512 1033 2499 2012 8224 1012 2085 1031 1056 13512 1033 2004 3564 2005 9668 2007 2848 3804 1996 8088 1996 2047 2259 2335 9188 2012 5369 8194 26947 5092 5737 5753 1997 1996 12456 1011 2157 1012 1037 1999 2028 9982 1037 1996 5310 3746 2005 2019 4895 6299 7810 10474 4070 3373 2000 2022 2010 1037 1031 1056 13512 1033 7719 1999 2392 1997 1037 2630 4281 3173 1037 12191 1012 2002 3022 4147 1037 1056 1011 3797 2008 2038 2028 2773 6267 2006 1996 3108 1999 8224 3022 15489 1012 2009 9631 1024 3283 6030 2290 1012 1037 1996 24443 2253 13434 2012 8224 1998 2059 2150 2739 2043 2049 4598 2001 15748 2000 2388 6277 1012 1031 1056 13512 1033 2001 5045 2005 23957 14536 3388 24133 5907 22807 1012 1037 2021 1031 1056 13512 1033 2855 2150 1037 5394 2006 1996 2157 1011 3358 4274 2073 1037 6056 1997 3424 1011 10317 1011 6149 3784 12857 8398 6793 1998 1996 12456 1011 2157 3373 2008 5477 5686 2004 7493 2001 6947 2008 13773 3028 2001 10420 2000 11992 1037 1998 2008 2242 2001 2055 2000 2689 1012 2004 2010 3804 9668 2265 2008 2003 1037 2535 2008 5477 5686 2038 14218 1012 2917 2003 1037 2298 2012 2129 2002 2288 2045 1012 1031 1056 13512 1033 2106 2498 3308 1001 8224 20799 14081 2080 1037 2990 13433 6499 11283 2278 1006 1030 2990 6873 6499 11283 2278 1007 2257 1022 2418 2169 6922 1997 1996 1031 1056 13512 1033 2004 2466 3191 2066 1037 16829 14951 2005 1996 2157 1011 3358 4274 2029 2038 2985 2086 16723 13773 3028 3316 1997 9530 13102 24771 2000 4223 11992 1012 2116 1997 1996 2477 1031 1056 13512 1033 5275 1999 2008 24443 2020 2062 2030 2625 13115 2007 2023 21386 1024 2005 6013 2008 3283 8649 19738 2015 2187 13827 2038 2580 1037 10317 6149 18847 14561 2008 9319 1031 1056 13512 1033 2907 2011 25850 2075 24116 2545 2046 4223 1037 1998 2101 2008 15180 2031 4866 2231 1998 8224 3454 4249 1997 2817 1998 3423 1998 2591 17606 2000 4047 2308 2021 2043 1037 2158 17612 2015 2055 1037 5907 3277 12473 2273 2002 3022 12599 2004 1037 28616 15707 26942 1998 1037 1059 14014 2099 1012 1037 1996 2187 2003 2012 2162 2007 4507 1012 1031 1056 13512 1033 2409 1996 3606 1012 2005 2008 1031 1056 13512 1033 2001 6965 14682 2079 20348 2098 1004 5045 1012 1001 15333 6342 2483 3900 7834 17130 5686 1037 2703 3312 7908 1006 1030 3827 11751 2102 1007 2257 1022 2418 1031 1056 13512 1033 2038 3130 2056 2008 1031 1056 13512 1033 7164 6555 2015 2031 1037 15404 2006 2296 2350 13773 3028 2194 1998 2038 2328 11721 2497 2004 2019 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.046367 140083176642432 run_classifier.py:465] input_ids: 101 2508 5477 5686 2019 4654 1011 8224 7904 2040 2626 1037 6801 24443 9177 1996 22617 1997 5907 1998 8906 3454 2001 10263 2011 2048 7858 2869 1012 1006 1046 3270 2319 18995 2121 1013 1996 2899 2695 1007 1037 2733 3283 1031 1056 13512 1033 2499 2012 8224 1012 2085 1031 1056 13512 1033 2004 3564 2005 9668 2007 2848 3804 1996 8088 1996 2047 2259 2335 9188 2012 5369 8194 26947 5092 5737 5753 1997 1996 12456 1011 2157 1012 1037 1999 2028 9982 1037 1996 5310 3746 2005 2019 4895 6299 7810 10474 4070 3373 2000 2022 2010 1037 1031 1056 13512 1033 7719 1999 2392 1997 1037 2630 4281 3173 1037 12191 1012 2002 3022 4147 1037 1056 1011 3797 2008 2038 2028 2773 6267 2006 1996 3108 1999 8224 3022 15489 1012 2009 9631 1024 3283 6030 2290 1012 1037 1996 24443 2253 13434 2012 8224 1998 2059 2150 2739 2043 2049 4598 2001 15748 2000 2388 6277 1012 1031 1056 13512 1033 2001 5045 2005 23957 14536 3388 24133 5907 22807 1012 1037 2021 1031 1056 13512 1033 2855 2150 1037 5394 2006 1996 2157 1011 3358 4274 2073 1037 6056 1997 3424 1011 10317 1011 6149 3784 12857 8398 6793 1998 1996 12456 1011 2157 3373 2008 5477 5686 2004 7493 2001 6947 2008 13773 3028 2001 10420 2000 11992 1037 1998 2008 2242 2001 2055 2000 2689 1012 2004 2010 3804 9668 2265 2008 2003 1037 2535 2008 5477 5686 2038 14218 1012 2917 2003 1037 2298 2012 2129 2002 2288 2045 1012 1031 1056 13512 1033 2106 2498 3308 1001 8224 20799 14081 2080 1037 2990 13433 6499 11283 2278 1006 1030 2990 6873 6499 11283 2278 1007 2257 1022 2418 2169 6922 1997 1996 1031 1056 13512 1033 2004 2466 3191 2066 1037 16829 14951 2005 1996 2157 1011 3358 4274 2029 2038 2985 2086 16723 13773 3028 3316 1997 9530 13102 24771 2000 4223 11992 1012 2116 1997 1996 2477 1031 1056 13512 1033 5275 1999 2008 24443 2020 2062 2030 2625 13115 2007 2023 21386 1024 2005 6013 2008 3283 8649 19738 2015 2187 13827 2038 2580 1037 10317 6149 18847 14561 2008 9319 1031 1056 13512 1033 2907 2011 25850 2075 24116 2545 2046 4223 1037 1998 2101 2008 15180 2031 4866 2231 1998 8224 3454 4249 1997 2817 1998 3423 1998 2591 17606 2000 4047 2308 2021 2043 1037 2158 17612 2015 2055 1037 5907 3277 12473 2273 2002 3022 12599 2004 1037 28616 15707 26942 1998 1037 1059 14014 2099 1012 1037 1996 2187 2003 2012 2162 2007 4507 1012 1031 1056 13512 1033 2409 1996 3606 1012 2005 2008 1031 1056 13512 1033 2001 6965 14682 2079 20348 2098 1004 5045 1012 1001 15333 6342 2483 3900 7834 17130 5686 1037 2703 3312 7908 1006 1030 3827 11751 2102 1007 2257 1022 2418 1031 1056 13512 1033 2038 3130 2056 2008 1031 1056 13512 1033 7164 6555 2015 2031 1037 15404 2006 2296 2350 13773 3028 2194 1998 2038 2328 11721 2497 2004 2019 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.049221 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.051903 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.054311 140083176642432 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.093266 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.096189 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] comedian louis c . k . is being accused of sexual misconduct by five women in a new york times report . the premiere of his controversial new movie \" i love you daddy \" has been cancelled and c . k . has not commented on the allegations . ( nick ##i dem ##ar ##co / the washington post ) on thursday afternoon the new york times released a story about sexual harassment allegations against comedian louis c . [ t ##gt ] . most big - name comedians have remained silent on the subject so far but others in the entertainment industry are reacting and let a s just say there isn a t a lot of shock over the accusations that the a louie a creator allegedly mast ##ur ##bate ##d in front of multiple women . rumors about c . [ t ##gt ] . had been circulating for years most explicitly in a def ##ame ##r story written in 2015 . so when the premiere of the comedian a s new movie a i love you daddy a was canceled along with an appearance on stephen colbert something was clearly up . that something was the times expo ##sa ##© with allegations from five women . we are i am guessing hours from all the louis ck stories breaking and i will admit this one i ' ve been waiting for . a ro ##xa ##ne gay ( @ r ##ga ##y ) november 9 2017 the silence from the men in comedy on twitter right now speaks volumes # yes ##all ##men # him ##to ##o https : / / t . co / 4 ##d ##np ##2 ##y ##b ##vy ##o a sean l . mccarthy ( @ the ##com ##ics ##com ##ic ) november 9 2017 as the article recounted women in the comedy industry who were allegedly harassed by c . [ t ##gt ] . were open about what happened to [ t ##gt ] . and yet people didn a t want to hear what they had to say . [ louis c . [ t ##gt ] . accused of sexual misconduct in new york times report ] a guys were backing away from us a julia wo ##lov said in the story . wo ##lov all ##ege ##s that while at a comedy festival in 2002 she and a friend were invited to c . [ t ##gt ] hotel room where [ t ##gt ] di ##sr ##obe ##d and mast ##ur ##bate ##d in front of them . the next day when the two women started telling other comedians what had happened a we could already feel the backlash . a other women are chi ##ming in with similar stories about being silenced . i was told to del ##ete a t ##wee ##t i wrote about louis ck abu ##sing women before i applied to a high - profile comedy job because the people conducting the hiring process might not like it . these [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.099591 140083176642432 run_classifier.py:464] tokens: [CLS] comedian louis c . k . is being accused of sexual misconduct by five women in a new york times report . the premiere of his controversial new movie \" i love you daddy \" has been cancelled and c . k . has not commented on the allegations . ( nick ##i dem ##ar ##co / the washington post ) on thursday afternoon the new york times released a story about sexual harassment allegations against comedian louis c . [ t ##gt ] . most big - name comedians have remained silent on the subject so far but others in the entertainment industry are reacting and let a s just say there isn a t a lot of shock over the accusations that the a louie a creator allegedly mast ##ur ##bate ##d in front of multiple women . rumors about c . [ t ##gt ] . had been circulating for years most explicitly in a def ##ame ##r story written in 2015 . so when the premiere of the comedian a s new movie a i love you daddy a was canceled along with an appearance on stephen colbert something was clearly up . that something was the times expo ##sa ##© with allegations from five women . we are i am guessing hours from all the louis ck stories breaking and i will admit this one i ' ve been waiting for . a ro ##xa ##ne gay ( @ r ##ga ##y ) november 9 2017 the silence from the men in comedy on twitter right now speaks volumes # yes ##all ##men # him ##to ##o https : / / t . co / 4 ##d ##np ##2 ##y ##b ##vy ##o a sean l . mccarthy ( @ the ##com ##ics ##com ##ic ) november 9 2017 as the article recounted women in the comedy industry who were allegedly harassed by c . [ t ##gt ] . were open about what happened to [ t ##gt ] . and yet people didn a t want to hear what they had to say . [ louis c . [ t ##gt ] . accused of sexual misconduct in new york times report ] a guys were backing away from us a julia wo ##lov said in the story . wo ##lov all ##ege ##s that while at a comedy festival in 2002 she and a friend were invited to c . [ t ##gt ] hotel room where [ t ##gt ] di ##sr ##obe ##d and mast ##ur ##bate ##d in front of them . the next day when the two women started telling other comedians what had happened a we could already feel the backlash . a other women are chi ##ming in with similar stories about being silenced . i was told to del ##ete a t ##wee ##t i wrote about louis ck abu ##sing women before i applied to a high - profile comedy job because the people conducting the hiring process might not like it . these [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 9971 3434 1039 1012 1047 1012 2003 2108 5496 1997 4424 23337 2011 2274 2308 1999 1037 2047 2259 2335 3189 1012 1996 6765 1997 2010 6801 2047 3185 1000 1045 2293 2017 8600 1000 2038 2042 8014 1998 1039 1012 1047 1012 2038 2025 7034 2006 1996 9989 1012 1006 4172 2072 17183 2906 3597 1013 1996 2899 2695 1007 2006 9432 5027 1996 2047 2259 2335 2207 1037 2466 2055 4424 16011 9989 2114 9971 3434 1039 1012 1031 1056 13512 1033 1012 2087 2502 1011 2171 25119 2031 2815 4333 2006 1996 3395 2061 2521 2021 2500 1999 1996 4024 3068 2024 24868 1998 2292 1037 1055 2074 2360 2045 3475 1037 1056 1037 2843 1997 5213 2058 1996 13519 2008 1996 1037 17438 1037 8543 9382 15429 3126 20179 2094 1999 2392 1997 3674 2308 1012 11256 2055 1039 1012 1031 1056 13512 1033 1012 2018 2042 22458 2005 2086 2087 12045 1999 1037 13366 14074 2099 2466 2517 1999 2325 1012 2061 2043 1996 6765 1997 1996 9971 1037 1055 2047 3185 1037 1045 2293 2017 8600 1037 2001 13261 2247 2007 2019 3311 2006 4459 23928 2242 2001 4415 2039 1012 2008 2242 2001 1996 2335 16258 3736 29652 2007 9989 2013 2274 2308 1012 2057 2024 1045 2572 16986 2847 2013 2035 1996 3434 23616 3441 4911 1998 1045 2097 6449 2023 2028 1045 1005 2310 2042 3403 2005 1012 1037 20996 18684 2638 5637 1006 1030 1054 3654 2100 1007 2281 1023 2418 1996 4223 2013 1996 2273 1999 4038 2006 10474 2157 2085 8847 6702 1001 2748 8095 3549 1001 2032 3406 2080 16770 1024 1013 1013 1056 1012 2522 1013 1018 2094 16275 2475 2100 2497 10736 2080 1037 5977 1048 1012 12584 1006 1030 1996 9006 6558 9006 2594 1007 2281 1023 2418 2004 1996 3720 22906 2308 1999 1996 4038 3068 2040 2020 9382 28186 2011 1039 1012 1031 1056 13512 1033 1012 2020 2330 2055 2054 3047 2000 1031 1056 13512 1033 1012 1998 2664 2111 2134 1037 1056 2215 2000 2963 2054 2027 2018 2000 2360 1012 1031 3434 1039 1012 1031 1056 13512 1033 1012 5496 1997 4424 23337 1999 2047 2259 2335 3189 1033 1037 4364 2020 5150 2185 2013 2149 1037 6423 24185 14301 2056 1999 1996 2466 1012 24185 14301 2035 24746 2015 2008 2096 2012 1037 4038 2782 1999 2526 2016 1998 1037 2767 2020 4778 2000 1039 1012 1031 1056 13512 1033 3309 2282 2073 1031 1056 13512 1033 4487 21338 20891 2094 1998 15429 3126 20179 2094 1999 2392 1997 2068 1012 1996 2279 2154 2043 1996 2048 2308 2318 4129 2060 25119 2054 2018 3047 1037 2057 2071 2525 2514 1996 25748 1012 1037 2060 2308 2024 9610 6562 1999 2007 2714 3441 2055 2108 25030 1012 1045 2001 2409 2000 3972 12870 1037 1056 28394 2102 1045 2626 2055 3434 23616 8273 7741 2308 2077 1045 4162 2000 1037 2152 1011 6337 4038 3105 2138 1996 2111 9283 1996 14763 2832 2453 2025 2066 2009 1012 2122 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.102471 140083176642432 run_classifier.py:465] input_ids: 101 9971 3434 1039 1012 1047 1012 2003 2108 5496 1997 4424 23337 2011 2274 2308 1999 1037 2047 2259 2335 3189 1012 1996 6765 1997 2010 6801 2047 3185 1000 1045 2293 2017 8600 1000 2038 2042 8014 1998 1039 1012 1047 1012 2038 2025 7034 2006 1996 9989 1012 1006 4172 2072 17183 2906 3597 1013 1996 2899 2695 1007 2006 9432 5027 1996 2047 2259 2335 2207 1037 2466 2055 4424 16011 9989 2114 9971 3434 1039 1012 1031 1056 13512 1033 1012 2087 2502 1011 2171 25119 2031 2815 4333 2006 1996 3395 2061 2521 2021 2500 1999 1996 4024 3068 2024 24868 1998 2292 1037 1055 2074 2360 2045 3475 1037 1056 1037 2843 1997 5213 2058 1996 13519 2008 1996 1037 17438 1037 8543 9382 15429 3126 20179 2094 1999 2392 1997 3674 2308 1012 11256 2055 1039 1012 1031 1056 13512 1033 1012 2018 2042 22458 2005 2086 2087 12045 1999 1037 13366 14074 2099 2466 2517 1999 2325 1012 2061 2043 1996 6765 1997 1996 9971 1037 1055 2047 3185 1037 1045 2293 2017 8600 1037 2001 13261 2247 2007 2019 3311 2006 4459 23928 2242 2001 4415 2039 1012 2008 2242 2001 1996 2335 16258 3736 29652 2007 9989 2013 2274 2308 1012 2057 2024 1045 2572 16986 2847 2013 2035 1996 3434 23616 3441 4911 1998 1045 2097 6449 2023 2028 1045 1005 2310 2042 3403 2005 1012 1037 20996 18684 2638 5637 1006 1030 1054 3654 2100 1007 2281 1023 2418 1996 4223 2013 1996 2273 1999 4038 2006 10474 2157 2085 8847 6702 1001 2748 8095 3549 1001 2032 3406 2080 16770 1024 1013 1013 1056 1012 2522 1013 1018 2094 16275 2475 2100 2497 10736 2080 1037 5977 1048 1012 12584 1006 1030 1996 9006 6558 9006 2594 1007 2281 1023 2418 2004 1996 3720 22906 2308 1999 1996 4038 3068 2040 2020 9382 28186 2011 1039 1012 1031 1056 13512 1033 1012 2020 2330 2055 2054 3047 2000 1031 1056 13512 1033 1012 1998 2664 2111 2134 1037 1056 2215 2000 2963 2054 2027 2018 2000 2360 1012 1031 3434 1039 1012 1031 1056 13512 1033 1012 5496 1997 4424 23337 1999 2047 2259 2335 3189 1033 1037 4364 2020 5150 2185 2013 2149 1037 6423 24185 14301 2056 1999 1996 2466 1012 24185 14301 2035 24746 2015 2008 2096 2012 1037 4038 2782 1999 2526 2016 1998 1037 2767 2020 4778 2000 1039 1012 1031 1056 13512 1033 3309 2282 2073 1031 1056 13512 1033 4487 21338 20891 2094 1998 15429 3126 20179 2094 1999 2392 1997 2068 1012 1996 2279 2154 2043 1996 2048 2308 2318 4129 2060 25119 2054 2018 3047 1037 2057 2071 2525 2514 1996 25748 1012 1037 2060 2308 2024 9610 6562 1999 2007 2714 3441 2055 2108 25030 1012 1045 2001 2409 2000 3972 12870 1037 1056 28394 2102 1045 2626 2055 3434 23616 8273 7741 2308 2077 1045 4162 2000 1037 2152 1011 6337 4038 3105 2138 1996 2111 9283 1996 14763 2832 2453 2025 2066 2009 1012 2122 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.105370 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.107939 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: -1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.110300 140083176642432 run_classifier.py:468] label: -1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.123194 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.126121 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] as ##taff are working at a pace that is un ##heard of ( in trade negotiations ) . . . and any suggestion that wear ##e not operating beyond a normal pace is just flat wrong a [ t ##gt ] told reporters . [ t ##gt ] said canada had am ##ent ##ioned ##a the u . s . ruling during talks on wednesday . asked whether the dispute could affect na ##ft ##a talks light ##hi ##zer told reporters : ai ##am not saying it doesn ##at have an effect on relationships it does but not on this negotiation . a [ t ##gt ] said the united states would ah ##ope ##fully ##a present draft text by the next round on the thorn ##y issue of rules of origin which outlines how much of a product needs to originate in a na ##ft ##a country and on a dispute settlement mechanism . [ t ##gt ] said the u . s . decision on bombardier still had several stages to go through before it was finalized . at ##her ##e are several more stages we dona ##t even know whether it is going to be successful and in addition there are off - ramps in the litigation a he said . ai ##tas too early to tell . a free ##land has suggested that canada could walk away from the na ##ft ##a talks over the so - called chapter 19 dispute mechanism under which bin ##ation ##al panels make binding decisions on complaints about illegal subsidies and dumping . the united states has frequently lost such cases . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.128995 140083176642432 run_classifier.py:464] tokens: [CLS] as ##taff are working at a pace that is un ##heard of ( in trade negotiations ) . . . and any suggestion that wear ##e not operating beyond a normal pace is just flat wrong a [ t ##gt ] told reporters . [ t ##gt ] said canada had am ##ent ##ioned ##a the u . s . ruling during talks on wednesday . asked whether the dispute could affect na ##ft ##a talks light ##hi ##zer told reporters : ai ##am not saying it doesn ##at have an effect on relationships it does but not on this negotiation . a [ t ##gt ] said the united states would ah ##ope ##fully ##a present draft text by the next round on the thorn ##y issue of rules of origin which outlines how much of a product needs to originate in a na ##ft ##a country and on a dispute settlement mechanism . [ t ##gt ] said the u . s . decision on bombardier still had several stages to go through before it was finalized . at ##her ##e are several more stages we dona ##t even know whether it is going to be successful and in addition there are off - ramps in the litigation a he said . ai ##tas too early to tell . a free ##land has suggested that canada could walk away from the na ##ft ##a talks over the so - called chapter 19 dispute mechanism under which bin ##ation ##al panels make binding decisions on complaints about illegal subsidies and dumping . the united states has frequently lost such cases . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2004 22542 2024 2551 2012 1037 6393 2008 2003 4895 26362 1997 1006 1999 3119 7776 1007 1012 1012 1012 1998 2151 10293 2008 4929 2063 2025 4082 3458 1037 3671 6393 2003 2074 4257 3308 1037 1031 1056 13512 1033 2409 12060 1012 1031 1056 13512 1033 2056 2710 2018 2572 4765 19798 2050 1996 1057 1012 1055 1012 6996 2076 7566 2006 9317 1012 2356 3251 1996 7593 2071 7461 6583 6199 2050 7566 2422 4048 6290 2409 12060 1024 9932 3286 2025 3038 2009 2987 4017 2031 2019 3466 2006 6550 2009 2515 2021 2025 2006 2023 19905 1012 1037 1031 1056 13512 1033 2056 1996 2142 2163 2052 6289 17635 7699 2050 2556 4433 3793 2011 1996 2279 2461 2006 1996 16337 2100 3277 1997 3513 1997 4761 2029 22106 2129 2172 1997 1037 4031 3791 2000 21754 1999 1037 6583 6199 2050 2406 1998 2006 1037 7593 4093 7337 1012 1031 1056 13512 1033 2056 1996 1057 1012 1055 1012 3247 2006 29143 2145 2018 2195 5711 2000 2175 2083 2077 2009 2001 23575 1012 2012 5886 2063 2024 2195 2062 5711 2057 24260 2102 2130 2113 3251 2009 2003 2183 2000 2022 3144 1998 1999 2804 2045 2024 2125 1011 24943 1999 1996 15382 1037 2002 2056 1012 9932 10230 2205 2220 2000 2425 1012 1037 2489 3122 2038 4081 2008 2710 2071 3328 2185 2013 1996 6583 6199 2050 7566 2058 1996 2061 1011 2170 3127 2539 7593 7337 2104 2029 8026 3370 2389 9320 2191 8031 6567 2006 10821 2055 6206 21762 1998 23642 1012 1996 2142 2163 2038 4703 2439 2107 3572 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.131680 140083176642432 run_classifier.py:465] input_ids: 101 2004 22542 2024 2551 2012 1037 6393 2008 2003 4895 26362 1997 1006 1999 3119 7776 1007 1012 1012 1012 1998 2151 10293 2008 4929 2063 2025 4082 3458 1037 3671 6393 2003 2074 4257 3308 1037 1031 1056 13512 1033 2409 12060 1012 1031 1056 13512 1033 2056 2710 2018 2572 4765 19798 2050 1996 1057 1012 1055 1012 6996 2076 7566 2006 9317 1012 2356 3251 1996 7593 2071 7461 6583 6199 2050 7566 2422 4048 6290 2409 12060 1024 9932 3286 2025 3038 2009 2987 4017 2031 2019 3466 2006 6550 2009 2515 2021 2025 2006 2023 19905 1012 1037 1031 1056 13512 1033 2056 1996 2142 2163 2052 6289 17635 7699 2050 2556 4433 3793 2011 1996 2279 2461 2006 1996 16337 2100 3277 1997 3513 1997 4761 2029 22106 2129 2172 1997 1037 4031 3791 2000 21754 1999 1037 6583 6199 2050 2406 1998 2006 1037 7593 4093 7337 1012 1031 1056 13512 1033 2056 1996 1057 1012 1055 1012 3247 2006 29143 2145 2018 2195 5711 2000 2175 2083 2077 2009 2001 23575 1012 2012 5886 2063 2024 2195 2062 5711 2057 24260 2102 2130 2113 3251 2009 2003 2183 2000 2022 3144 1998 1999 2804 2045 2024 2125 1011 24943 1999 1996 15382 1037 2002 2056 1012 9932 10230 2205 2220 2000 2425 1012 1037 2489 3122 2038 4081 2008 2710 2071 3328 2185 2013 1996 6583 6199 2050 7566 2058 1996 2061 1011 2170 3127 2539 7593 7337 2104 2029 8026 3370 2389 9320 2191 8031 6567 2006 10821 2055 6206 21762 1998 23642 1012 1996 2142 2163 2038 4703 2439 2107 3572 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.134541 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.137181 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.139539 140083176642432 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.146517 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.149835 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] [ t ##gt ] said [ t ##gt ] was installing a fence on the roof of a three - story building near the library when [ t ##gt ] looked down and made eye contact with the suspect . \" i saw in [ t ##gt ] eyes [ t ##gt ] didn ' t care [ t ##gt ] said . the gun ##man continued down the street firing three shots toward a campus church then changed direction and fired three more times into the air [ t ##gt ] said . a garbage truck driver leaped out of his vehicle and ran away as did a woman carrying two babies cordoba . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.152447 140083176642432 run_classifier.py:464] tokens: [CLS] [ t ##gt ] said [ t ##gt ] was installing a fence on the roof of a three - story building near the library when [ t ##gt ] looked down and made eye contact with the suspect . \" i saw in [ t ##gt ] eyes [ t ##gt ] didn ' t care [ t ##gt ] said . the gun ##man continued down the street firing three shots toward a campus church then changed direction and fired three more times into the air [ t ##gt ] said . a garbage truck driver leaped out of his vehicle and ran away as did a woman carrying two babies cordoba . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1031 1056 13512 1033 2056 1031 1056 13512 1033 2001 23658 1037 8638 2006 1996 4412 1997 1037 2093 1011 2466 2311 2379 1996 3075 2043 1031 1056 13512 1033 2246 2091 1998 2081 3239 3967 2007 1996 8343 1012 1000 1045 2387 1999 1031 1056 13512 1033 2159 1031 1056 13512 1033 2134 1005 1056 2729 1031 1056 13512 1033 2056 1012 1996 3282 2386 2506 2091 1996 2395 7493 2093 7171 2646 1037 3721 2277 2059 2904 3257 1998 5045 2093 2062 2335 2046 1996 2250 1031 1056 13512 1033 2056 1012 1037 13044 4744 4062 16900 2041 1997 2010 4316 1998 2743 2185 2004 2106 1037 2450 4755 2048 10834 17986 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.155107 140083176642432 run_classifier.py:465] input_ids: 101 1031 1056 13512 1033 2056 1031 1056 13512 1033 2001 23658 1037 8638 2006 1996 4412 1997 1037 2093 1011 2466 2311 2379 1996 3075 2043 1031 1056 13512 1033 2246 2091 1998 2081 3239 3967 2007 1996 8343 1012 1000 1045 2387 1999 1031 1056 13512 1033 2159 1031 1056 13512 1033 2134 1005 1056 2729 1031 1056 13512 1033 2056 1012 1996 3282 2386 2506 2091 1996 2395 7493 2093 7171 2646 1037 3721 2277 2059 2904 3257 1998 5045 2093 2062 2335 2046 1996 2250 1031 1056 13512 1033 2056 1012 1037 13044 4744 4062 16900 2041 1997 2010 4316 1998 2743 2185 2004 2106 1037 2450 4755 2048 10834 17986 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.157844 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.160259 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.162720 140083176642432 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.180896 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.189022 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] hong hai group chairman terry go ##u said tuesday that investigations by chinese authorities have found none of the 10 suicide ##s at his group ' s shenzhen complex in guangdong province had anything to do with the working conditions there . guo said at the group ' s shareholders meeting that chinese authorities sent a team of 200 - odd officials to conduct a 10 - day on - site investigation into the reasons behind the incidents at the shenzhen complex where over 400 000 people are employed . the next day another fox ##con ##n worker jumped to his death bringing the total number of suicide ##s to 10 and the number of attempts to 12 and fuel ##ing criticism that go ##u is \" running a blood and sweat factory . [ t ##gt ] said that after a thorough investigation the chinese officials did not \" det ##ain \" him which meant that hon hai was not at fault . \" none of the 12 suicide attempts at the shenzhen complex were a result of poor working conditions or low salaries as has been alleged \" [ t ##gt ] said . [ t ##gt ] said [ t ##gt ] would not rule out the possibility of sui ##ng the media organizations or journalists for their ground ##less reports . citing surveys in china [ t ##gt ] said more than 100 million people in china suffer from various types of mental disorders and 16 million of them are categorized as being in \" serious condition \" . based on these statistics go ##u said the percentage of attempted suicide ##s among fox ##con ##n ' s 450 000 workers in shenzhen is substantially lower than the percentage of mentally ill people in china ' s total population . as part of the group ' s efforts to stem the suicide attempts it will stop offering compensation of 10 years salary to the families of suicide victims [ t ##gt ] said . the decision was made after one of the workers who attempted suicide was found to have told his family in a suicide note that the company will pay them a large sum if he succeeded in killing himself according to ku ##o . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.192380 140083176642432 run_classifier.py:464] tokens: [CLS] hong hai group chairman terry go ##u said tuesday that investigations by chinese authorities have found none of the 10 suicide ##s at his group ' s shenzhen complex in guangdong province had anything to do with the working conditions there . guo said at the group ' s shareholders meeting that chinese authorities sent a team of 200 - odd officials to conduct a 10 - day on - site investigation into the reasons behind the incidents at the shenzhen complex where over 400 000 people are employed . the next day another fox ##con ##n worker jumped to his death bringing the total number of suicide ##s to 10 and the number of attempts to 12 and fuel ##ing criticism that go ##u is \" running a blood and sweat factory . [ t ##gt ] said that after a thorough investigation the chinese officials did not \" det ##ain \" him which meant that hon hai was not at fault . \" none of the 12 suicide attempts at the shenzhen complex were a result of poor working conditions or low salaries as has been alleged \" [ t ##gt ] said . [ t ##gt ] said [ t ##gt ] would not rule out the possibility of sui ##ng the media organizations or journalists for their ground ##less reports . citing surveys in china [ t ##gt ] said more than 100 million people in china suffer from various types of mental disorders and 16 million of them are categorized as being in \" serious condition \" . based on these statistics go ##u said the percentage of attempted suicide ##s among fox ##con ##n ' s 450 000 workers in shenzhen is substantially lower than the percentage of mentally ill people in china ' s total population . as part of the group ' s efforts to stem the suicide attempts it will stop offering compensation of 10 years salary to the families of suicide victims [ t ##gt ] said . the decision was made after one of the workers who attempted suicide was found to have told his family in a suicide note that the company will pay them a large sum if he succeeded in killing himself according to ku ##o . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4291 15030 2177 3472 6609 2175 2226 2056 9857 2008 9751 2011 2822 4614 2031 2179 3904 1997 1996 2184 5920 2015 2012 2010 2177 1005 1055 26555 3375 1999 21287 2874 2018 2505 2000 2079 2007 1996 2551 3785 2045 1012 22720 2056 2012 1996 2177 1005 1055 15337 3116 2008 2822 4614 2741 1037 2136 1997 3263 1011 5976 4584 2000 6204 1037 2184 1011 2154 2006 1011 2609 4812 2046 1996 4436 2369 1996 10444 2012 1996 26555 3375 2073 2058 4278 2199 2111 2024 4846 1012 1996 2279 2154 2178 4419 8663 2078 7309 5598 2000 2010 2331 5026 1996 2561 2193 1997 5920 2015 2000 2184 1998 1996 2193 1997 4740 2000 2260 1998 4762 2075 6256 2008 2175 2226 2003 1000 2770 1037 2668 1998 7518 4713 1012 1031 1056 13512 1033 2056 2008 2044 1037 16030 4812 1996 2822 4584 2106 2025 1000 20010 8113 1000 2032 2029 3214 2008 10189 15030 2001 2025 2012 6346 1012 1000 3904 1997 1996 2260 5920 4740 2012 1996 26555 3375 2020 1037 2765 1997 3532 2551 3785 2030 2659 20566 2004 2038 2042 6884 1000 1031 1056 13512 1033 2056 1012 1031 1056 13512 1033 2056 1031 1056 13512 1033 2052 2025 3627 2041 1996 6061 1997 24086 3070 1996 2865 4411 2030 8845 2005 2037 2598 3238 4311 1012 8951 12265 1999 2859 1031 1056 13512 1033 2056 2062 2084 2531 2454 2111 1999 2859 9015 2013 2536 4127 1997 5177 10840 1998 2385 2454 1997 2068 2024 20427 2004 2108 1999 1000 3809 4650 1000 1012 2241 2006 2122 6747 2175 2226 2056 1996 7017 1997 4692 5920 2015 2426 4419 8663 2078 1005 1055 10332 2199 3667 1999 26555 2003 12381 2896 2084 1996 7017 1997 10597 5665 2111 1999 2859 1005 1055 2561 2313 1012 2004 2112 1997 1996 2177 1005 1055 4073 2000 7872 1996 5920 4740 2009 2097 2644 5378 9430 1997 2184 2086 10300 2000 1996 2945 1997 5920 5694 1031 1056 13512 1033 2056 1012 1996 3247 2001 2081 2044 2028 1997 1996 3667 2040 4692 5920 2001 2179 2000 2031 2409 2010 2155 1999 1037 5920 3602 2008 1996 2194 2097 3477 2068 1037 2312 7680 2065 2002 4594 1999 4288 2370 2429 2000 13970 2080 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.194890 140083176642432 run_classifier.py:465] input_ids: 101 4291 15030 2177 3472 6609 2175 2226 2056 9857 2008 9751 2011 2822 4614 2031 2179 3904 1997 1996 2184 5920 2015 2012 2010 2177 1005 1055 26555 3375 1999 21287 2874 2018 2505 2000 2079 2007 1996 2551 3785 2045 1012 22720 2056 2012 1996 2177 1005 1055 15337 3116 2008 2822 4614 2741 1037 2136 1997 3263 1011 5976 4584 2000 6204 1037 2184 1011 2154 2006 1011 2609 4812 2046 1996 4436 2369 1996 10444 2012 1996 26555 3375 2073 2058 4278 2199 2111 2024 4846 1012 1996 2279 2154 2178 4419 8663 2078 7309 5598 2000 2010 2331 5026 1996 2561 2193 1997 5920 2015 2000 2184 1998 1996 2193 1997 4740 2000 2260 1998 4762 2075 6256 2008 2175 2226 2003 1000 2770 1037 2668 1998 7518 4713 1012 1031 1056 13512 1033 2056 2008 2044 1037 16030 4812 1996 2822 4584 2106 2025 1000 20010 8113 1000 2032 2029 3214 2008 10189 15030 2001 2025 2012 6346 1012 1000 3904 1997 1996 2260 5920 4740 2012 1996 26555 3375 2020 1037 2765 1997 3532 2551 3785 2030 2659 20566 2004 2038 2042 6884 1000 1031 1056 13512 1033 2056 1012 1031 1056 13512 1033 2056 1031 1056 13512 1033 2052 2025 3627 2041 1996 6061 1997 24086 3070 1996 2865 4411 2030 8845 2005 2037 2598 3238 4311 1012 8951 12265 1999 2859 1031 1056 13512 1033 2056 2062 2084 2531 2454 2111 1999 2859 9015 2013 2536 4127 1997 5177 10840 1998 2385 2454 1997 2068 2024 20427 2004 2108 1999 1000 3809 4650 1000 1012 2241 2006 2122 6747 2175 2226 2056 1996 7017 1997 4692 5920 2015 2426 4419 8663 2078 1005 1055 10332 2199 3667 1999 26555 2003 12381 2896 2084 1996 7017 1997 10597 5665 2111 1999 2859 1005 1055 2561 2313 1012 2004 2112 1997 1996 2177 1005 1055 4073 2000 7872 1996 5920 4740 2009 2097 2644 5378 9430 1997 2184 2086 10300 2000 1996 2945 1997 5920 5694 1031 1056 13512 1033 2056 1012 1996 3247 2001 2081 2044 2028 1997 1996 3667 2040 4692 5920 2001 2179 2000 2031 2409 2010 2155 1999 1037 5920 3602 2008 1996 2194 2097 3477 2068 1037 2312 7680 2065 2002 4594 1999 4288 2370 2429 2000 13970 2080 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.197402 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.199928 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:38.202475 140083176642432 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.640050 140083176642432 run_classifier.py:774] Writing example 0 of 284\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.661031 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.663568 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] frank ##en rei ##tera ##tes he won ' t resign : ' i know that i ' ve let a lot of people down [ t ##gt ] said monday [ t ##gt ] would not resign from office after allegations of sexual harassment have been leveled against [ t ##gt ] . \" i know that i ' ve let a lot of people down \" frank ##en said noting that he was looking forward to getting back to work . \" my colleagues my staff my supporters and everyone who has counted on me to be a champion for women . to all of you i just want to again say i am sorry . i know there are no magic words i can say to regain your trust . \" he said the process will take time and \" that starts with going back to work today . \" the minnesota democrat spoke to reporters on capitol hill for the first time since multiple women have accused him of inappropriate sexual conduct ranging from for ##ci ##ble kissing to unwanted touching . he took a few questions reiterated that he would not resign and expressed remorse and regret . \" i ' ve been trying to take responsibility by ap ##olo ##gizing \" frank ##en said . he added \" i ' m going to be accountable \" and \" cooperate completely with the ethics investigation . \" frank ##en ' s conduct has been referred to the senate ethics committee . the committee could recommend anywhere from a rep ##rim ##and to ce ##ns ##ure to expulsion but the full senate would have to act on that . lee ##anne tweed ##en a radio host in los angeles and former model toured with frank ##en as part of the us ##o . she recalled frank ##en forcibly kissing her during sketches and rehearsals . a photo taken aboard a cargo plane also shows frank ##en touching tweed ##en ' s breasts over a fl ##ak jacket while she was asleep . looking over his shoulder frank ##en smirk ##s at the camera . frank ##en said he didn ' t remember his time with tweed ##en the same way but noted \" i feel that you have to respect women ' s experience . i apologized to her and i meant it . and i was very grateful that she accepted it . \" women have also accused frank ##en of touching their butt ##ocks while taking photos in minnesota . frank ##en said he does not remember specific instances in which that happened but he did not deny that it did . \" one is too many \" frank ##en said . he added that it was di ##sr ##es ##pe ##ct ##ful and he is sorry he hurt them . he repeated later \" i am tremendous ##ly sorry . . . . i am embarrassed . i feel ashamed . \" [ t ##gt ] ' s comments echo what [ t ##gt [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.668797 140083176642432 run_classifier.py:464] tokens: [CLS] frank ##en rei ##tera ##tes he won ' t resign : ' i know that i ' ve let a lot of people down [ t ##gt ] said monday [ t ##gt ] would not resign from office after allegations of sexual harassment have been leveled against [ t ##gt ] . \" i know that i ' ve let a lot of people down \" frank ##en said noting that he was looking forward to getting back to work . \" my colleagues my staff my supporters and everyone who has counted on me to be a champion for women . to all of you i just want to again say i am sorry . i know there are no magic words i can say to regain your trust . \" he said the process will take time and \" that starts with going back to work today . \" the minnesota democrat spoke to reporters on capitol hill for the first time since multiple women have accused him of inappropriate sexual conduct ranging from for ##ci ##ble kissing to unwanted touching . he took a few questions reiterated that he would not resign and expressed remorse and regret . \" i ' ve been trying to take responsibility by ap ##olo ##gizing \" frank ##en said . he added \" i ' m going to be accountable \" and \" cooperate completely with the ethics investigation . \" frank ##en ' s conduct has been referred to the senate ethics committee . the committee could recommend anywhere from a rep ##rim ##and to ce ##ns ##ure to expulsion but the full senate would have to act on that . lee ##anne tweed ##en a radio host in los angeles and former model toured with frank ##en as part of the us ##o . she recalled frank ##en forcibly kissing her during sketches and rehearsals . a photo taken aboard a cargo plane also shows frank ##en touching tweed ##en ' s breasts over a fl ##ak jacket while she was asleep . looking over his shoulder frank ##en smirk ##s at the camera . frank ##en said he didn ' t remember his time with tweed ##en the same way but noted \" i feel that you have to respect women ' s experience . i apologized to her and i meant it . and i was very grateful that she accepted it . \" women have also accused frank ##en of touching their butt ##ocks while taking photos in minnesota . frank ##en said he does not remember specific instances in which that happened but he did not deny that it did . \" one is too many \" frank ##en said . he added that it was di ##sr ##es ##pe ##ct ##ful and he is sorry he hurt them . he repeated later \" i am tremendous ##ly sorry . . . . i am embarrassed . i feel ashamed . \" [ t ##gt ] ' s comments echo what [ t ##gt [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3581 2368 24964 14621 4570 2002 2180 1005 1056 12897 1024 1005 1045 2113 2008 1045 1005 2310 2292 1037 2843 1997 2111 2091 1031 1056 13512 1033 2056 6928 1031 1056 13512 1033 2052 2025 12897 2013 2436 2044 9989 1997 4424 16011 2031 2042 22915 2114 1031 1056 13512 1033 1012 1000 1045 2113 2008 1045 1005 2310 2292 1037 2843 1997 2111 2091 1000 3581 2368 2056 9073 2008 2002 2001 2559 2830 2000 2893 2067 2000 2147 1012 1000 2026 8628 2026 3095 2026 6793 1998 3071 2040 2038 8897 2006 2033 2000 2022 1037 3410 2005 2308 1012 2000 2035 1997 2017 1045 2074 2215 2000 2153 2360 1045 2572 3374 1012 1045 2113 2045 2024 2053 3894 2616 1045 2064 2360 2000 12452 2115 3404 1012 1000 2002 2056 1996 2832 2097 2202 2051 1998 1000 2008 4627 2007 2183 2067 2000 2147 2651 1012 1000 1996 5135 7672 3764 2000 12060 2006 9424 2940 2005 1996 2034 2051 2144 3674 2308 2031 5496 2032 1997 15884 4424 6204 7478 2013 2005 6895 3468 7618 2000 18162 7244 1012 2002 2165 1037 2261 3980 28960 2008 2002 2052 2025 12897 1998 5228 23124 1998 9038 1012 1000 1045 1005 2310 2042 2667 2000 2202 5368 2011 9706 12898 28660 1000 3581 2368 2056 1012 2002 2794 1000 1045 1005 1049 2183 2000 2022 26771 1000 1998 1000 17654 3294 2007 1996 9615 4812 1012 1000 3581 2368 1005 1055 6204 2038 2042 3615 2000 1996 4001 9615 2837 1012 1996 2837 2071 16755 5973 2013 1037 16360 20026 5685 2000 8292 3619 5397 2000 18272 2021 1996 2440 4001 2052 2031 2000 2552 2006 2008 1012 3389 20147 26922 2368 1037 2557 3677 1999 3050 3349 1998 2280 2944 7255 2007 3581 2368 2004 2112 1997 1996 2149 2080 1012 2016 7383 3581 2368 20951 7618 2014 2076 12741 1998 24760 1012 1037 6302 2579 7548 1037 6636 4946 2036 3065 3581 2368 7244 26922 2368 1005 1055 12682 2058 1037 13109 4817 6598 2096 2016 2001 6680 1012 2559 2058 2010 3244 3581 2368 15081 2015 2012 1996 4950 1012 3581 2368 2056 2002 2134 1005 1056 3342 2010 2051 2007 26922 2368 1996 2168 2126 2021 3264 1000 1045 2514 2008 2017 2031 2000 4847 2308 1005 1055 3325 1012 1045 17806 2000 2014 1998 1045 3214 2009 1012 1998 1045 2001 2200 8794 2008 2016 3970 2009 1012 1000 2308 2031 2036 5496 3581 2368 1997 7244 2037 10007 25384 2096 2635 7760 1999 5135 1012 3581 2368 2056 2002 2515 2025 3342 3563 12107 1999 2029 2008 3047 2021 2002 2106 2025 9772 2008 2009 2106 1012 1000 2028 2003 2205 2116 1000 3581 2368 2056 1012 2002 2794 2008 2009 2001 4487 21338 2229 5051 6593 3993 1998 2002 2003 3374 2002 3480 2068 1012 2002 5567 2101 1000 1045 2572 14388 2135 3374 1012 1012 1012 1012 1045 2572 10339 1012 1045 2514 14984 1012 1000 1031 1056 13512 1033 1005 1055 7928 9052 2054 1031 1056 13512 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.674819 140083176642432 run_classifier.py:465] input_ids: 101 3581 2368 24964 14621 4570 2002 2180 1005 1056 12897 1024 1005 1045 2113 2008 1045 1005 2310 2292 1037 2843 1997 2111 2091 1031 1056 13512 1033 2056 6928 1031 1056 13512 1033 2052 2025 12897 2013 2436 2044 9989 1997 4424 16011 2031 2042 22915 2114 1031 1056 13512 1033 1012 1000 1045 2113 2008 1045 1005 2310 2292 1037 2843 1997 2111 2091 1000 3581 2368 2056 9073 2008 2002 2001 2559 2830 2000 2893 2067 2000 2147 1012 1000 2026 8628 2026 3095 2026 6793 1998 3071 2040 2038 8897 2006 2033 2000 2022 1037 3410 2005 2308 1012 2000 2035 1997 2017 1045 2074 2215 2000 2153 2360 1045 2572 3374 1012 1045 2113 2045 2024 2053 3894 2616 1045 2064 2360 2000 12452 2115 3404 1012 1000 2002 2056 1996 2832 2097 2202 2051 1998 1000 2008 4627 2007 2183 2067 2000 2147 2651 1012 1000 1996 5135 7672 3764 2000 12060 2006 9424 2940 2005 1996 2034 2051 2144 3674 2308 2031 5496 2032 1997 15884 4424 6204 7478 2013 2005 6895 3468 7618 2000 18162 7244 1012 2002 2165 1037 2261 3980 28960 2008 2002 2052 2025 12897 1998 5228 23124 1998 9038 1012 1000 1045 1005 2310 2042 2667 2000 2202 5368 2011 9706 12898 28660 1000 3581 2368 2056 1012 2002 2794 1000 1045 1005 1049 2183 2000 2022 26771 1000 1998 1000 17654 3294 2007 1996 9615 4812 1012 1000 3581 2368 1005 1055 6204 2038 2042 3615 2000 1996 4001 9615 2837 1012 1996 2837 2071 16755 5973 2013 1037 16360 20026 5685 2000 8292 3619 5397 2000 18272 2021 1996 2440 4001 2052 2031 2000 2552 2006 2008 1012 3389 20147 26922 2368 1037 2557 3677 1999 3050 3349 1998 2280 2944 7255 2007 3581 2368 2004 2112 1997 1996 2149 2080 1012 2016 7383 3581 2368 20951 7618 2014 2076 12741 1998 24760 1012 1037 6302 2579 7548 1037 6636 4946 2036 3065 3581 2368 7244 26922 2368 1005 1055 12682 2058 1037 13109 4817 6598 2096 2016 2001 6680 1012 2559 2058 2010 3244 3581 2368 15081 2015 2012 1996 4950 1012 3581 2368 2056 2002 2134 1005 1056 3342 2010 2051 2007 26922 2368 1996 2168 2126 2021 3264 1000 1045 2514 2008 2017 2031 2000 4847 2308 1005 1055 3325 1012 1045 17806 2000 2014 1998 1045 3214 2009 1012 1998 1045 2001 2200 8794 2008 2016 3970 2009 1012 1000 2308 2031 2036 5496 3581 2368 1997 7244 2037 10007 25384 2096 2635 7760 1999 5135 1012 3581 2368 2056 2002 2515 2025 3342 3563 12107 1999 2029 2008 3047 2021 2002 2106 2025 9772 2008 2009 2106 1012 1000 2028 2003 2205 2116 1000 3581 2368 2056 1012 2002 2794 2008 2009 2001 4487 21338 2229 5051 6593 3993 1998 2002 2003 3374 2002 3480 2068 1012 2002 5567 2101 1000 1045 2572 14388 2135 3374 1012 1012 1012 1012 1045 2572 10339 1012 1045 2514 14984 1012 1000 1031 1056 13512 1033 1005 1055 7928 9052 2054 1031 1056 13512 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.679594 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.684233 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.692025 140083176642432 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.718956 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.721555 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] [ t ##gt ] has made a career of what are known as wage - and - hour cases . that may sound dry but the issues involved strike at the heart of the relationship between employees - particularly low - income employees - and the people they work for . as [ t ##gt ] explains it this a population that is often at the mercy of the people they work for . the benefits at stake here are typically small - two hours of overtime here a lunch break there - but they add up . [ t ##gt ] entered the wal - mart suit earlier this year . mills law firm a law firm based in california had been appointed by the court to represent the plaintiffs . mills is one of the nation ' s pre ##emi ##nent class - action law firms but needed local counsel . [ t ##gt ] became that counsel the lawyer on the ground in boston . that the case has taken eight years to resolve speaks to the difficulty of sui ##ng a be ##hem ##oth . though [ t ##gt ] was not at liberty to talk about wal - mart specifically [ t ##gt ] talked generally about the difficulty of sui ##ng a big company . \" they have so many resources \" [ t ##gt ] said . \" if you need records like time ##cards that prove how much your client worked they have the records . if you need to talk to a manager who can explain what went on the manager works for them . they can tie up cases knowing that employees have no resources and need lawyers who can take cases on con ##ting ##ency \" meaning they get paid only if they win the case . asks [ t ##gt ] : \" how many lawyers can afford to do that ? [ t ##gt ] refers to the settlement as a \" mini - stimulus \" for the affected workers who will receive an average of $ 73 ##4 . \" it ' s direct assistance - cash - to people who really really need it . \" he argues that the settlement will be good for low - wage workers whose employers will be less likely to exploit them and to employers . law - ab ##idi ##ng employers he said will no longer have to compete against companies that derive an unfair advantage by under ##pa ##ying their workers . [ t ##gt ] delivers this message like many of [ t ##gt ] statements with something approaching mess ##iani ##c ze ##al . [ t ##gt ] is david battling go ##lia ##th and this case is proof that sometimes david can win . \" i ' m a lucky guy \" [ t ##gt ] said . \" i get to do what i love to do . \" [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.729115 140083176642432 run_classifier.py:464] tokens: [CLS] [ t ##gt ] has made a career of what are known as wage - and - hour cases . that may sound dry but the issues involved strike at the heart of the relationship between employees - particularly low - income employees - and the people they work for . as [ t ##gt ] explains it this a population that is often at the mercy of the people they work for . the benefits at stake here are typically small - two hours of overtime here a lunch break there - but they add up . [ t ##gt ] entered the wal - mart suit earlier this year . mills law firm a law firm based in california had been appointed by the court to represent the plaintiffs . mills is one of the nation ' s pre ##emi ##nent class - action law firms but needed local counsel . [ t ##gt ] became that counsel the lawyer on the ground in boston . that the case has taken eight years to resolve speaks to the difficulty of sui ##ng a be ##hem ##oth . though [ t ##gt ] was not at liberty to talk about wal - mart specifically [ t ##gt ] talked generally about the difficulty of sui ##ng a big company . \" they have so many resources \" [ t ##gt ] said . \" if you need records like time ##cards that prove how much your client worked they have the records . if you need to talk to a manager who can explain what went on the manager works for them . they can tie up cases knowing that employees have no resources and need lawyers who can take cases on con ##ting ##ency \" meaning they get paid only if they win the case . asks [ t ##gt ] : \" how many lawyers can afford to do that ? [ t ##gt ] refers to the settlement as a \" mini - stimulus \" for the affected workers who will receive an average of $ 73 ##4 . \" it ' s direct assistance - cash - to people who really really need it . \" he argues that the settlement will be good for low - wage workers whose employers will be less likely to exploit them and to employers . law - ab ##idi ##ng employers he said will no longer have to compete against companies that derive an unfair advantage by under ##pa ##ying their workers . [ t ##gt ] delivers this message like many of [ t ##gt ] statements with something approaching mess ##iani ##c ze ##al . [ t ##gt ] is david battling go ##lia ##th and this case is proof that sometimes david can win . \" i ' m a lucky guy \" [ t ##gt ] said . \" i get to do what i love to do . \" [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1031 1056 13512 1033 2038 2081 1037 2476 1997 2054 2024 2124 2004 11897 1011 1998 1011 3178 3572 1012 2008 2089 2614 4318 2021 1996 3314 2920 4894 2012 1996 2540 1997 1996 3276 2090 5126 1011 3391 2659 1011 3318 5126 1011 1998 1996 2111 2027 2147 2005 1012 2004 1031 1056 13512 1033 7607 2009 2023 1037 2313 2008 2003 2411 2012 1996 8673 1997 1996 2111 2027 2147 2005 1012 1996 6666 2012 8406 2182 2024 4050 2235 1011 2048 2847 1997 12253 2182 1037 6265 3338 2045 1011 2021 2027 5587 2039 1012 1031 1056 13512 1033 3133 1996 24547 1011 20481 4848 3041 2023 2095 1012 6341 2375 3813 1037 2375 3813 2241 1999 2662 2018 2042 2805 2011 1996 2457 2000 5050 1996 23953 1012 6341 2003 2028 1997 1996 3842 1005 1055 3653 23238 21576 2465 1011 2895 2375 9786 2021 2734 2334 9517 1012 1031 1056 13512 1033 2150 2008 9517 1996 5160 2006 1996 2598 1999 3731 1012 2008 1996 2553 2038 2579 2809 2086 2000 10663 8847 2000 1996 7669 1997 24086 3070 1037 2022 29122 14573 1012 2295 1031 1056 13512 1033 2001 2025 2012 7044 2000 2831 2055 24547 1011 20481 4919 1031 1056 13512 1033 5720 3227 2055 1996 7669 1997 24086 3070 1037 2502 2194 1012 1000 2027 2031 2061 2116 4219 1000 1031 1056 13512 1033 2056 1012 1000 2065 2017 2342 2636 2066 2051 17965 2008 6011 2129 2172 2115 7396 2499 2027 2031 1996 2636 1012 2065 2017 2342 2000 2831 2000 1037 3208 2040 2064 4863 2054 2253 2006 1996 3208 2573 2005 2068 1012 2027 2064 5495 2039 3572 4209 2008 5126 2031 2053 4219 1998 2342 9559 2040 2064 2202 3572 2006 9530 3436 11916 1000 3574 2027 2131 3825 2069 2065 2027 2663 1996 2553 1012 5176 1031 1056 13512 1033 1024 1000 2129 2116 9559 2064 8984 2000 2079 2008 1029 1031 1056 13512 1033 5218 2000 1996 4093 2004 1037 1000 7163 1011 19220 1000 2005 1996 5360 3667 2040 2097 4374 2019 2779 1997 1002 6421 2549 1012 1000 2009 1005 1055 3622 5375 1011 5356 1011 2000 2111 2040 2428 2428 2342 2009 1012 1000 2002 9251 2008 1996 4093 2097 2022 2204 2005 2659 1011 11897 3667 3005 12433 2097 2022 2625 3497 2000 18077 2068 1998 2000 12433 1012 2375 1011 11113 28173 3070 12433 2002 2056 2097 2053 2936 2031 2000 5566 2114 3316 2008 18547 2019 15571 5056 2011 2104 4502 14147 2037 3667 1012 1031 1056 13512 1033 18058 2023 4471 2066 2116 1997 1031 1056 13512 1033 8635 2007 2242 8455 6752 25443 2278 27838 2389 1012 1031 1056 13512 1033 2003 2585 17773 2175 6632 2705 1998 2023 2553 2003 6947 2008 2823 2585 2064 2663 1012 1000 1045 1005 1049 1037 5341 3124 1000 1031 1056 13512 1033 2056 1012 1000 1045 2131 2000 2079 2054 1045 2293 2000 2079 1012 1000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.732089 140083176642432 run_classifier.py:465] input_ids: 101 1031 1056 13512 1033 2038 2081 1037 2476 1997 2054 2024 2124 2004 11897 1011 1998 1011 3178 3572 1012 2008 2089 2614 4318 2021 1996 3314 2920 4894 2012 1996 2540 1997 1996 3276 2090 5126 1011 3391 2659 1011 3318 5126 1011 1998 1996 2111 2027 2147 2005 1012 2004 1031 1056 13512 1033 7607 2009 2023 1037 2313 2008 2003 2411 2012 1996 8673 1997 1996 2111 2027 2147 2005 1012 1996 6666 2012 8406 2182 2024 4050 2235 1011 2048 2847 1997 12253 2182 1037 6265 3338 2045 1011 2021 2027 5587 2039 1012 1031 1056 13512 1033 3133 1996 24547 1011 20481 4848 3041 2023 2095 1012 6341 2375 3813 1037 2375 3813 2241 1999 2662 2018 2042 2805 2011 1996 2457 2000 5050 1996 23953 1012 6341 2003 2028 1997 1996 3842 1005 1055 3653 23238 21576 2465 1011 2895 2375 9786 2021 2734 2334 9517 1012 1031 1056 13512 1033 2150 2008 9517 1996 5160 2006 1996 2598 1999 3731 1012 2008 1996 2553 2038 2579 2809 2086 2000 10663 8847 2000 1996 7669 1997 24086 3070 1037 2022 29122 14573 1012 2295 1031 1056 13512 1033 2001 2025 2012 7044 2000 2831 2055 24547 1011 20481 4919 1031 1056 13512 1033 5720 3227 2055 1996 7669 1997 24086 3070 1037 2502 2194 1012 1000 2027 2031 2061 2116 4219 1000 1031 1056 13512 1033 2056 1012 1000 2065 2017 2342 2636 2066 2051 17965 2008 6011 2129 2172 2115 7396 2499 2027 2031 1996 2636 1012 2065 2017 2342 2000 2831 2000 1037 3208 2040 2064 4863 2054 2253 2006 1996 3208 2573 2005 2068 1012 2027 2064 5495 2039 3572 4209 2008 5126 2031 2053 4219 1998 2342 9559 2040 2064 2202 3572 2006 9530 3436 11916 1000 3574 2027 2131 3825 2069 2065 2027 2663 1996 2553 1012 5176 1031 1056 13512 1033 1024 1000 2129 2116 9559 2064 8984 2000 2079 2008 1029 1031 1056 13512 1033 5218 2000 1996 4093 2004 1037 1000 7163 1011 19220 1000 2005 1996 5360 3667 2040 2097 4374 2019 2779 1997 1002 6421 2549 1012 1000 2009 1005 1055 3622 5375 1011 5356 1011 2000 2111 2040 2428 2428 2342 2009 1012 1000 2002 9251 2008 1996 4093 2097 2022 2204 2005 2659 1011 11897 3667 3005 12433 2097 2022 2625 3497 2000 18077 2068 1998 2000 12433 1012 2375 1011 11113 28173 3070 12433 2002 2056 2097 2053 2936 2031 2000 5566 2114 3316 2008 18547 2019 15571 5056 2011 2104 4502 14147 2037 3667 1012 1031 1056 13512 1033 18058 2023 4471 2066 2116 1997 1031 1056 13512 1033 8635 2007 2242 8455 6752 25443 2278 27838 2389 1012 1031 1056 13512 1033 2003 2585 17773 2175 6632 2705 1998 2023 2553 2003 6947 2008 2823 2585 2064 2663 1012 1000 1045 1005 1049 1037 5341 3124 1000 1031 1056 13512 1033 2056 1012 1000 1045 2131 2000 2079 2054 1045 2293 2000 2079 1012 1000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.734586 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.737814 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.740195 140083176642432 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.771493 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.774163 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] but as the finals have progressed and bryant ' s will has grown stronger and more determined [ t ##gt ] has noticed a pattern from the past re - emerging . \" we always at the end of the evening can find areas during the game where we say kobe needs to move the ball more and get more people involved [ t ##gt ] said . \" but that ' s something that you just kind of have to take with [ t ##gt ] . because of [ t ##gt ] ability [ t ##gt ] can take and make shots that most other players can ' t make . [ t ##gt ] said that over [ t ##gt ] years as an assistant and a player alongside bryant [ t ##gt ] ' s noticed how a \" peck ##ing order \" emerges in the lakers offense with bryant as the top option and too often the only option . \" we tell our guys to start the offense away from [ t ##gt ] \" [ t ##gt ] said . \" use this side of the court see your options over here ; if nothing ' s there reverse it to [ t ##gt ] and now the shot clock ' s down and let [ t ##gt ] do [ t ##gt ] thing . but when [ t ##gt ] ' s out there on the floor and [ t ##gt ] ' s doing [ t ##gt ] little signals asking for the ball there ' s kind of a peck ##ing order that happens out there on the court . \" they don ' t want to piss [ t ##gt ] off and they want to please the coaching staff as well . but [ t ##gt ] ' s the closest one to them on the floor . so a lot of times they ' ll force the ball into [ t ##gt ] with three people around [ t ##gt ] instead of making the right play . \" the only player on the lakers who consistently does what the offense di ##cta ##tes is derek fisher [ t ##gt ] said with too many younger players def ##er ##ring to bryant ' s commands . \" some of the younger guys they just want to make [ t ##gt ] happy \" [ t ##gt ] said . \" when i played sha ##q was the second . . . there were two dominant players . so if we went away from kobe and threw it in to sha ##q what can he say ? now who is that guy that ' s on the same level that he ' s on ? if they make a play over here to lamar ( o ##dom ) or somebody else and kobe gets mad then they ' re going to play more to that because nobody ' s on that same level . \" well how [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.777230 140083176642432 run_classifier.py:464] tokens: [CLS] but as the finals have progressed and bryant ' s will has grown stronger and more determined [ t ##gt ] has noticed a pattern from the past re - emerging . \" we always at the end of the evening can find areas during the game where we say kobe needs to move the ball more and get more people involved [ t ##gt ] said . \" but that ' s something that you just kind of have to take with [ t ##gt ] . because of [ t ##gt ] ability [ t ##gt ] can take and make shots that most other players can ' t make . [ t ##gt ] said that over [ t ##gt ] years as an assistant and a player alongside bryant [ t ##gt ] ' s noticed how a \" peck ##ing order \" emerges in the lakers offense with bryant as the top option and too often the only option . \" we tell our guys to start the offense away from [ t ##gt ] \" [ t ##gt ] said . \" use this side of the court see your options over here ; if nothing ' s there reverse it to [ t ##gt ] and now the shot clock ' s down and let [ t ##gt ] do [ t ##gt ] thing . but when [ t ##gt ] ' s out there on the floor and [ t ##gt ] ' s doing [ t ##gt ] little signals asking for the ball there ' s kind of a peck ##ing order that happens out there on the court . \" they don ' t want to piss [ t ##gt ] off and they want to please the coaching staff as well . but [ t ##gt ] ' s the closest one to them on the floor . so a lot of times they ' ll force the ball into [ t ##gt ] with three people around [ t ##gt ] instead of making the right play . \" the only player on the lakers who consistently does what the offense di ##cta ##tes is derek fisher [ t ##gt ] said with too many younger players def ##er ##ring to bryant ' s commands . \" some of the younger guys they just want to make [ t ##gt ] happy \" [ t ##gt ] said . \" when i played sha ##q was the second . . . there were two dominant players . so if we went away from kobe and threw it in to sha ##q what can he say ? now who is that guy that ' s on the same level that he ' s on ? if they make a play over here to lamar ( o ##dom ) or somebody else and kobe gets mad then they ' re going to play more to that because nobody ' s on that same level . \" well how [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2021 2004 1996 4399 2031 12506 1998 12471 1005 1055 2097 2038 4961 6428 1998 2062 4340 1031 1056 13512 1033 2038 4384 1037 5418 2013 1996 2627 2128 1011 8361 1012 1000 2057 2467 2012 1996 2203 1997 1996 3944 2064 2424 2752 2076 1996 2208 2073 2057 2360 24113 3791 2000 2693 1996 3608 2062 1998 2131 2062 2111 2920 1031 1056 13512 1033 2056 1012 1000 2021 2008 1005 1055 2242 2008 2017 2074 2785 1997 2031 2000 2202 2007 1031 1056 13512 1033 1012 2138 1997 1031 1056 13512 1033 3754 1031 1056 13512 1033 2064 2202 1998 2191 7171 2008 2087 2060 2867 2064 1005 1056 2191 1012 1031 1056 13512 1033 2056 2008 2058 1031 1056 13512 1033 2086 2004 2019 3353 1998 1037 2447 4077 12471 1031 1056 13512 1033 1005 1055 4384 2129 1037 1000 18082 2075 2344 1000 19391 1999 1996 18264 10048 2007 12471 2004 1996 2327 5724 1998 2205 2411 1996 2069 5724 1012 1000 2057 2425 2256 4364 2000 2707 1996 10048 2185 2013 1031 1056 13512 1033 1000 1031 1056 13512 1033 2056 1012 1000 2224 2023 2217 1997 1996 2457 2156 2115 7047 2058 2182 1025 2065 2498 1005 1055 2045 7901 2009 2000 1031 1056 13512 1033 1998 2085 1996 2915 5119 1005 1055 2091 1998 2292 1031 1056 13512 1033 2079 1031 1056 13512 1033 2518 1012 2021 2043 1031 1056 13512 1033 1005 1055 2041 2045 2006 1996 2723 1998 1031 1056 13512 1033 1005 1055 2725 1031 1056 13512 1033 2210 7755 4851 2005 1996 3608 2045 1005 1055 2785 1997 1037 18082 2075 2344 2008 6433 2041 2045 2006 1996 2457 1012 1000 2027 2123 1005 1056 2215 2000 18138 1031 1056 13512 1033 2125 1998 2027 2215 2000 3531 1996 7748 3095 2004 2092 1012 2021 1031 1056 13512 1033 1005 1055 1996 7541 2028 2000 2068 2006 1996 2723 1012 2061 1037 2843 1997 2335 2027 1005 2222 2486 1996 3608 2046 1031 1056 13512 1033 2007 2093 2111 2105 1031 1056 13512 1033 2612 1997 2437 1996 2157 2377 1012 1000 1996 2069 2447 2006 1996 18264 2040 10862 2515 2054 1996 10048 4487 25572 4570 2003 7256 8731 1031 1056 13512 1033 2056 2007 2205 2116 3920 2867 13366 2121 4892 2000 12471 1005 1055 10954 1012 1000 2070 1997 1996 3920 4364 2027 2074 2215 2000 2191 1031 1056 13512 1033 3407 1000 1031 1056 13512 1033 2056 1012 1000 2043 1045 2209 21146 4160 2001 1996 2117 1012 1012 1012 2045 2020 2048 7444 2867 1012 2061 2065 2057 2253 2185 2013 24113 1998 4711 2009 1999 2000 21146 4160 2054 2064 2002 2360 1029 2085 2040 2003 2008 3124 2008 1005 1055 2006 1996 2168 2504 2008 2002 1005 1055 2006 1029 2065 2027 2191 1037 2377 2058 2182 2000 19756 1006 1051 9527 1007 2030 8307 2842 1998 24113 4152 5506 2059 2027 1005 2128 2183 2000 2377 2062 2000 2008 2138 6343 1005 1055 2006 2008 2168 2504 1012 1000 2092 2129 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.780745 140083176642432 run_classifier.py:465] input_ids: 101 2021 2004 1996 4399 2031 12506 1998 12471 1005 1055 2097 2038 4961 6428 1998 2062 4340 1031 1056 13512 1033 2038 4384 1037 5418 2013 1996 2627 2128 1011 8361 1012 1000 2057 2467 2012 1996 2203 1997 1996 3944 2064 2424 2752 2076 1996 2208 2073 2057 2360 24113 3791 2000 2693 1996 3608 2062 1998 2131 2062 2111 2920 1031 1056 13512 1033 2056 1012 1000 2021 2008 1005 1055 2242 2008 2017 2074 2785 1997 2031 2000 2202 2007 1031 1056 13512 1033 1012 2138 1997 1031 1056 13512 1033 3754 1031 1056 13512 1033 2064 2202 1998 2191 7171 2008 2087 2060 2867 2064 1005 1056 2191 1012 1031 1056 13512 1033 2056 2008 2058 1031 1056 13512 1033 2086 2004 2019 3353 1998 1037 2447 4077 12471 1031 1056 13512 1033 1005 1055 4384 2129 1037 1000 18082 2075 2344 1000 19391 1999 1996 18264 10048 2007 12471 2004 1996 2327 5724 1998 2205 2411 1996 2069 5724 1012 1000 2057 2425 2256 4364 2000 2707 1996 10048 2185 2013 1031 1056 13512 1033 1000 1031 1056 13512 1033 2056 1012 1000 2224 2023 2217 1997 1996 2457 2156 2115 7047 2058 2182 1025 2065 2498 1005 1055 2045 7901 2009 2000 1031 1056 13512 1033 1998 2085 1996 2915 5119 1005 1055 2091 1998 2292 1031 1056 13512 1033 2079 1031 1056 13512 1033 2518 1012 2021 2043 1031 1056 13512 1033 1005 1055 2041 2045 2006 1996 2723 1998 1031 1056 13512 1033 1005 1055 2725 1031 1056 13512 1033 2210 7755 4851 2005 1996 3608 2045 1005 1055 2785 1997 1037 18082 2075 2344 2008 6433 2041 2045 2006 1996 2457 1012 1000 2027 2123 1005 1056 2215 2000 18138 1031 1056 13512 1033 2125 1998 2027 2215 2000 3531 1996 7748 3095 2004 2092 1012 2021 1031 1056 13512 1033 1005 1055 1996 7541 2028 2000 2068 2006 1996 2723 1012 2061 1037 2843 1997 2335 2027 1005 2222 2486 1996 3608 2046 1031 1056 13512 1033 2007 2093 2111 2105 1031 1056 13512 1033 2612 1997 2437 1996 2157 2377 1012 1000 1996 2069 2447 2006 1996 18264 2040 10862 2515 2054 1996 10048 4487 25572 4570 2003 7256 8731 1031 1056 13512 1033 2056 2007 2205 2116 3920 2867 13366 2121 4892 2000 12471 1005 1055 10954 1012 1000 2070 1997 1996 3920 4364 2027 2074 2215 2000 2191 1031 1056 13512 1033 3407 1000 1031 1056 13512 1033 2056 1012 1000 2043 1045 2209 21146 4160 2001 1996 2117 1012 1012 1012 2045 2020 2048 7444 2867 1012 2061 2065 2057 2253 2185 2013 24113 1998 4711 2009 1999 2000 21146 4160 2054 2064 2002 2360 1029 2085 2040 2003 2008 3124 2008 1005 1055 2006 1996 2168 2504 2008 2002 1005 1055 2006 1029 2065 2027 2191 1037 2377 2058 2182 2000 19756 1006 1051 9527 1007 2030 8307 2842 1998 24113 4152 5506 2059 2027 1005 2128 2183 2000 2377 2062 2000 2008 2138 6343 1005 1055 2006 2008 2168 2504 1012 1000 2092 2129 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.783293 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.787463 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.790404 140083176642432 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.829463 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.831573 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] charles manson spent over 46 years in prison for the vicious murders of seven people in 1969 including actress sharon tate . after his lengthy trial and conviction manson became a constant and mor ##bid presence in pop culture . ( erin patrick o ' connor / the washington post ) a prelude to the con ##fl ##ag ##ration was the slaughter of the seven people in two affluent los angeles neighborhoods . orchestrated by mr . manson on two successive nights in august 1969 the seemingly random killings were calculated to haste ##n the race war by making them appear committed by black militants . that in turn he told his followers would stir white sentiment against african americans triggering widespread violence by blacks . vincent bug ##lio ##si the hard - charging deputy district attorney who prosecuted mr . manson described the manson name as aa metaphor for evil . a mr . manson was a study in stark contrasts . small and sc ##ra ##wny he was also charismatic and held an almost hypnotic power over his followers especially women . some believed he was divine . investigators academic researchers and journalists found him alternately erratic and focused a proficient guitarist a lover of animals a racist and an anti - semi ##te with a left - leaning hatred of the ae ##sta ##bl ##ishment ##a and corporate america and bitterness over his rejection by the music celebrity world of hollywood . he was not insane but he could fake it and had an ins ##ati ##able need to control others prompting him to recruit naive and mall ##ea ##ble ac ##ol ##yte ##s to his family according to behavior ##ists who studied his life . aba ##sic ##ally manson was a coward a eric hi ##ckey dean of the california school of forensic studies at all ##ian ##t international university told maclean ##as magazine in 2012 . a he was the kind of guy who had other people do his bidding and i think he really enjoyed taking advantage of people who were gu ##lli ##ble . a he married twice first to a teenage waitress rosalie willis in 1955 di ##vor ##cing in 1958 . then in 1959 he married a woman with a prostitution record named leon ##a ac ##and ##ya stevens according to prison records . that union also ended in divorce . a son from his first marriage [ t ##gt ] committed suicide in 1993 . [ t ##gt ] had a son from [ t ##gt ] second marriage charles luther manson . [ t ##gt ] had at least one other child as well . prosecutors depicted mr . manson as the met ##ic ##ulous master ##mind of the murders and while family members acknowledged [ t ##gt ] planning role they said [ t ##gt ] did not participate in the killings . the jury nevertheless found [ t ##gt ] equally cu ##lp ##able under california ##as joint - responsibility rule . [ t ##gt ] was [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.835669 140083176642432 run_classifier.py:464] tokens: [CLS] charles manson spent over 46 years in prison for the vicious murders of seven people in 1969 including actress sharon tate . after his lengthy trial and conviction manson became a constant and mor ##bid presence in pop culture . ( erin patrick o ' connor / the washington post ) a prelude to the con ##fl ##ag ##ration was the slaughter of the seven people in two affluent los angeles neighborhoods . orchestrated by mr . manson on two successive nights in august 1969 the seemingly random killings were calculated to haste ##n the race war by making them appear committed by black militants . that in turn he told his followers would stir white sentiment against african americans triggering widespread violence by blacks . vincent bug ##lio ##si the hard - charging deputy district attorney who prosecuted mr . manson described the manson name as aa metaphor for evil . a mr . manson was a study in stark contrasts . small and sc ##ra ##wny he was also charismatic and held an almost hypnotic power over his followers especially women . some believed he was divine . investigators academic researchers and journalists found him alternately erratic and focused a proficient guitarist a lover of animals a racist and an anti - semi ##te with a left - leaning hatred of the ae ##sta ##bl ##ishment ##a and corporate america and bitterness over his rejection by the music celebrity world of hollywood . he was not insane but he could fake it and had an ins ##ati ##able need to control others prompting him to recruit naive and mall ##ea ##ble ac ##ol ##yte ##s to his family according to behavior ##ists who studied his life . aba ##sic ##ally manson was a coward a eric hi ##ckey dean of the california school of forensic studies at all ##ian ##t international university told maclean ##as magazine in 2012 . a he was the kind of guy who had other people do his bidding and i think he really enjoyed taking advantage of people who were gu ##lli ##ble . a he married twice first to a teenage waitress rosalie willis in 1955 di ##vor ##cing in 1958 . then in 1959 he married a woman with a prostitution record named leon ##a ac ##and ##ya stevens according to prison records . that union also ended in divorce . a son from his first marriage [ t ##gt ] committed suicide in 1993 . [ t ##gt ] had a son from [ t ##gt ] second marriage charles luther manson . [ t ##gt ] had at least one other child as well . prosecutors depicted mr . manson as the met ##ic ##ulous master ##mind of the murders and while family members acknowledged [ t ##gt ] planning role they said [ t ##gt ] did not participate in the killings . the jury nevertheless found [ t ##gt ] equally cu ##lp ##able under california ##as joint - responsibility rule . [ t ##gt ] was [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2798 21440 2985 2058 4805 2086 1999 3827 2005 1996 13925 9916 1997 2698 2111 1999 3440 2164 3883 10666 9902 1012 2044 2010 12401 3979 1998 10652 21440 2150 1037 5377 1998 22822 17062 3739 1999 3769 3226 1012 1006 11781 4754 1051 1005 6720 1013 1996 2899 2695 1007 1037 19508 2000 1996 9530 10258 8490 8156 2001 1996 14574 1997 1996 2698 2111 1999 2048 22666 3050 3349 11681 1012 23339 2011 2720 1012 21440 2006 2048 11165 6385 1999 2257 3440 1996 9428 6721 16431 2020 10174 2000 24748 2078 1996 2679 2162 2011 2437 2068 3711 5462 2011 2304 17671 1012 2008 1999 2735 2002 2409 2010 8771 2052 16130 2317 15792 2114 3060 4841 29170 6923 4808 2011 10823 1012 6320 11829 12798 5332 1996 2524 1011 13003 4112 2212 4905 2040 21651 2720 1012 21440 2649 1996 21440 2171 2004 9779 19240 2005 4763 1012 1037 2720 1012 21440 2001 1037 2817 1999 9762 23347 1012 2235 1998 8040 2527 22251 2002 2001 2036 23916 1998 2218 2019 2471 28322 2373 2058 2010 8771 2926 2308 1012 2070 3373 2002 2001 7746 1012 14766 3834 6950 1998 8845 2179 2032 23554 24122 1998 4208 1037 27029 5990 1037 7089 1997 4176 1037 16939 1998 2019 3424 1011 4100 2618 2007 1037 2187 1011 6729 11150 1997 1996 29347 9153 16558 21808 2050 1998 5971 2637 1998 22364 2058 2010 13893 2011 1996 2189 8958 2088 1997 5365 1012 2002 2001 2025 9577 2021 2002 2071 8275 2009 1998 2018 2019 16021 10450 3085 2342 2000 2491 2500 15870 2032 2000 13024 15743 1998 6670 5243 3468 9353 4747 17250 2015 2000 2010 2155 2429 2000 5248 5130 2040 3273 2010 2166 1012 19557 19570 3973 21440 2001 1037 16592 1037 4388 7632 29183 4670 1997 1996 2662 2082 1997 15359 2913 2012 2035 2937 2102 2248 2118 2409 22528 3022 2932 1999 2262 1012 1037 2002 2001 1996 2785 1997 3124 2040 2018 2060 2111 2079 2010 17534 1998 1045 2228 2002 2428 5632 2635 5056 1997 2111 2040 2020 19739 6894 3468 1012 1037 2002 2496 3807 2034 2000 1037 9454 13877 29564 12688 1999 3982 4487 14550 6129 1999 3845 1012 2059 1999 3851 2002 2496 1037 2450 2007 1037 15016 2501 2315 6506 2050 9353 5685 3148 8799 2429 2000 3827 2636 1012 2008 2586 2036 3092 1999 8179 1012 1037 2365 2013 2010 2034 3510 1031 1056 13512 1033 5462 5920 1999 2857 1012 1031 1056 13512 1033 2018 1037 2365 2013 1031 1056 13512 1033 2117 3510 2798 9678 21440 1012 1031 1056 13512 1033 2018 2012 2560 2028 2060 2775 2004 2092 1012 19608 8212 2720 1012 21440 2004 1996 2777 2594 16203 3040 23356 1997 1996 9916 1998 2096 2155 2372 8969 1031 1056 13512 1033 4041 2535 2027 2056 1031 1056 13512 1033 2106 2025 5589 1999 1996 16431 1012 1996 6467 6600 2179 1031 1056 13512 1033 8053 12731 14277 3085 2104 2662 3022 4101 1011 5368 3627 1012 1031 1056 13512 1033 2001 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.839622 140083176642432 run_classifier.py:465] input_ids: 101 2798 21440 2985 2058 4805 2086 1999 3827 2005 1996 13925 9916 1997 2698 2111 1999 3440 2164 3883 10666 9902 1012 2044 2010 12401 3979 1998 10652 21440 2150 1037 5377 1998 22822 17062 3739 1999 3769 3226 1012 1006 11781 4754 1051 1005 6720 1013 1996 2899 2695 1007 1037 19508 2000 1996 9530 10258 8490 8156 2001 1996 14574 1997 1996 2698 2111 1999 2048 22666 3050 3349 11681 1012 23339 2011 2720 1012 21440 2006 2048 11165 6385 1999 2257 3440 1996 9428 6721 16431 2020 10174 2000 24748 2078 1996 2679 2162 2011 2437 2068 3711 5462 2011 2304 17671 1012 2008 1999 2735 2002 2409 2010 8771 2052 16130 2317 15792 2114 3060 4841 29170 6923 4808 2011 10823 1012 6320 11829 12798 5332 1996 2524 1011 13003 4112 2212 4905 2040 21651 2720 1012 21440 2649 1996 21440 2171 2004 9779 19240 2005 4763 1012 1037 2720 1012 21440 2001 1037 2817 1999 9762 23347 1012 2235 1998 8040 2527 22251 2002 2001 2036 23916 1998 2218 2019 2471 28322 2373 2058 2010 8771 2926 2308 1012 2070 3373 2002 2001 7746 1012 14766 3834 6950 1998 8845 2179 2032 23554 24122 1998 4208 1037 27029 5990 1037 7089 1997 4176 1037 16939 1998 2019 3424 1011 4100 2618 2007 1037 2187 1011 6729 11150 1997 1996 29347 9153 16558 21808 2050 1998 5971 2637 1998 22364 2058 2010 13893 2011 1996 2189 8958 2088 1997 5365 1012 2002 2001 2025 9577 2021 2002 2071 8275 2009 1998 2018 2019 16021 10450 3085 2342 2000 2491 2500 15870 2032 2000 13024 15743 1998 6670 5243 3468 9353 4747 17250 2015 2000 2010 2155 2429 2000 5248 5130 2040 3273 2010 2166 1012 19557 19570 3973 21440 2001 1037 16592 1037 4388 7632 29183 4670 1997 1996 2662 2082 1997 15359 2913 2012 2035 2937 2102 2248 2118 2409 22528 3022 2932 1999 2262 1012 1037 2002 2001 1996 2785 1997 3124 2040 2018 2060 2111 2079 2010 17534 1998 1045 2228 2002 2428 5632 2635 5056 1997 2111 2040 2020 19739 6894 3468 1012 1037 2002 2496 3807 2034 2000 1037 9454 13877 29564 12688 1999 3982 4487 14550 6129 1999 3845 1012 2059 1999 3851 2002 2496 1037 2450 2007 1037 15016 2501 2315 6506 2050 9353 5685 3148 8799 2429 2000 3827 2636 1012 2008 2586 2036 3092 1999 8179 1012 1037 2365 2013 2010 2034 3510 1031 1056 13512 1033 5462 5920 1999 2857 1012 1031 1056 13512 1033 2018 1037 2365 2013 1031 1056 13512 1033 2117 3510 2798 9678 21440 1012 1031 1056 13512 1033 2018 2012 2560 2028 2060 2775 2004 2092 1012 19608 8212 2720 1012 21440 2004 1996 2777 2594 16203 3040 23356 1997 1996 9916 1998 2096 2155 2372 8969 1031 1056 13512 1033 4041 2535 2027 2056 1031 1056 13512 1033 2106 2025 5589 1999 1996 16431 1012 1996 6467 6600 2179 1031 1056 13512 1033 8053 12731 14277 3085 2104 2662 3022 4101 1011 5368 3627 1012 1031 1056 13512 1033 2001 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.847398 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.850135 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: -1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.852994 140083176642432 run_classifier.py:468] label: -1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.869745 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.874237 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] dear carolyn : my girlfriend and i just went on our first vacation together . i thought it went well but after we were home she told me she felt i had been cheap because i wanted to split all costs 50 - 50 . ia ##m concerned that she and i have fundamentally different attitudes toward money and also that we have fundamentally different attitudes toward communication as i think she should have spoken up when i first proposed splitting 50 - 50 not waited until after the vacation was over . first vacation ##er : ia ##m definitely with you on the communication problem . yes it would have helped for her to say something beforehand a if in fact she had doubts then . but even if she wasn ##at sure till she actually saw what you meant by a ##50 - 50 a then speaking up on the spot would have been the more productive thing to do : ah ##ey when you said 50 - 50 i thought you meant we ##ad share expenses a but i wasn ##at expecting that we ##ad split every meal down to the loose change . a she did eventually speak up though so you have that . use it by responding honestly with your concerns . say you wish she had said something as soon as this bothered her and ask if there ##as a reason she didn ##at . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.877948 140083176642432 run_classifier.py:464] tokens: [CLS] dear carolyn : my girlfriend and i just went on our first vacation together . i thought it went well but after we were home she told me she felt i had been cheap because i wanted to split all costs 50 - 50 . ia ##m concerned that she and i have fundamentally different attitudes toward money and also that we have fundamentally different attitudes toward communication as i think she should have spoken up when i first proposed splitting 50 - 50 not waited until after the vacation was over . first vacation ##er : ia ##m definitely with you on the communication problem . yes it would have helped for her to say something beforehand a if in fact she had doubts then . but even if she wasn ##at sure till she actually saw what you meant by a ##50 - 50 a then speaking up on the spot would have been the more productive thing to do : ah ##ey when you said 50 - 50 i thought you meant we ##ad share expenses a but i wasn ##at expecting that we ##ad split every meal down to the loose change . a she did eventually speak up though so you have that . use it by responding honestly with your concerns . say you wish she had said something as soon as this bothered her and ask if there ##as a reason she didn ##at . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 6203 15611 1024 2026 6513 1998 1045 2074 2253 2006 2256 2034 10885 2362 1012 1045 2245 2009 2253 2092 2021 2044 2057 2020 2188 2016 2409 2033 2016 2371 1045 2018 2042 10036 2138 1045 2359 2000 3975 2035 5366 2753 1011 2753 1012 24264 2213 4986 2008 2016 1998 1045 2031 24670 2367 13818 2646 2769 1998 2036 2008 2057 2031 24670 2367 13818 2646 4807 2004 1045 2228 2016 2323 2031 5287 2039 2043 1045 2034 3818 14541 2753 1011 2753 2025 4741 2127 2044 1996 10885 2001 2058 1012 2034 10885 2121 1024 24264 2213 5791 2007 2017 2006 1996 4807 3291 1012 2748 2009 2052 2031 3271 2005 2014 2000 2360 2242 25828 1037 2065 1999 2755 2016 2018 13579 2059 1012 2021 2130 2065 2016 2347 4017 2469 6229 2016 2941 2387 2054 2017 3214 2011 1037 12376 1011 2753 1037 2059 4092 2039 2006 1996 3962 2052 2031 2042 1996 2062 13318 2518 2000 2079 1024 6289 3240 2043 2017 2056 2753 1011 2753 1045 2245 2017 3214 2057 4215 3745 11727 1037 2021 1045 2347 4017 8074 2008 2057 4215 3975 2296 7954 2091 2000 1996 6065 2689 1012 1037 2016 2106 2776 3713 2039 2295 2061 2017 2031 2008 1012 2224 2009 2011 14120 9826 2007 2115 5936 1012 2360 2017 4299 2016 2018 2056 2242 2004 2574 2004 2023 11250 2014 1998 3198 2065 2045 3022 1037 3114 2016 2134 4017 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.881757 140083176642432 run_classifier.py:465] input_ids: 101 6203 15611 1024 2026 6513 1998 1045 2074 2253 2006 2256 2034 10885 2362 1012 1045 2245 2009 2253 2092 2021 2044 2057 2020 2188 2016 2409 2033 2016 2371 1045 2018 2042 10036 2138 1045 2359 2000 3975 2035 5366 2753 1011 2753 1012 24264 2213 4986 2008 2016 1998 1045 2031 24670 2367 13818 2646 2769 1998 2036 2008 2057 2031 24670 2367 13818 2646 4807 2004 1045 2228 2016 2323 2031 5287 2039 2043 1045 2034 3818 14541 2753 1011 2753 2025 4741 2127 2044 1996 10885 2001 2058 1012 2034 10885 2121 1024 24264 2213 5791 2007 2017 2006 1996 4807 3291 1012 2748 2009 2052 2031 3271 2005 2014 2000 2360 2242 25828 1037 2065 1999 2755 2016 2018 13579 2059 1012 2021 2130 2065 2016 2347 4017 2469 6229 2016 2941 2387 2054 2017 3214 2011 1037 12376 1011 2753 1037 2059 4092 2039 2006 1996 3962 2052 2031 2042 1996 2062 13318 2518 2000 2079 1024 6289 3240 2043 2017 2056 2753 1011 2753 1045 2245 2017 3214 2057 4215 3745 11727 1037 2021 1045 2347 4017 8074 2008 2057 4215 3975 2296 7954 2091 2000 1996 6065 2689 1012 1037 2016 2106 2776 3713 2039 2295 2061 2017 2031 2008 1012 2224 2009 2011 14120 9826 2007 2115 5936 1012 2360 2017 4299 2016 2018 2056 2242 2004 2574 2004 2023 11250 2014 1998 3198 2065 2045 3022 1037 3114 2016 2134 4017 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.885163 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.888050 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:53.890279 140083176642432 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.482656 140083176642432 run_classifier.py:774] Writing example 0 of 285\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.508033 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.511919 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the inspector general for the interior department has opened an investigation into [ t ##gt ] travel during seven months in office from [ t ##gt ] use of taxpayer - funded charter and military planes to [ t ##gt ] mixing of official trips with political appearances . nancy k . dip ##ao ##lo a spokesperson for deputy inspector general mary kendall described a broad investigation into z ##ink ##e as at ##rave ##l in general a including am ##odes of travel costs and [ t ##gt ] speaks during a white house briefing in april . ( ja ##bin bot ##sford / the washington post ) the flight cost taxpayers $ 12 375 according to an interior department spoke ##sw ##oman . commercial airlines run daily flights between the two airports and charge as little as $ 300 . [ t ##gt ] as spoke ##sw ##oman heather swift said no commercial flight was available that would have worked with his schedule that night . [ t ##gt ] appeared at an event held by a major campaign donor giving a motivation ##al speech at a dinner for the las vegas golden knights a hockey team owned by bill foley the chairman of fidelity national financial . employees and pac ##s associated with the financial services company have given close to $ 200 000 to z ##ink ##e as past congressional campaigns . ac ##lai ##ms that the secretary ##as full schedule required the use of chartered aircraft deserve scrutiny a the law ##makers wrote in a letter to kendall last week . ai ##t appears as though secretary z ##ink ##e and his staff could have taken a commercial flight from las vegas to montana if he did not attend the motivation ##al speech to the hockey team owned by his friend and campaign contributor . a [ t ##gt ] was in the las vegas area that day after flying on a commercial southwest airlines jet from reno ne ##v . where [ t ##gt ] spoke the night before at a nearby dinner in lake ta ##hoe held by the rule of law defense fund a conservative group of attorneys general backed by the koch brothers . just before the golden knights dinner [ t ##gt ] had appeared in the tiny rural nevada town of pa ##hr ##ump to announce a routine local funding grant from congress to rural communities . it was one of several official trips that coincided with weekends [ t ##gt ] spent at [ t ##gt ] homes in santa barbara cal ##if . and montana . the secretary and [ t ##gt ] official entourage also boarded private flights between the caribbean islands of st . thomas and st . croix during a three - day trip to the virgin islands in march [ t ##gt ] first month on the job . swift said [ t ##gt ] as charter flights were authorized by ethics officials and booked only when feasible commercial flights were unavailable . she [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.518064 140083176642432 run_classifier.py:464] tokens: [CLS] the inspector general for the interior department has opened an investigation into [ t ##gt ] travel during seven months in office from [ t ##gt ] use of taxpayer - funded charter and military planes to [ t ##gt ] mixing of official trips with political appearances . nancy k . dip ##ao ##lo a spokesperson for deputy inspector general mary kendall described a broad investigation into z ##ink ##e as at ##rave ##l in general a including am ##odes of travel costs and [ t ##gt ] speaks during a white house briefing in april . ( ja ##bin bot ##sford / the washington post ) the flight cost taxpayers $ 12 375 according to an interior department spoke ##sw ##oman . commercial airlines run daily flights between the two airports and charge as little as $ 300 . [ t ##gt ] as spoke ##sw ##oman heather swift said no commercial flight was available that would have worked with his schedule that night . [ t ##gt ] appeared at an event held by a major campaign donor giving a motivation ##al speech at a dinner for the las vegas golden knights a hockey team owned by bill foley the chairman of fidelity national financial . employees and pac ##s associated with the financial services company have given close to $ 200 000 to z ##ink ##e as past congressional campaigns . ac ##lai ##ms that the secretary ##as full schedule required the use of chartered aircraft deserve scrutiny a the law ##makers wrote in a letter to kendall last week . ai ##t appears as though secretary z ##ink ##e and his staff could have taken a commercial flight from las vegas to montana if he did not attend the motivation ##al speech to the hockey team owned by his friend and campaign contributor . a [ t ##gt ] was in the las vegas area that day after flying on a commercial southwest airlines jet from reno ne ##v . where [ t ##gt ] spoke the night before at a nearby dinner in lake ta ##hoe held by the rule of law defense fund a conservative group of attorneys general backed by the koch brothers . just before the golden knights dinner [ t ##gt ] had appeared in the tiny rural nevada town of pa ##hr ##ump to announce a routine local funding grant from congress to rural communities . it was one of several official trips that coincided with weekends [ t ##gt ] spent at [ t ##gt ] homes in santa barbara cal ##if . and montana . the secretary and [ t ##gt ] official entourage also boarded private flights between the caribbean islands of st . thomas and st . croix during a three - day trip to the virgin islands in march [ t ##gt ] first month on the job . swift said [ t ##gt ] as charter flights were authorized by ethics officials and booked only when feasible commercial flights were unavailable . she [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 7742 2236 2005 1996 4592 2533 2038 2441 2019 4812 2046 1031 1056 13512 1033 3604 2076 2698 2706 1999 2436 2013 1031 1056 13512 1033 2224 1997 26980 1011 6787 6111 1998 2510 9738 2000 1031 1056 13512 1033 6809 1997 2880 9109 2007 2576 3922 1012 7912 1047 1012 16510 7113 4135 1037 15974 2005 4112 7742 2236 2984 14509 2649 1037 5041 4812 2046 1062 19839 2063 2004 2012 22401 2140 1999 2236 1037 2164 2572 19847 1997 3604 5366 1998 1031 1056 13512 1033 8847 2076 1037 2317 2160 27918 1999 2258 1012 1006 14855 8428 28516 17658 1013 1996 2899 2695 1007 1996 3462 3465 26457 1002 2260 18034 2429 2000 2019 4592 2533 3764 26760 20778 1012 3293 7608 2448 3679 7599 2090 1996 2048 13586 1998 3715 2004 2210 2004 1002 3998 1012 1031 1056 13512 1033 2004 3764 26760 20778 9533 9170 2056 2053 3293 3462 2001 2800 2008 2052 2031 2499 2007 2010 6134 2008 2305 1012 1031 1056 13512 1033 2596 2012 2019 2724 2218 2011 1037 2350 3049 15009 3228 1037 14354 2389 4613 2012 1037 4596 2005 1996 5869 7136 3585 7307 1037 3873 2136 3079 2011 3021 17106 1996 3472 1997 22625 2120 3361 1012 5126 1998 14397 2015 3378 2007 1996 3361 2578 2194 2031 2445 2485 2000 1002 3263 2199 2000 1062 19839 2063 2004 2627 7740 8008 1012 9353 19771 5244 2008 1996 3187 3022 2440 6134 3223 1996 2224 1997 12443 2948 10107 17423 1037 1996 2375 12088 2626 1999 1037 3661 2000 14509 2197 2733 1012 9932 2102 3544 2004 2295 3187 1062 19839 2063 1998 2010 3095 2071 2031 2579 1037 3293 3462 2013 5869 7136 2000 8124 2065 2002 2106 2025 5463 1996 14354 2389 4613 2000 1996 3873 2136 3079 2011 2010 2767 1998 3049 12130 1012 1037 1031 1056 13512 1033 2001 1999 1996 5869 7136 2181 2008 2154 2044 3909 2006 1037 3293 4943 7608 6892 2013 17738 11265 2615 1012 2073 1031 1056 13512 1033 3764 1996 2305 2077 2012 1037 3518 4596 1999 2697 11937 14490 2218 2011 1996 3627 1997 2375 3639 4636 1037 4603 2177 1997 16214 2236 6153 2011 1996 15259 3428 1012 2074 2077 1996 3585 7307 4596 1031 1056 13512 1033 2018 2596 1999 1996 4714 3541 7756 2237 1997 6643 8093 24237 2000 14970 1037 9410 2334 4804 3946 2013 3519 2000 3541 4279 1012 2009 2001 2028 1997 2195 2880 9109 2008 18616 2007 13499 1031 1056 13512 1033 2985 2012 1031 1056 13512 1033 5014 1999 4203 6437 10250 10128 1012 1998 8124 1012 1996 3187 1998 1031 1056 13512 1033 2880 25342 2036 17383 2797 7599 2090 1996 7139 3470 1997 2358 1012 2726 1998 2358 1012 18733 2076 1037 2093 1011 2154 4440 2000 1996 6261 3470 1999 2233 1031 1056 13512 1033 2034 3204 2006 1996 3105 1012 9170 2056 1031 1056 13512 1033 2004 6111 7599 2020 9362 2011 9615 4584 1998 17414 2069 2043 22945 3293 7599 2020 20165 1012 2016 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.523682 140083176642432 run_classifier.py:465] input_ids: 101 1996 7742 2236 2005 1996 4592 2533 2038 2441 2019 4812 2046 1031 1056 13512 1033 3604 2076 2698 2706 1999 2436 2013 1031 1056 13512 1033 2224 1997 26980 1011 6787 6111 1998 2510 9738 2000 1031 1056 13512 1033 6809 1997 2880 9109 2007 2576 3922 1012 7912 1047 1012 16510 7113 4135 1037 15974 2005 4112 7742 2236 2984 14509 2649 1037 5041 4812 2046 1062 19839 2063 2004 2012 22401 2140 1999 2236 1037 2164 2572 19847 1997 3604 5366 1998 1031 1056 13512 1033 8847 2076 1037 2317 2160 27918 1999 2258 1012 1006 14855 8428 28516 17658 1013 1996 2899 2695 1007 1996 3462 3465 26457 1002 2260 18034 2429 2000 2019 4592 2533 3764 26760 20778 1012 3293 7608 2448 3679 7599 2090 1996 2048 13586 1998 3715 2004 2210 2004 1002 3998 1012 1031 1056 13512 1033 2004 3764 26760 20778 9533 9170 2056 2053 3293 3462 2001 2800 2008 2052 2031 2499 2007 2010 6134 2008 2305 1012 1031 1056 13512 1033 2596 2012 2019 2724 2218 2011 1037 2350 3049 15009 3228 1037 14354 2389 4613 2012 1037 4596 2005 1996 5869 7136 3585 7307 1037 3873 2136 3079 2011 3021 17106 1996 3472 1997 22625 2120 3361 1012 5126 1998 14397 2015 3378 2007 1996 3361 2578 2194 2031 2445 2485 2000 1002 3263 2199 2000 1062 19839 2063 2004 2627 7740 8008 1012 9353 19771 5244 2008 1996 3187 3022 2440 6134 3223 1996 2224 1997 12443 2948 10107 17423 1037 1996 2375 12088 2626 1999 1037 3661 2000 14509 2197 2733 1012 9932 2102 3544 2004 2295 3187 1062 19839 2063 1998 2010 3095 2071 2031 2579 1037 3293 3462 2013 5869 7136 2000 8124 2065 2002 2106 2025 5463 1996 14354 2389 4613 2000 1996 3873 2136 3079 2011 2010 2767 1998 3049 12130 1012 1037 1031 1056 13512 1033 2001 1999 1996 5869 7136 2181 2008 2154 2044 3909 2006 1037 3293 4943 7608 6892 2013 17738 11265 2615 1012 2073 1031 1056 13512 1033 3764 1996 2305 2077 2012 1037 3518 4596 1999 2697 11937 14490 2218 2011 1996 3627 1997 2375 3639 4636 1037 4603 2177 1997 16214 2236 6153 2011 1996 15259 3428 1012 2074 2077 1996 3585 7307 4596 1031 1056 13512 1033 2018 2596 1999 1996 4714 3541 7756 2237 1997 6643 8093 24237 2000 14970 1037 9410 2334 4804 3946 2013 3519 2000 3541 4279 1012 2009 2001 2028 1997 2195 2880 9109 2008 18616 2007 13499 1031 1056 13512 1033 2985 2012 1031 1056 13512 1033 5014 1999 4203 6437 10250 10128 1012 1998 8124 1012 1996 3187 1998 1031 1056 13512 1033 2880 25342 2036 17383 2797 7599 2090 1996 7139 3470 1997 2358 1012 2726 1998 2358 1012 18733 2076 1037 2093 1011 2154 4440 2000 1996 6261 3470 1999 2233 1031 1056 13512 1033 2034 3204 2006 1996 3105 1012 9170 2056 1031 1056 13512 1033 2004 6111 7599 2020 9362 2011 9615 4584 1998 17414 2069 2043 22945 3293 7599 2020 20165 1012 2016 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.527282 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.533283 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.536725 140083176642432 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.589118 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.591449 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] dubai / london ( reuters ) - british foreign secretary boris johnson held almost an hour of talks with iranian president hassan ro ##uh ##ani on sunday after flying to tehran to seek the release of a jailed british - iranian aid worker . [ t ##gt ] meets with iranian president hassan ro ##uh ##ani in tehran iran december 10 2017 . president . ir / hand ##out via reuters ab ##oth spoke forth ##right ##ly about the obstacles in the relationship and agreed on the need to make progress in all areas a said a spoke ##sw ##oman for britain ##as foreign office after [ t ##gt ] concluded what was only the third visit to iran by a british foreign minister in the past 14 years . [ t ##gt ] met ali akbar sale ##hi head of iran ##as atomic energy organization earlier on sunday . on saturday [ t ##gt ] had talks with [ t ##gt ] iranian counterpart mohammad java ##d za ##ri ##f about ac ##ons ##ular cases of dual nationals ##a such as na ##zan ##in za ##gh ##ari - rat ##cliffe who britain says was visiting family on holiday when she was jailed by iran for attempting to overthrow the government . the case has taken on domestic political importance after [ t ##gt ] said last month that za ##gh ##ari - rat ##cliffe trained journalists which her employer denies . [ t ##gt ] later apologized . opponents have called for [ t ##gt ] to resign if [ t ##gt ] comments lead to her serving longer in prison . [ t ##gt ] meets with iranian president hassan ro ##uh ##ani in tehran iran december 10 2017 . president . ir / hand ##out via reuters that deal is under threat after u . s . president donald trump decided to dec ##ert ##ify iran ##as compliance with its terms . [ t ##gt ] told za ##ri ##f [ t ##gt ] believed the deal should be fully implemented . the foreign office did not mention za ##gh ##ari - rat ##cliffe by name although [ t ##gt ] has vowed to leave an ##o stone un ##turn ##eda in britain ##as efforts to free her . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.593847 140083176642432 run_classifier.py:464] tokens: [CLS] dubai / london ( reuters ) - british foreign secretary boris johnson held almost an hour of talks with iranian president hassan ro ##uh ##ani on sunday after flying to tehran to seek the release of a jailed british - iranian aid worker . [ t ##gt ] meets with iranian president hassan ro ##uh ##ani in tehran iran december 10 2017 . president . ir / hand ##out via reuters ab ##oth spoke forth ##right ##ly about the obstacles in the relationship and agreed on the need to make progress in all areas a said a spoke ##sw ##oman for britain ##as foreign office after [ t ##gt ] concluded what was only the third visit to iran by a british foreign minister in the past 14 years . [ t ##gt ] met ali akbar sale ##hi head of iran ##as atomic energy organization earlier on sunday . on saturday [ t ##gt ] had talks with [ t ##gt ] iranian counterpart mohammad java ##d za ##ri ##f about ac ##ons ##ular cases of dual nationals ##a such as na ##zan ##in za ##gh ##ari - rat ##cliffe who britain says was visiting family on holiday when she was jailed by iran for attempting to overthrow the government . the case has taken on domestic political importance after [ t ##gt ] said last month that za ##gh ##ari - rat ##cliffe trained journalists which her employer denies . [ t ##gt ] later apologized . opponents have called for [ t ##gt ] to resign if [ t ##gt ] comments lead to her serving longer in prison . [ t ##gt ] meets with iranian president hassan ro ##uh ##ani in tehran iran december 10 2017 . president . ir / hand ##out via reuters that deal is under threat after u . s . president donald trump decided to dec ##ert ##ify iran ##as compliance with its terms . [ t ##gt ] told za ##ri ##f [ t ##gt ] believed the deal should be fully implemented . the foreign office did not mention za ##gh ##ari - rat ##cliffe by name although [ t ##gt ] has vowed to leave an ##o stone un ##turn ##eda in britain ##as efforts to free her . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 11558 1013 2414 1006 26665 1007 1011 2329 3097 3187 11235 3779 2218 2471 2019 3178 1997 7566 2007 7726 2343 13222 20996 27225 7088 2006 4465 2044 3909 2000 13503 2000 6148 1996 2713 1997 1037 21278 2329 1011 7726 4681 7309 1012 1031 1056 13512 1033 6010 2007 7726 2343 13222 20996 27225 7088 1999 13503 4238 2285 2184 2418 1012 2343 1012 20868 1013 2192 5833 3081 26665 11113 14573 3764 5743 15950 2135 2055 1996 15314 1999 1996 3276 1998 3530 2006 1996 2342 2000 2191 5082 1999 2035 2752 1037 2056 1037 3764 26760 20778 2005 3725 3022 3097 2436 2044 1031 1056 13512 1033 5531 2054 2001 2069 1996 2353 3942 2000 4238 2011 1037 2329 3097 2704 1999 1996 2627 2403 2086 1012 1031 1056 13512 1033 2777 4862 20730 5096 4048 2132 1997 4238 3022 9593 2943 3029 3041 2006 4465 1012 2006 5095 1031 1056 13512 1033 2018 7566 2007 1031 1056 13512 1033 7726 13637 12050 9262 2094 23564 3089 2546 2055 9353 5644 7934 3572 1997 7037 10342 2050 2107 2004 6583 13471 2378 23564 5603 8486 1011 9350 18115 2040 3725 2758 2001 5873 2155 2006 6209 2043 2016 2001 21278 2011 4238 2005 7161 2000 16857 1996 2231 1012 1996 2553 2038 2579 2006 4968 2576 5197 2044 1031 1056 13512 1033 2056 2197 3204 2008 23564 5603 8486 1011 9350 18115 4738 8845 2029 2014 11194 23439 1012 1031 1056 13512 1033 2101 17806 1012 7892 2031 2170 2005 1031 1056 13512 1033 2000 12897 2065 1031 1056 13512 1033 7928 2599 2000 2014 3529 2936 1999 3827 1012 1031 1056 13512 1033 6010 2007 7726 2343 13222 20996 27225 7088 1999 13503 4238 2285 2184 2418 1012 2343 1012 20868 1013 2192 5833 3081 26665 2008 3066 2003 2104 5081 2044 1057 1012 1055 1012 2343 6221 8398 2787 2000 11703 8743 8757 4238 3022 12646 2007 2049 3408 1012 1031 1056 13512 1033 2409 23564 3089 2546 1031 1056 13512 1033 3373 1996 3066 2323 2022 3929 7528 1012 1996 3097 2436 2106 2025 5254 23564 5603 8486 1011 9350 18115 2011 2171 2348 1031 1056 13512 1033 2038 18152 2000 2681 2019 2080 2962 4895 22299 11960 1999 3725 3022 4073 2000 2489 2014 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.595957 140083176642432 run_classifier.py:465] input_ids: 101 11558 1013 2414 1006 26665 1007 1011 2329 3097 3187 11235 3779 2218 2471 2019 3178 1997 7566 2007 7726 2343 13222 20996 27225 7088 2006 4465 2044 3909 2000 13503 2000 6148 1996 2713 1997 1037 21278 2329 1011 7726 4681 7309 1012 1031 1056 13512 1033 6010 2007 7726 2343 13222 20996 27225 7088 1999 13503 4238 2285 2184 2418 1012 2343 1012 20868 1013 2192 5833 3081 26665 11113 14573 3764 5743 15950 2135 2055 1996 15314 1999 1996 3276 1998 3530 2006 1996 2342 2000 2191 5082 1999 2035 2752 1037 2056 1037 3764 26760 20778 2005 3725 3022 3097 2436 2044 1031 1056 13512 1033 5531 2054 2001 2069 1996 2353 3942 2000 4238 2011 1037 2329 3097 2704 1999 1996 2627 2403 2086 1012 1031 1056 13512 1033 2777 4862 20730 5096 4048 2132 1997 4238 3022 9593 2943 3029 3041 2006 4465 1012 2006 5095 1031 1056 13512 1033 2018 7566 2007 1031 1056 13512 1033 7726 13637 12050 9262 2094 23564 3089 2546 2055 9353 5644 7934 3572 1997 7037 10342 2050 2107 2004 6583 13471 2378 23564 5603 8486 1011 9350 18115 2040 3725 2758 2001 5873 2155 2006 6209 2043 2016 2001 21278 2011 4238 2005 7161 2000 16857 1996 2231 1012 1996 2553 2038 2579 2006 4968 2576 5197 2044 1031 1056 13512 1033 2056 2197 3204 2008 23564 5603 8486 1011 9350 18115 4738 8845 2029 2014 11194 23439 1012 1031 1056 13512 1033 2101 17806 1012 7892 2031 2170 2005 1031 1056 13512 1033 2000 12897 2065 1031 1056 13512 1033 7928 2599 2000 2014 3529 2936 1999 3827 1012 1031 1056 13512 1033 6010 2007 7726 2343 13222 20996 27225 7088 1999 13503 4238 2285 2184 2418 1012 2343 1012 20868 1013 2192 5833 3081 26665 2008 3066 2003 2104 5081 2044 1057 1012 1055 1012 2343 6221 8398 2787 2000 11703 8743 8757 4238 3022 12646 2007 2049 3408 1012 1031 1056 13512 1033 2409 23564 3089 2546 1031 1056 13512 1033 3373 1996 3066 2323 2022 3929 7528 1012 1996 3097 2436 2106 2025 5254 23564 5603 8486 1011 9350 18115 2011 2171 2348 1031 1056 13512 1033 2038 18152 2000 2681 2019 2080 2962 4895 22299 11960 1999 3725 3022 4073 2000 2489 2014 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.598026 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.599942 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.601628 140083176642432 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.611067 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.613452 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] [ t ##gt ] made a secret appearance on ' top gear ' - and even got behind the wheel . the royal was filmed driving when jeremy clarkson richard hammond and james may were running the show . but the clip was kept under wraps with only a select few knowing [ t ##gt ] was in shot . according to show [ t ##gt ] turned up at the track one day during filming . [ t ##gt ] was \" standing around having a cup of tea \" when clarkson said [ t ##gt ] could have a go . and [ t ##gt ] told sunday times driving : \" [ t ##gt ] was really good but if i tell you which film ia ##ll be beheaded . \" so is the newly - engaged prince harry leaving his wife - to - be meg ##han mark ##le for the day to film on the grand tour ? with series two already wrapped up hammond and may think [ t ##gt ] ' s probably going to be too busy in the coming months - although they ' ve haven ' t ruled out a future guest appearance . ai think [ t ##gt ] as probably busy a said hammond . aa ##ls ##o let ##as be honest [ t ##gt ] probably has better things to do . a ai ##tas difficult to imagine [ t ##gt ] wouldn ##at have better things to do a joked may . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.615772 140083176642432 run_classifier.py:464] tokens: [CLS] [ t ##gt ] made a secret appearance on ' top gear ' - and even got behind the wheel . the royal was filmed driving when jeremy clarkson richard hammond and james may were running the show . but the clip was kept under wraps with only a select few knowing [ t ##gt ] was in shot . according to show [ t ##gt ] turned up at the track one day during filming . [ t ##gt ] was \" standing around having a cup of tea \" when clarkson said [ t ##gt ] could have a go . and [ t ##gt ] told sunday times driving : \" [ t ##gt ] was really good but if i tell you which film ia ##ll be beheaded . \" so is the newly - engaged prince harry leaving his wife - to - be meg ##han mark ##le for the day to film on the grand tour ? with series two already wrapped up hammond and may think [ t ##gt ] ' s probably going to be too busy in the coming months - although they ' ve haven ' t ruled out a future guest appearance . ai think [ t ##gt ] as probably busy a said hammond . aa ##ls ##o let ##as be honest [ t ##gt ] probably has better things to do . a ai ##tas difficult to imagine [ t ##gt ] wouldn ##at have better things to do a joked may . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1031 1056 13512 1033 2081 1037 3595 3311 2006 1005 2327 6718 1005 1011 1998 2130 2288 2369 1996 5217 1012 1996 2548 2001 6361 4439 2043 7441 18648 2957 11309 1998 2508 2089 2020 2770 1996 2265 1012 2021 1996 12528 2001 2921 2104 19735 2007 2069 1037 7276 2261 4209 1031 1056 13512 1033 2001 1999 2915 1012 2429 2000 2265 1031 1056 13512 1033 2357 2039 2012 1996 2650 2028 2154 2076 7467 1012 1031 1056 13512 1033 2001 1000 3061 2105 2383 1037 2452 1997 5572 1000 2043 18648 2056 1031 1056 13512 1033 2071 2031 1037 2175 1012 1998 1031 1056 13512 1033 2409 4465 2335 4439 1024 1000 1031 1056 13512 1033 2001 2428 2204 2021 2065 1045 2425 2017 2029 2143 24264 3363 2022 28923 1012 1000 2061 2003 1996 4397 1011 5117 3159 4302 2975 2010 2564 1011 2000 1011 2022 12669 4819 2928 2571 2005 1996 2154 2000 2143 2006 1996 2882 2778 1029 2007 2186 2048 2525 5058 2039 11309 1998 2089 2228 1031 1056 13512 1033 1005 1055 2763 2183 2000 2022 2205 5697 1999 1996 2746 2706 1011 2348 2027 1005 2310 4033 1005 1056 5451 2041 1037 2925 4113 3311 1012 9932 2228 1031 1056 13512 1033 2004 2763 5697 1037 2056 11309 1012 9779 4877 2080 2292 3022 2022 7481 1031 1056 13512 1033 2763 2038 2488 2477 2000 2079 1012 1037 9932 10230 3697 2000 5674 1031 1056 13512 1033 2876 4017 2031 2488 2477 2000 2079 1037 19700 2089 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.618002 140083176642432 run_classifier.py:465] input_ids: 101 1031 1056 13512 1033 2081 1037 3595 3311 2006 1005 2327 6718 1005 1011 1998 2130 2288 2369 1996 5217 1012 1996 2548 2001 6361 4439 2043 7441 18648 2957 11309 1998 2508 2089 2020 2770 1996 2265 1012 2021 1996 12528 2001 2921 2104 19735 2007 2069 1037 7276 2261 4209 1031 1056 13512 1033 2001 1999 2915 1012 2429 2000 2265 1031 1056 13512 1033 2357 2039 2012 1996 2650 2028 2154 2076 7467 1012 1031 1056 13512 1033 2001 1000 3061 2105 2383 1037 2452 1997 5572 1000 2043 18648 2056 1031 1056 13512 1033 2071 2031 1037 2175 1012 1998 1031 1056 13512 1033 2409 4465 2335 4439 1024 1000 1031 1056 13512 1033 2001 2428 2204 2021 2065 1045 2425 2017 2029 2143 24264 3363 2022 28923 1012 1000 2061 2003 1996 4397 1011 5117 3159 4302 2975 2010 2564 1011 2000 1011 2022 12669 4819 2928 2571 2005 1996 2154 2000 2143 2006 1996 2882 2778 1029 2007 2186 2048 2525 5058 2039 11309 1998 2089 2228 1031 1056 13512 1033 1005 1055 2763 2183 2000 2022 2205 5697 1999 1996 2746 2706 1011 2348 2027 1005 2310 4033 1005 1056 5451 2041 1037 2925 4113 3311 1012 9932 2228 1031 1056 13512 1033 2004 2763 5697 1037 2056 11309 1012 9779 4877 2080 2292 3022 2022 7481 1031 1056 13512 1033 2763 2038 2488 2477 2000 2079 1012 1037 9932 10230 3697 2000 5674 1031 1056 13512 1033 2876 4017 2031 2488 2477 2000 2079 1037 19700 2089 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.620033 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.621923 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.627230 140083176642432 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.644783 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.647514 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] well hello op ##rah ! the kennedy center announced tuesday that [ t ##gt ] the do ##yen ##ne of daytime television will be among the five artists receiving this year ' s kennedy center honors . ! the kennedy center announced tuesday that [ t ##gt ] the do ##yen ##ne of daytime television will be among the five artists receiving this year ' s kennedy center honors . the selection of [ t ##gt ] may be startling but it ' s not without precedent . the choice ha ##rks back to 1993 when late - night television host johnny carson was selected breaking the long line of honor ##ees who were strictly traditional performing artists . [ t ##gt ] taking a break from tap ##ing for [ t ##gt ] 25th season and reviewing the nearly 5 000 hours of footage let out with a bu ##oya ##nt \" wow - zee ! \" [ t ##gt ] explained \" this feels like an official american citizenship in a very exclusive club of artists and contributors to the nation in a very special way . it feels like an elevated kind of award and there aren ' t many in this category . they look at your work your life work who you are as a human being and the spirit of who you are as a human being . not many honors look at that depth . \" the 2010 lineup is an ideal op ##rah - esq ##ue round table . each chosen artist ' s life has been brushed by hardship and tragedy . [ t ##gt ] 56 has talked about her own teenage abuse and homeless ##ness . but she found a niche in the news business working as an anchor in nashville and baltimore where she had her first talk show . she is now one of the most successful and wealthiest business executives with her own network debuting in january . her acting credits include an oscar nomination for her work in \" the color purple . \" she later produced the broadway musical based on the \" purple \" movie and book and produced and starred in the film \" beloved . \" in the business world [ t ##gt ] is credited with helping to revive the book industry with her on - air book club which will resume this month . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.650409 140083176642432 run_classifier.py:464] tokens: [CLS] well hello op ##rah ! the kennedy center announced tuesday that [ t ##gt ] the do ##yen ##ne of daytime television will be among the five artists receiving this year ' s kennedy center honors . ! the kennedy center announced tuesday that [ t ##gt ] the do ##yen ##ne of daytime television will be among the five artists receiving this year ' s kennedy center honors . the selection of [ t ##gt ] may be startling but it ' s not without precedent . the choice ha ##rks back to 1993 when late - night television host johnny carson was selected breaking the long line of honor ##ees who were strictly traditional performing artists . [ t ##gt ] taking a break from tap ##ing for [ t ##gt ] 25th season and reviewing the nearly 5 000 hours of footage let out with a bu ##oya ##nt \" wow - zee ! \" [ t ##gt ] explained \" this feels like an official american citizenship in a very exclusive club of artists and contributors to the nation in a very special way . it feels like an elevated kind of award and there aren ' t many in this category . they look at your work your life work who you are as a human being and the spirit of who you are as a human being . not many honors look at that depth . \" the 2010 lineup is an ideal op ##rah - esq ##ue round table . each chosen artist ' s life has been brushed by hardship and tragedy . [ t ##gt ] 56 has talked about her own teenage abuse and homeless ##ness . but she found a niche in the news business working as an anchor in nashville and baltimore where she had her first talk show . she is now one of the most successful and wealthiest business executives with her own network debuting in january . her acting credits include an oscar nomination for her work in \" the color purple . \" she later produced the broadway musical based on the \" purple \" movie and book and produced and starred in the film \" beloved . \" in the business world [ t ##gt ] is credited with helping to revive the book industry with her on - air book club which will resume this month . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2092 7592 6728 10404 999 1996 5817 2415 2623 9857 2008 1031 1056 13512 1033 1996 2079 20684 2638 1997 12217 2547 2097 2022 2426 1996 2274 3324 4909 2023 2095 1005 1055 5817 2415 7836 1012 999 1996 5817 2415 2623 9857 2008 1031 1056 13512 1033 1996 2079 20684 2638 1997 12217 2547 2097 2022 2426 1996 2274 3324 4909 2023 2095 1005 1055 5817 2415 7836 1012 1996 4989 1997 1031 1056 13512 1033 2089 2022 19828 2021 2009 1005 1055 2025 2302 20056 1012 1996 3601 5292 19987 2067 2000 2857 2043 2397 1011 2305 2547 3677 5206 9806 2001 3479 4911 1996 2146 2240 1997 3932 10285 2040 2020 9975 3151 4488 3324 1012 1031 1056 13512 1033 2635 1037 3338 2013 11112 2075 2005 1031 1056 13512 1033 10965 2161 1998 15252 1996 3053 1019 2199 2847 1997 8333 2292 2041 2007 1037 20934 18232 3372 1000 10166 1011 23727 999 1000 1031 1056 13512 1033 4541 1000 2023 5683 2066 2019 2880 2137 9068 1999 1037 2200 7262 2252 1997 3324 1998 16884 2000 1996 3842 1999 1037 2200 2569 2126 1012 2009 5683 2066 2019 8319 2785 1997 2400 1998 2045 4995 1005 1056 2116 1999 2023 4696 1012 2027 2298 2012 2115 2147 2115 2166 2147 2040 2017 2024 2004 1037 2529 2108 1998 1996 4382 1997 2040 2017 2024 2004 1037 2529 2108 1012 2025 2116 7836 2298 2012 2008 5995 1012 1000 1996 2230 10515 2003 2019 7812 6728 10404 1011 25325 5657 2461 2795 1012 2169 4217 3063 1005 1055 2166 2038 2042 7765 2011 26479 1998 10576 1012 1031 1056 13512 1033 5179 2038 5720 2055 2014 2219 9454 6905 1998 11573 2791 1012 2021 2016 2179 1037 18111 1999 1996 2739 2449 2551 2004 2019 8133 1999 8423 1998 6222 2073 2016 2018 2014 2034 2831 2265 1012 2016 2003 2085 2028 1997 1996 2087 3144 1998 27809 2449 12706 2007 2014 2219 2897 24469 1999 2254 1012 2014 3772 6495 2421 2019 7436 6488 2005 2014 2147 1999 1000 1996 3609 6379 1012 1000 2016 2101 2550 1996 5934 3315 2241 2006 1996 1000 6379 1000 3185 1998 2338 1998 2550 1998 5652 1999 1996 2143 1000 11419 1012 1000 1999 1996 2449 2088 1031 1056 13512 1033 2003 5827 2007 5094 2000 17995 1996 2338 3068 2007 2014 2006 1011 2250 2338 2252 2029 2097 13746 2023 3204 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.652936 140083176642432 run_classifier.py:465] input_ids: 101 2092 7592 6728 10404 999 1996 5817 2415 2623 9857 2008 1031 1056 13512 1033 1996 2079 20684 2638 1997 12217 2547 2097 2022 2426 1996 2274 3324 4909 2023 2095 1005 1055 5817 2415 7836 1012 999 1996 5817 2415 2623 9857 2008 1031 1056 13512 1033 1996 2079 20684 2638 1997 12217 2547 2097 2022 2426 1996 2274 3324 4909 2023 2095 1005 1055 5817 2415 7836 1012 1996 4989 1997 1031 1056 13512 1033 2089 2022 19828 2021 2009 1005 1055 2025 2302 20056 1012 1996 3601 5292 19987 2067 2000 2857 2043 2397 1011 2305 2547 3677 5206 9806 2001 3479 4911 1996 2146 2240 1997 3932 10285 2040 2020 9975 3151 4488 3324 1012 1031 1056 13512 1033 2635 1037 3338 2013 11112 2075 2005 1031 1056 13512 1033 10965 2161 1998 15252 1996 3053 1019 2199 2847 1997 8333 2292 2041 2007 1037 20934 18232 3372 1000 10166 1011 23727 999 1000 1031 1056 13512 1033 4541 1000 2023 5683 2066 2019 2880 2137 9068 1999 1037 2200 7262 2252 1997 3324 1998 16884 2000 1996 3842 1999 1037 2200 2569 2126 1012 2009 5683 2066 2019 8319 2785 1997 2400 1998 2045 4995 1005 1056 2116 1999 2023 4696 1012 2027 2298 2012 2115 2147 2115 2166 2147 2040 2017 2024 2004 1037 2529 2108 1998 1996 4382 1997 2040 2017 2024 2004 1037 2529 2108 1012 2025 2116 7836 2298 2012 2008 5995 1012 1000 1996 2230 10515 2003 2019 7812 6728 10404 1011 25325 5657 2461 2795 1012 2169 4217 3063 1005 1055 2166 2038 2042 7765 2011 26479 1998 10576 1012 1031 1056 13512 1033 5179 2038 5720 2055 2014 2219 9454 6905 1998 11573 2791 1012 2021 2016 2179 1037 18111 1999 1996 2739 2449 2551 2004 2019 8133 1999 8423 1998 6222 2073 2016 2018 2014 2034 2831 2265 1012 2016 2003 2085 2028 1997 1996 2087 3144 1998 27809 2449 12706 2007 2014 2219 2897 24469 1999 2254 1012 2014 3772 6495 2421 2019 7436 6488 2005 2014 2147 1999 1000 1996 3609 6379 1012 1000 2016 2101 2550 1996 5934 3315 2241 2006 1996 1000 6379 1000 3185 1998 2338 1998 2550 1998 5652 1999 1996 2143 1000 11419 1012 1000 1999 1996 2449 2088 1031 1056 13512 1033 2003 5827 2007 5094 2000 17995 1996 2338 3068 2007 2014 2006 1011 2250 2338 2252 2029 2097 13746 2023 3204 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.655282 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.657553 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.659764 140083176642432 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.666491 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.669107 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] brisbane ( australia ) ( af ##p ) a england unveiled their modern - day ab ##od ##yl ##ine ##a strategy to reduce the influence of australia ##as master batsman [ t ##gt ] in the first ashes test at the ga ##bba on saturday . marsh recalled for an eighth time to the test team made 51 in 141 balls and put on 99 runs with smith for the fifth wicket . smith had a moment on 69 when a rear ##ing jake ball delivery hit the top of his bat but fell out of reach of a close - in fielder . root set in ##vent ##ive field settings for pace ##man chris wo ##akes pitching the ball short to smith . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.671504 140083176642432 run_classifier.py:464] tokens: [CLS] brisbane ( australia ) ( af ##p ) a england unveiled their modern - day ab ##od ##yl ##ine ##a strategy to reduce the influence of australia ##as master batsman [ t ##gt ] in the first ashes test at the ga ##bba on saturday . marsh recalled for an eighth time to the test team made 51 in 141 balls and put on 99 runs with smith for the fifth wicket . smith had a moment on 69 when a rear ##ing jake ball delivery hit the top of his bat but fell out of reach of a close - in fielder . root set in ##vent ##ive field settings for pace ##man chris wo ##akes pitching the ball short to smith . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 7717 1006 2660 1007 1006 21358 2361 1007 1037 2563 11521 2037 2715 1011 2154 11113 7716 8516 3170 2050 5656 2000 5547 1996 3747 1997 2660 3022 3040 13953 1031 1056 13512 1033 1999 1996 2034 11289 3231 2012 1996 11721 22414 2006 5095 1012 9409 7383 2005 2019 5964 2051 2000 1996 3231 2136 2081 4868 1999 15471 7395 1998 2404 2006 5585 3216 2007 3044 2005 1996 3587 12937 1012 3044 2018 1037 2617 2006 6353 2043 1037 4373 2075 5180 3608 6959 2718 1996 2327 1997 2010 7151 2021 3062 2041 1997 3362 1997 1037 2485 1011 1999 25000 1012 7117 2275 1999 15338 3512 2492 10906 2005 6393 2386 3782 24185 20060 14696 1996 3608 2460 2000 3044 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.673790 140083176642432 run_classifier.py:465] input_ids: 101 7717 1006 2660 1007 1006 21358 2361 1007 1037 2563 11521 2037 2715 1011 2154 11113 7716 8516 3170 2050 5656 2000 5547 1996 3747 1997 2660 3022 3040 13953 1031 1056 13512 1033 1999 1996 2034 11289 3231 2012 1996 11721 22414 2006 5095 1012 9409 7383 2005 2019 5964 2051 2000 1996 3231 2136 2081 4868 1999 15471 7395 1998 2404 2006 5585 3216 2007 3044 2005 1996 3587 12937 1012 3044 2018 1037 2617 2006 6353 2043 1037 4373 2075 5180 3608 6959 2718 1996 2327 1997 2010 7151 2021 3062 2041 1997 3362 1997 1037 2485 1011 1999 25000 1012 7117 2275 1999 15338 3512 2492 10906 2005 6393 2386 3782 24185 20060 14696 1996 3608 2460 2000 3044 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.676170 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.678386 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:56.680457 140083176642432 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 340\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.824911 140083176642432 run_classifier.py:774] Writing example 0 of 340\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.848071 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.850955 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] north korean defect ##or ji seo ##ng - ho raises his cr ##ut ##ches as he is recognized by [ t ##gt ] during the state of the union address on jan . 30 2018 . ( man ##del ng ##an / af ##p / get ##ty images ) [ t ##gt ] will meet north korean defect ##ors in the oval office on friday a provocative action meant to highlight human rights violations and one that could raise alarms in p ##yon ##gy ##ang . [ t ##gt ] is expected to meet with eight defect ##ors a six who live in south korea and two who live in the united states a two days after [ t ##gt ] pun ##ctuated [ t ##gt ] state of the union address by praising ji seo ##ng - ho a defect ##or from north korea who had been invited to watch the address from the first lady ' s box . ji will be among the group at the white house on friday . an ##o regime has op ##pressed its own citizens more totally or brutally than the cruel dictatorship in north korea a [ t ##gt ] said tuesday night during the annual address to congress . \" north korea ' s reckless pursuit of nuclear missiles could very soon threaten our homeland . \" the visit was arranged by greg scar ##lat ##oi ##u at the committee for human rights in north korea a person familiar with the meeting said . [ t ##gt ] has sought to highlight the human costs of dictator kim jong un ' s regime but foreign policy experts warned that there are risks to such a strategy . [ t ##gt ] ' s administration has said that [ t ##gt ] is continuing that policy . but the president ' s increasing rhetoric including vows to use military power to \" totally destroy \" the north and his personal den ##unciation ##s of kim have ramp ##ed up tensions on the peninsula . experts said [ t ##gt ] ' s embrace of defect ##ors could also be interpreted in p ##yon ##gy ##ang as a threat . am ##eet ##ing [ t ##gt ] in the oval raises the question of whether the u . s . strategy is regime change a said one foreign - policy expert who specializes in east asia . ai ##t could reduce the incentive to negotiate and potentially under ##cut efforts [ of cooperation ] with china . the real question is : is north korea strategy changing ? a at ##oda ##y he lives in seoul where he rescues other defect ##ors and broadcasts into north korea what the regime fears the most a the truth a [ t ##gt ] said during [ t ##gt ] address to congress . at ##oda ##y [ t ##gt ] has a new leg but seo ##ng - ho i understand you still keep those cr ##ut ##ches as a reminder of how far [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.859225 140083176642432 run_classifier.py:464] tokens: [CLS] north korean defect ##or ji seo ##ng - ho raises his cr ##ut ##ches as he is recognized by [ t ##gt ] during the state of the union address on jan . 30 2018 . ( man ##del ng ##an / af ##p / get ##ty images ) [ t ##gt ] will meet north korean defect ##ors in the oval office on friday a provocative action meant to highlight human rights violations and one that could raise alarms in p ##yon ##gy ##ang . [ t ##gt ] is expected to meet with eight defect ##ors a six who live in south korea and two who live in the united states a two days after [ t ##gt ] pun ##ctuated [ t ##gt ] state of the union address by praising ji seo ##ng - ho a defect ##or from north korea who had been invited to watch the address from the first lady ' s box . ji will be among the group at the white house on friday . an ##o regime has op ##pressed its own citizens more totally or brutally than the cruel dictatorship in north korea a [ t ##gt ] said tuesday night during the annual address to congress . \" north korea ' s reckless pursuit of nuclear missiles could very soon threaten our homeland . \" the visit was arranged by greg scar ##lat ##oi ##u at the committee for human rights in north korea a person familiar with the meeting said . [ t ##gt ] has sought to highlight the human costs of dictator kim jong un ' s regime but foreign policy experts warned that there are risks to such a strategy . [ t ##gt ] ' s administration has said that [ t ##gt ] is continuing that policy . but the president ' s increasing rhetoric including vows to use military power to \" totally destroy \" the north and his personal den ##unciation ##s of kim have ramp ##ed up tensions on the peninsula . experts said [ t ##gt ] ' s embrace of defect ##ors could also be interpreted in p ##yon ##gy ##ang as a threat . am ##eet ##ing [ t ##gt ] in the oval raises the question of whether the u . s . strategy is regime change a said one foreign - policy expert who specializes in east asia . ai ##t could reduce the incentive to negotiate and potentially under ##cut efforts [ of cooperation ] with china . the real question is : is north korea strategy changing ? a at ##oda ##y he lives in seoul where he rescues other defect ##ors and broadcasts into north korea what the regime fears the most a the truth a [ t ##gt ] said during [ t ##gt ] address to congress . at ##oda ##y [ t ##gt ] has a new leg but seo ##ng - ho i understand you still keep those cr ##ut ##ches as a reminder of how far [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2167 4759 21262 2953 10147 27457 3070 1011 7570 13275 2010 13675 4904 8376 2004 2002 2003 3858 2011 1031 1056 13512 1033 2076 1996 2110 1997 1996 2586 4769 2006 5553 1012 2382 2760 1012 1006 2158 9247 12835 2319 1013 21358 2361 1013 2131 3723 4871 1007 1031 1056 13512 1033 2097 3113 2167 4759 21262 5668 1999 1996 9242 2436 2006 5958 1037 26422 2895 3214 2000 12944 2529 2916 13302 1998 2028 2008 2071 5333 29034 1999 1052 14001 6292 5654 1012 1031 1056 13512 1033 2003 3517 2000 3113 2007 2809 21262 5668 1037 2416 2040 2444 1999 2148 4420 1998 2048 2040 2444 1999 1996 2142 2163 1037 2048 2420 2044 1031 1056 13512 1033 26136 25638 1031 1056 13512 1033 2110 1997 1996 2586 4769 2011 15838 10147 27457 3070 1011 7570 1037 21262 2953 2013 2167 4420 2040 2018 2042 4778 2000 3422 1996 4769 2013 1996 2034 3203 1005 1055 3482 1012 10147 2097 2022 2426 1996 2177 2012 1996 2317 2160 2006 5958 1012 2019 2080 6939 2038 6728 19811 2049 2219 4480 2062 6135 2030 23197 2084 1996 10311 18944 1999 2167 4420 1037 1031 1056 13512 1033 2056 9857 2305 2076 1996 3296 4769 2000 3519 1012 1000 2167 4420 1005 1055 18555 8463 1997 4517 10815 2071 2200 2574 15686 2256 10759 1012 1000 1996 3942 2001 5412 2011 6754 11228 20051 10448 2226 2012 1996 2837 2005 2529 2916 1999 2167 4420 1037 2711 5220 2007 1996 3116 2056 1012 1031 1056 13512 1033 2038 4912 2000 12944 1996 2529 5366 1997 21237 5035 18528 4895 1005 1055 6939 2021 3097 3343 8519 7420 2008 2045 2024 10831 2000 2107 1037 5656 1012 1031 1056 13512 1033 1005 1055 3447 2038 2056 2008 1031 1056 13512 1033 2003 5719 2008 3343 1012 2021 1996 2343 1005 1055 4852 17871 2164 16495 2000 2224 2510 2373 2000 1000 6135 6033 1000 1996 2167 1998 2010 3167 7939 24101 2015 1997 5035 2031 13276 2098 2039 13136 2006 1996 6000 1012 8519 2056 1031 1056 13512 1033 1005 1055 9979 1997 21262 5668 2071 2036 2022 10009 1999 1052 14001 6292 5654 2004 1037 5081 1012 2572 15558 2075 1031 1056 13512 1033 1999 1996 9242 13275 1996 3160 1997 3251 1996 1057 1012 1055 1012 5656 2003 6939 2689 1037 2056 2028 3097 1011 3343 6739 2040 16997 1999 2264 4021 1012 9932 2102 2071 5547 1996 20438 2000 13676 1998 9280 2104 12690 4073 1031 1997 6792 1033 2007 2859 1012 1996 2613 3160 2003 1024 2003 2167 4420 5656 5278 1029 1037 2012 13390 2100 2002 3268 1999 10884 2073 2002 26001 2060 21262 5668 1998 8960 2046 2167 4420 2054 1996 6939 10069 1996 2087 1037 1996 3606 1037 1031 1056 13512 1033 2056 2076 1031 1056 13512 1033 4769 2000 3519 1012 2012 13390 2100 1031 1056 13512 1033 2038 1037 2047 4190 2021 27457 3070 1011 7570 1045 3305 2017 2145 2562 2216 13675 4904 8376 2004 1037 14764 1997 2129 2521 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.863023 140083176642432 run_classifier.py:465] input_ids: 101 2167 4759 21262 2953 10147 27457 3070 1011 7570 13275 2010 13675 4904 8376 2004 2002 2003 3858 2011 1031 1056 13512 1033 2076 1996 2110 1997 1996 2586 4769 2006 5553 1012 2382 2760 1012 1006 2158 9247 12835 2319 1013 21358 2361 1013 2131 3723 4871 1007 1031 1056 13512 1033 2097 3113 2167 4759 21262 5668 1999 1996 9242 2436 2006 5958 1037 26422 2895 3214 2000 12944 2529 2916 13302 1998 2028 2008 2071 5333 29034 1999 1052 14001 6292 5654 1012 1031 1056 13512 1033 2003 3517 2000 3113 2007 2809 21262 5668 1037 2416 2040 2444 1999 2148 4420 1998 2048 2040 2444 1999 1996 2142 2163 1037 2048 2420 2044 1031 1056 13512 1033 26136 25638 1031 1056 13512 1033 2110 1997 1996 2586 4769 2011 15838 10147 27457 3070 1011 7570 1037 21262 2953 2013 2167 4420 2040 2018 2042 4778 2000 3422 1996 4769 2013 1996 2034 3203 1005 1055 3482 1012 10147 2097 2022 2426 1996 2177 2012 1996 2317 2160 2006 5958 1012 2019 2080 6939 2038 6728 19811 2049 2219 4480 2062 6135 2030 23197 2084 1996 10311 18944 1999 2167 4420 1037 1031 1056 13512 1033 2056 9857 2305 2076 1996 3296 4769 2000 3519 1012 1000 2167 4420 1005 1055 18555 8463 1997 4517 10815 2071 2200 2574 15686 2256 10759 1012 1000 1996 3942 2001 5412 2011 6754 11228 20051 10448 2226 2012 1996 2837 2005 2529 2916 1999 2167 4420 1037 2711 5220 2007 1996 3116 2056 1012 1031 1056 13512 1033 2038 4912 2000 12944 1996 2529 5366 1997 21237 5035 18528 4895 1005 1055 6939 2021 3097 3343 8519 7420 2008 2045 2024 10831 2000 2107 1037 5656 1012 1031 1056 13512 1033 1005 1055 3447 2038 2056 2008 1031 1056 13512 1033 2003 5719 2008 3343 1012 2021 1996 2343 1005 1055 4852 17871 2164 16495 2000 2224 2510 2373 2000 1000 6135 6033 1000 1996 2167 1998 2010 3167 7939 24101 2015 1997 5035 2031 13276 2098 2039 13136 2006 1996 6000 1012 8519 2056 1031 1056 13512 1033 1005 1055 9979 1997 21262 5668 2071 2036 2022 10009 1999 1052 14001 6292 5654 2004 1037 5081 1012 2572 15558 2075 1031 1056 13512 1033 1999 1996 9242 13275 1996 3160 1997 3251 1996 1057 1012 1055 1012 5656 2003 6939 2689 1037 2056 2028 3097 1011 3343 6739 2040 16997 1999 2264 4021 1012 9932 2102 2071 5547 1996 20438 2000 13676 1998 9280 2104 12690 4073 1031 1997 6792 1033 2007 2859 1012 1996 2613 3160 2003 1024 2003 2167 4420 5656 5278 1029 1037 2012 13390 2100 2002 3268 1999 10884 2073 2002 26001 2060 21262 5668 1998 8960 2046 2167 4420 2054 1996 6939 10069 1996 2087 1037 1996 3606 1037 1031 1056 13512 1033 2056 2076 1031 1056 13512 1033 4769 2000 3519 1012 2012 13390 2100 1031 1056 13512 1033 2038 1037 2047 4190 2021 27457 3070 1011 7570 1045 3305 2017 2145 2562 2216 13675 4904 8376 2004 1037 14764 1997 2129 2521 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.867021 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.876003 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.879755 140083176642432 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.904705 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.906990 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] republicans who criticized mr . obama ' s approach to the united nations , and america ' s role in the world more broadly , praised mr . trump ' s speech . president obama ended his first speech to the united nations with a call to respect universal rights and the u . n . itself , saying all nations owed an obligation to the international body . democrats took the opposite view and cast mr . trump as reckless - - the opposite , they would argue , of the measured tone mr . obama consistently set . \" obama , at the end of the day , is a structural ##ist who believes that if you can get everybody into these international organizations and multi ##lateral institutions that will prom ##ul ##gate norms of behavior that will condition states and prevent the need for conflict . he also der ##ided the obama administration ' s nuclear deal with iran , saying he is leaning toward pulling out of the agreement if the islamic republic does n ' t cease sponsoring terrorism and f ##ome ##nting disco ##rd in the middle east . the united states stands ready to begin a new chapter of international cooperation , one that recognizes the rights and responsibilities of all nations , \" mr . obama said in the fall of 2009 . \" there are not two presidents who represent the two poles of that more than obama and trump , \" said james cara ##fan ##o , vice president of foreign policy at the conservative heritage foundation . in the place of mr . obama ' s carefully crafted or ##atory were \" t ##wee ##t - ready \" quotes such as the \" rocket man \" line , the threat to destroy north korea and calling the iran nuclear deal embarrassing . by contrast , mr . obama came to the united nations in 2013 , shortly after iranian president hassan ro ##uh ##ani rose to power , desperately seeking an agreement with the would - be nuclear power and dev ##oting much of his address to the need for international cooperation and diplomacy . in addition to the president ' s rhetoric , administration officials at the time were frantically trying to arrange a brief side ##line meeting between mr . obama and mr . ro ##uh ##ani , attempting to secure a hands ##hak ##e that would sign ##ify the start of a relationship between the two decades - old foe ##s . contrasts can be drawn from mr . trump ' s speech tuesday and any of mr . obama ' s addresses during his eight years in office . but few illustrate the difference as clearly as mr . obama ' s first , in which he laid out a broad philosophy of breaking with the bush administration ' s intervention ##ist foreign policy and rec ##om ##mit ##ting america to the united nations and other international groups . in his remarks , mr . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.910499 140083176642432 run_classifier.py:464] tokens: [CLS] republicans who criticized mr . obama ' s approach to the united nations , and america ' s role in the world more broadly , praised mr . trump ' s speech . president obama ended his first speech to the united nations with a call to respect universal rights and the u . n . itself , saying all nations owed an obligation to the international body . democrats took the opposite view and cast mr . trump as reckless - - the opposite , they would argue , of the measured tone mr . obama consistently set . \" obama , at the end of the day , is a structural ##ist who believes that if you can get everybody into these international organizations and multi ##lateral institutions that will prom ##ul ##gate norms of behavior that will condition states and prevent the need for conflict . he also der ##ided the obama administration ' s nuclear deal with iran , saying he is leaning toward pulling out of the agreement if the islamic republic does n ' t cease sponsoring terrorism and f ##ome ##nting disco ##rd in the middle east . the united states stands ready to begin a new chapter of international cooperation , one that recognizes the rights and responsibilities of all nations , \" mr . obama said in the fall of 2009 . \" there are not two presidents who represent the two poles of that more than obama and trump , \" said james cara ##fan ##o , vice president of foreign policy at the conservative heritage foundation . in the place of mr . obama ' s carefully crafted or ##atory were \" t ##wee ##t - ready \" quotes such as the \" rocket man \" line , the threat to destroy north korea and calling the iran nuclear deal embarrassing . by contrast , mr . obama came to the united nations in 2013 , shortly after iranian president hassan ro ##uh ##ani rose to power , desperately seeking an agreement with the would - be nuclear power and dev ##oting much of his address to the need for international cooperation and diplomacy . in addition to the president ' s rhetoric , administration officials at the time were frantically trying to arrange a brief side ##line meeting between mr . obama and mr . ro ##uh ##ani , attempting to secure a hands ##hak ##e that would sign ##ify the start of a relationship between the two decades - old foe ##s . contrasts can be drawn from mr . trump ' s speech tuesday and any of mr . obama ' s addresses during his eight years in office . but few illustrate the difference as clearly as mr . obama ' s first , in which he laid out a broad philosophy of breaking with the bush administration ' s intervention ##ist foreign policy and rec ##om ##mit ##ting america to the united nations and other international groups . in his remarks , mr . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 10643 2040 6367 2720 1012 8112 1005 1055 3921 2000 1996 2142 3741 1010 1998 2637 1005 1055 2535 1999 1996 2088 2062 13644 1010 5868 2720 1012 8398 1005 1055 4613 1012 2343 8112 3092 2010 2034 4613 2000 1996 2142 3741 2007 1037 2655 2000 4847 5415 2916 1998 1996 1057 1012 1050 1012 2993 1010 3038 2035 3741 12232 2019 14987 2000 1996 2248 2303 1012 8037 2165 1996 4500 3193 1998 3459 2720 1012 8398 2004 18555 1011 1011 1996 4500 1010 2027 2052 7475 1010 1997 1996 7594 4309 2720 1012 8112 10862 2275 1012 1000 8112 1010 2012 1996 2203 1997 1996 2154 1010 2003 1037 8332 2923 2040 7164 2008 2065 2017 2064 2131 7955 2046 2122 2248 4411 1998 4800 28277 4896 2008 2097 20877 5313 5867 17606 1997 5248 2008 2097 4650 2163 1998 4652 1996 2342 2005 4736 1012 2002 2036 4315 14097 1996 8112 3447 1005 1055 4517 3066 2007 4238 1010 3038 2002 2003 6729 2646 4815 2041 1997 1996 3820 2065 1996 5499 3072 2515 1050 1005 1056 13236 29396 10130 1998 1042 8462 24360 12532 4103 1999 1996 2690 2264 1012 1996 2142 2163 4832 3201 2000 4088 1037 2047 3127 1997 2248 6792 1010 2028 2008 14600 1996 2916 1998 10198 1997 2035 3741 1010 1000 2720 1012 8112 2056 1999 1996 2991 1997 2268 1012 1000 2045 2024 2025 2048 11274 2040 5050 1996 2048 10567 1997 2008 2062 2084 8112 1998 8398 1010 1000 2056 2508 14418 15143 2080 1010 3580 2343 1997 3097 3343 2012 1996 4603 4348 3192 1012 1999 1996 2173 1997 2720 1012 8112 1005 1055 5362 19275 2030 14049 2020 1000 1056 28394 2102 1011 3201 1000 16614 2107 2004 1996 1000 7596 2158 1000 2240 1010 1996 5081 2000 6033 2167 4420 1998 4214 1996 4238 4517 3066 16436 1012 2011 5688 1010 2720 1012 8112 2234 2000 1996 2142 3741 1999 2286 1010 3859 2044 7726 2343 13222 20996 27225 7088 3123 2000 2373 1010 9652 6224 2019 3820 2007 1996 2052 1011 2022 4517 2373 1998 16475 20656 2172 1997 2010 4769 2000 1996 2342 2005 2248 6792 1998 17610 1012 1999 2804 2000 1996 2343 1005 1055 17871 1010 3447 4584 2012 1996 2051 2020 16460 2667 2000 13621 1037 4766 2217 4179 3116 2090 2720 1012 8112 1998 2720 1012 20996 27225 7088 1010 7161 2000 5851 1037 2398 20459 2063 2008 2052 3696 8757 1996 2707 1997 1037 3276 2090 1996 2048 5109 1011 2214 22277 2015 1012 23347 2064 2022 4567 2013 2720 1012 8398 1005 1055 4613 9857 1998 2151 1997 2720 1012 8112 1005 1055 11596 2076 2010 2809 2086 1999 2436 1012 2021 2261 19141 1996 4489 2004 4415 2004 2720 1012 8112 1005 1055 2034 1010 1999 2029 2002 4201 2041 1037 5041 4695 1997 4911 2007 1996 5747 3447 1005 1055 8830 2923 3097 3343 1998 28667 5358 22930 3436 2637 2000 1996 2142 3741 1998 2060 2248 2967 1012 1999 2010 12629 1010 2720 1012 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.914892 140083176642432 run_classifier.py:465] input_ids: 101 10643 2040 6367 2720 1012 8112 1005 1055 3921 2000 1996 2142 3741 1010 1998 2637 1005 1055 2535 1999 1996 2088 2062 13644 1010 5868 2720 1012 8398 1005 1055 4613 1012 2343 8112 3092 2010 2034 4613 2000 1996 2142 3741 2007 1037 2655 2000 4847 5415 2916 1998 1996 1057 1012 1050 1012 2993 1010 3038 2035 3741 12232 2019 14987 2000 1996 2248 2303 1012 8037 2165 1996 4500 3193 1998 3459 2720 1012 8398 2004 18555 1011 1011 1996 4500 1010 2027 2052 7475 1010 1997 1996 7594 4309 2720 1012 8112 10862 2275 1012 1000 8112 1010 2012 1996 2203 1997 1996 2154 1010 2003 1037 8332 2923 2040 7164 2008 2065 2017 2064 2131 7955 2046 2122 2248 4411 1998 4800 28277 4896 2008 2097 20877 5313 5867 17606 1997 5248 2008 2097 4650 2163 1998 4652 1996 2342 2005 4736 1012 2002 2036 4315 14097 1996 8112 3447 1005 1055 4517 3066 2007 4238 1010 3038 2002 2003 6729 2646 4815 2041 1997 1996 3820 2065 1996 5499 3072 2515 1050 1005 1056 13236 29396 10130 1998 1042 8462 24360 12532 4103 1999 1996 2690 2264 1012 1996 2142 2163 4832 3201 2000 4088 1037 2047 3127 1997 2248 6792 1010 2028 2008 14600 1996 2916 1998 10198 1997 2035 3741 1010 1000 2720 1012 8112 2056 1999 1996 2991 1997 2268 1012 1000 2045 2024 2025 2048 11274 2040 5050 1996 2048 10567 1997 2008 2062 2084 8112 1998 8398 1010 1000 2056 2508 14418 15143 2080 1010 3580 2343 1997 3097 3343 2012 1996 4603 4348 3192 1012 1999 1996 2173 1997 2720 1012 8112 1005 1055 5362 19275 2030 14049 2020 1000 1056 28394 2102 1011 3201 1000 16614 2107 2004 1996 1000 7596 2158 1000 2240 1010 1996 5081 2000 6033 2167 4420 1998 4214 1996 4238 4517 3066 16436 1012 2011 5688 1010 2720 1012 8112 2234 2000 1996 2142 3741 1999 2286 1010 3859 2044 7726 2343 13222 20996 27225 7088 3123 2000 2373 1010 9652 6224 2019 3820 2007 1996 2052 1011 2022 4517 2373 1998 16475 20656 2172 1997 2010 4769 2000 1996 2342 2005 2248 6792 1998 17610 1012 1999 2804 2000 1996 2343 1005 1055 17871 1010 3447 4584 2012 1996 2051 2020 16460 2667 2000 13621 1037 4766 2217 4179 3116 2090 2720 1012 8112 1998 2720 1012 20996 27225 7088 1010 7161 2000 5851 1037 2398 20459 2063 2008 2052 3696 8757 1996 2707 1997 1037 3276 2090 1996 2048 5109 1011 2214 22277 2015 1012 23347 2064 2022 4567 2013 2720 1012 8398 1005 1055 4613 9857 1998 2151 1997 2720 1012 8112 1005 1055 11596 2076 2010 2809 2086 1999 2436 1012 2021 2261 19141 1996 4489 2004 4415 2004 2720 1012 8112 1005 1055 2034 1010 1999 2029 2002 4201 2041 1037 5041 4695 1997 4911 2007 1996 5747 3447 1005 1055 8830 2923 3097 3343 1998 28667 5358 22930 3436 2637 2000 1996 2142 3741 1998 2060 2248 2967 1012 1999 2010 12629 1010 2720 1012 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.918848 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.925285 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.929665 140083176642432 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.935050 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.940562 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] marc mar ##on on robin williams , [ t ##gt ] and learning to be a good listener . on interviewing [ t ##gt ] . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.944385 140083176642432 run_classifier.py:464] tokens: [CLS] marc mar ##on on robin williams , [ t ##gt ] and learning to be a good listener . on interviewing [ t ##gt ] . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 7871 9388 2239 2006 5863 3766 1010 1031 1056 13512 1033 1998 4083 2000 2022 1037 2204 19373 1012 2006 27805 1031 1056 13512 1033 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.948797 140083176642432 run_classifier.py:465] input_ids: 101 7871 9388 2239 2006 5863 3766 1010 1031 1056 13512 1033 1998 4083 2000 2022 1037 2204 19373 1012 2006 27805 1031 1056 13512 1033 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.953226 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.957278 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.961189 140083176642432 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.978270 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.982961 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the white house said [ t ##gt ] sl ##ur ##red through part of [ t ##gt ] speech about jerusalem on wednesday because [ t ##gt ] had a dry throat . [ t ##gt ] in a major foreign policy shift announced that the u . s . would move its embassy in israel from tel aviv to jerusalem . but toward the end of the white house address [ t ##gt ] began to sl ##ur parts of [ t ##gt ] speech ga ##rb ##ling ago ##d bless the united states ##a at the end of [ t ##gt ] remarks . \" god bless the una ##tted ste ##ths [ t ##gt ] said wednesday . ( evan vu ##cci / ap ) [ t ##gt ] fueled buzz on social media that the president was having some health problems or dent ##ure slip ##page . a his throat was dry a white house spokesman raj shah said . at ##her ##ea ##s nothing to it . a the president grabbed for a bottle of water during a nov . 15 speech . ( joshua roberts / reuters ) last month [ t ##gt ] had an awkward water - bottle moment during a speech rec ##app ##ing [ t ##gt ] 12 - day trip to asia . the president stopped mid - speech to reach behind a podium to get a bottle of water which he lifted to his mouth with two hands . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.987637 140083176642432 run_classifier.py:464] tokens: [CLS] the white house said [ t ##gt ] sl ##ur ##red through part of [ t ##gt ] speech about jerusalem on wednesday because [ t ##gt ] had a dry throat . [ t ##gt ] in a major foreign policy shift announced that the u . s . would move its embassy in israel from tel aviv to jerusalem . but toward the end of the white house address [ t ##gt ] began to sl ##ur parts of [ t ##gt ] speech ga ##rb ##ling ago ##d bless the united states ##a at the end of [ t ##gt ] remarks . \" god bless the una ##tted ste ##ths [ t ##gt ] said wednesday . ( evan vu ##cci / ap ) [ t ##gt ] fueled buzz on social media that the president was having some health problems or dent ##ure slip ##page . a his throat was dry a white house spokesman raj shah said . at ##her ##ea ##s nothing to it . a the president grabbed for a bottle of water during a nov . 15 speech . ( joshua roberts / reuters ) last month [ t ##gt ] had an awkward water - bottle moment during a speech rec ##app ##ing [ t ##gt ] 12 - day trip to asia . the president stopped mid - speech to reach behind a podium to get a bottle of water which he lifted to his mouth with two hands . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 2317 2160 2056 1031 1056 13512 1033 22889 3126 5596 2083 2112 1997 1031 1056 13512 1033 4613 2055 6744 2006 9317 2138 1031 1056 13512 1033 2018 1037 4318 3759 1012 1031 1056 13512 1033 1999 1037 2350 3097 3343 5670 2623 2008 1996 1057 1012 1055 1012 2052 2693 2049 8408 1999 3956 2013 10093 12724 2000 6744 1012 2021 2646 1996 2203 1997 1996 2317 2160 4769 1031 1056 13512 1033 2211 2000 22889 3126 3033 1997 1031 1056 13512 1033 4613 11721 15185 2989 3283 2094 19994 1996 2142 2163 2050 2012 1996 2203 1997 1031 1056 13512 1033 12629 1012 1000 2643 19994 1996 14477 16190 26261 26830 1031 1056 13512 1033 2056 9317 1012 1006 9340 24728 14693 1013 9706 1007 1031 1056 13512 1033 17999 12610 2006 2591 2865 2008 1996 2343 2001 2383 2070 2740 3471 2030 21418 5397 7540 13704 1012 1037 2010 3759 2001 4318 1037 2317 2160 14056 11948 7890 2056 1012 2012 5886 5243 2015 2498 2000 2009 1012 1037 1996 2343 4046 2005 1037 5835 1997 2300 2076 1037 13292 1012 2321 4613 1012 1006 9122 7031 1013 26665 1007 2197 3204 1031 1056 13512 1033 2018 2019 9596 2300 1011 5835 2617 2076 1037 4613 28667 29098 2075 1031 1056 13512 1033 2260 1011 2154 4440 2000 4021 1012 1996 2343 3030 3054 1011 4613 2000 3362 2369 1037 14502 2000 2131 1037 5835 1997 2300 2029 2002 4196 2000 2010 2677 2007 2048 2398 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.991291 140083176642432 run_classifier.py:465] input_ids: 101 1996 2317 2160 2056 1031 1056 13512 1033 22889 3126 5596 2083 2112 1997 1031 1056 13512 1033 4613 2055 6744 2006 9317 2138 1031 1056 13512 1033 2018 1037 4318 3759 1012 1031 1056 13512 1033 1999 1037 2350 3097 3343 5670 2623 2008 1996 1057 1012 1055 1012 2052 2693 2049 8408 1999 3956 2013 10093 12724 2000 6744 1012 2021 2646 1996 2203 1997 1996 2317 2160 4769 1031 1056 13512 1033 2211 2000 22889 3126 3033 1997 1031 1056 13512 1033 4613 11721 15185 2989 3283 2094 19994 1996 2142 2163 2050 2012 1996 2203 1997 1031 1056 13512 1033 12629 1012 1000 2643 19994 1996 14477 16190 26261 26830 1031 1056 13512 1033 2056 9317 1012 1006 9340 24728 14693 1013 9706 1007 1031 1056 13512 1033 17999 12610 2006 2591 2865 2008 1996 2343 2001 2383 2070 2740 3471 2030 21418 5397 7540 13704 1012 1037 2010 3759 2001 4318 1037 2317 2160 14056 11948 7890 2056 1012 2012 5886 5243 2015 2498 2000 2009 1012 1037 1996 2343 4046 2005 1037 5835 1997 2300 2076 1037 13292 1012 2321 4613 1012 1006 9122 7031 1013 26665 1007 2197 3204 1031 1056 13512 1033 2018 2019 9596 2300 1011 5835 2617 2076 1037 4613 28667 29098 2075 1031 1056 13512 1033 2260 1011 2154 4440 2000 4021 1012 1996 2343 3030 3054 1011 4613 2000 3362 2369 1037 14502 2000 2131 1037 5835 1997 2300 2029 2002 4196 2000 2010 2677 2007 2048 2398 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.995429 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:47:59.998955 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:48:00.001678 140083176642432 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:48:00.007517 140083176642432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:48:00.011275 140083176642432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] you can check out reactions from other celebrities like taylor swift , d ##way ##ne johnson , [ t ##gt ] and others . - - [ t ##gt ] - l ##rb - @ barack ##ob ##ama - rr ##b - october 2 , 2017 . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:48:00.015480 140083176642432 run_classifier.py:464] tokens: [CLS] you can check out reactions from other celebrities like taylor swift , d ##way ##ne johnson , [ t ##gt ] and others . - - [ t ##gt ] - l ##rb - @ barack ##ob ##ama - rr ##b - october 2 , 2017 . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2017 2064 4638 2041 9597 2013 2060 12330 2066 4202 9170 1010 1040 4576 2638 3779 1010 1031 1056 13512 1033 1998 2500 1012 1011 1011 1031 1056 13512 1033 1011 1048 15185 1011 1030 13857 16429 8067 1011 25269 2497 1011 2255 1016 1010 2418 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:48:00.019800 140083176642432 run_classifier.py:465] input_ids: 101 2017 2064 4638 2041 9597 2013 2060 12330 2066 4202 9170 1010 1040 4576 2638 3779 1010 1031 1056 13512 1033 1998 2500 1012 1011 1011 1031 1056 13512 1033 1011 1048 15185 1011 1030 13857 16429 8067 1011 25269 2497 1011 2255 1016 1010 2418 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:48:00.023627 140083176642432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:48:00.027456 140083176642432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 14:48:00.031332 140083176642432 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LiIFIsqg3I2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "# tf.logging.set_verbosity(tf.logging.INFO) #DEBUG,ERROR,FATAL,INFO,WARN\n",
        "def model_train(estimator):\n",
        "  # We'll set sequences to be at most 128 tokens long.\n",
        "#   train_features = run_classifier.convert_examples_to_features(\n",
        "#       train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
        "  print('  Num examples = {}'.format(len(train_InputExamples)))\n",
        "  print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
        "  tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "  train_input_fn = run_classifier.input_fn_builder(\n",
        "      features=train_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=True,\n",
        "      drop_remainder=True)\n",
        "  md = estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "  print('***** Finished training at {} *****'.format(datetime.datetime.now()))\n",
        "  return md\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qatznvlRsQ-2",
        "colab_type": "text"
      },
      "source": [
        "#Evaluation and Prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkmmTPdYsTSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_eval(estimator,eval_examples=dev_InputExamples):\n",
        "  # Eval the model.\n",
        "#   eval_examples = dev_InputExamples#processor.get_dev_examples(TASK_DATA_DIR)\n",
        "#   eval_features = run_classifier.convert_examples_to_features(\n",
        "#       eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  print('  Num examples = {}'.format(len(eval_examples)))\n",
        "  print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "\n",
        "  # Eval will be slightly WRONG on the TPU because it will truncate\n",
        "  # the last batch.\n",
        "  eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n",
        "  eval_input_fn = run_classifier.input_fn_builder(\n",
        "      features=eval_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=False,\n",
        "      drop_remainder=True)\n",
        "  result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "  print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "  with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "    print(\"***** Eval results *****\")\n",
        "    for key in sorted(result.keys()):\n",
        "      print('  {} = {}'.format(key, str(result[key])))\n",
        "      writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "      \n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcCrUx2Esa7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "labels = [\"Negative\",\"Neutral\", \"Positive\"]\n",
        "def model_predict(estimator,prediction_examples,input_features,checkpoint_path=None):\n",
        "  # Make predictions on a subset of eval examples\n",
        "#   prediction_examples = processor.get_dev_examples(TASK_DATA_DIR)[:PREDICT_BATCH_SIZE]\n",
        "#   input_features = run_classifier.convert_examples_to_features(prediction_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=True)\n",
        "  if checkpoint_path: \n",
        "    predictions = estimator.predict(predict_input_fn,checkpoint_path=checkpoint_path)\n",
        "  else:\n",
        "    predictions = estimator.predict(predict_input_fn)\n",
        "  return [(sentence, prediction['probabilities']) for sentence, prediction in zip(prediction_examples, predictions)]\n",
        "\n",
        "# model_train(estimator_from_tfhub)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff4zi6mK90Ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.logging.set_verbosity(tf.logging.FATAL)\n",
        "# model_train(estimator_from_tfhub)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ1fsOEQ1Mgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.logging.set_verbosity(tf.logging.FATAL)\n",
        "# pd = model_predict(estimator_from_tfhub,train_InputExamples,train_features)#,checkpoint_path=OUTPUT_DIR+'/model.ckpt-690')\n",
        "# labels_val = []\n",
        "# true_label = list(train['sentiment'])\n",
        "# for item in pd:\n",
        "#     labels_val.append(labels[np.argmax(item[1])])\n",
        "# print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "# print(metrics.classification_report(y_pred=labels_val,y_true = true_label))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# for chkp in range(506,700,46):\n",
        "#   pd = model_predict(estimator_from_tfhub,dev_InputExamples,checkpoint_path=OUTPUT_DIR+'/model-ckpt.%d'%ckpt))\n",
        "#   labels_val = []\n",
        "#   true_label = list(dev['sentiment'])\n",
        "#   for item in pd:\n",
        "#       labels_val.append(labels[np.argmax(item[1])])\n",
        "#   print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "#   print(metrics.classification_report(y_pred=labels_val,y_true = true_label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-4mW2G-AoXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pd = model_predict(estimator_from_tfhub,dev_InputExamples,eval_features)#,checkpoint_path='ga://bert_example/bert-tfhub/models/nontrainable//model.ckpt-690')\n",
        "# labels_val = []\n",
        "# true_label = list(dev['sentiment'])\n",
        "# for item in pd:\n",
        "#     labels_val.append(labels[np.argmax(item[1])])\n",
        "# print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "# print(metrics.classification_report(y_pred=labels_val,y_true = true_label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ascfbXXbzEpw",
        "colab_type": "code",
        "outputId": "2b18a97c-00b0-41ed-d81b-d6dc6dd7758f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10680
        }
      },
      "source": [
        "## Run it if you want to train for a range of epochs and see the validation error and save the prediction on than\n",
        "## Part Name **\n",
        "tf.logging.set_verbosity(tf.logging.FATAL)\n",
        "mds = []\n",
        "evs = []\n",
        "pds = []\n",
        "# tf.logging.set_verbosity(tf.logging.INFO)\n",
        "from shutil import copyfile\n",
        "max_f1 = 0\n",
        "\n",
        "for i in range(1,15):\n",
        "\n",
        "  NUM_TRAIN_EPOCHS = i\n",
        "  \n",
        "  num_train_steps = int(len(train_InputExamples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "  num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "  model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps,\n",
        "  use_tpu=True,\n",
        "  bert_hub_module_handle=BERT_MODEL_HUB)\n",
        "  \n",
        "  estimator_from_tfhub = tf.contrib.tpu.TPUEstimator(\n",
        "  use_tpu=True,\n",
        "  model_fn=model_fn,\n",
        "  config=get_run_config(OUTPUT_DIR),\n",
        "  train_batch_size=TRAIN_BATCH_SIZE,\n",
        "  eval_batch_size=EVAL_BATCH_SIZE,\n",
        "  predict_batch_size=PREDICT_BATCH_SIZE)\n",
        "  \n",
        "  md = model_train(estimator_from_tfhub)\n",
        "  ev = model_eval(estimator_from_tfhub)\n",
        "  pd = model_predict(estimator_from_tfhub,dev_InputExamples,eval_features)\n",
        "  mds.append(md)\n",
        "  evs.append(ev)\n",
        "  pds.append(pd)\n",
        "#   print(ev)\n",
        "  print('>>>>>>>>>>>>>>>>>>>>Dev Resutls')\n",
        "  true_label = list(dev['sentiment'])\n",
        "  labels_val = []\n",
        "  for item in pd:\n",
        "    labels_val.append(labels[np.argmax(item[1])])\n",
        "  print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "  print(metrics.classification_report(y_pred=labels_val,y_true = true_label))\n",
        "  \n",
        "  print('>>>>>>>>>>>>>>>>>>>>Train Results')\n",
        "  pd = model_predict(estimator_from_tfhub,train_InputExamples,train_features)\n",
        "  true_label = list(train['sentiment'])\n",
        "  labels_val = []\n",
        "  for item in pd:\n",
        "    labels_val.append(labels[np.argmax(item[1])])\n",
        "  print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "  print(metrics.classification_report(y_pred=labels_val,y_true = true_label))\n",
        "  print('----------------------------next epoch: %d----------------------------'%(i+1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for pd,ev in zip(pds,evs):\n",
        "#   print(ev)\n",
        "  labels_val = []\n",
        "  for item in pd:\n",
        "    labels_val.append(labels[np.argmax(item[1])])\n",
        "  print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "  print(metrics.classification_report(y_pred=labels_val,y_true = true_label))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Started training at 2019-05-16 14:48:03.779620 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "excluded trainable variables: >> [<tf.Variable 'module/bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/output_bias:0' shape=(30522,) dtype=float32>, <tf.Variable 'output_weights:0' shape=(3, 768) dtype=float32>, <tf.Variable 'output_bias:0' shape=(3,) dtype=float32>]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Finished training at 2019-05-16 14:51:02.331229 *****\n",
            "***** Started evaluation at 2019-05-16 14:51:02.331610 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-05-16 14:51:41.003373 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.57857144\n",
            "  eval_loss = 0.8773033\n",
            "  global_step = 46\n",
            "  loss = 0.96320504\n",
            ">>>>>>>>>>>>>>>>>>>>Dev Resutls\n",
            "[[  0   0  23]\n",
            " [  0   0  97]\n",
            " [  0   0 164]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.00      0.00      0.00        23\n",
            "     Neutral       0.00      0.00      0.00        97\n",
            "    Positive       0.58      1.00      0.73       164\n",
            "\n",
            "   micro avg       0.58      0.58      0.58       284\n",
            "   macro avg       0.19      0.33      0.24       284\n",
            "weighted avg       0.33      0.58      0.42       284\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>Train Results\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[  0   0 145]\n",
            " [  0   0 443]\n",
            " [  0   0 913]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.00      0.00      0.00       145\n",
            "     Neutral       0.00      0.00      0.00       443\n",
            "    Positive       0.61      1.00      0.76       913\n",
            "\n",
            "   micro avg       0.61      0.61      0.61      1501\n",
            "   macro avg       0.20      0.33      0.25      1501\n",
            "weighted avg       0.37      0.61      0.46      1501\n",
            "\n",
            "----------------------------next epoch: 2----------------------------\n",
            "***** Started training at 2019-05-16 14:52:48.135626 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "excluded trainable variables: >> [<tf.Variable 'module/bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/output_bias:0' shape=(30522,) dtype=float32>, <tf.Variable 'output_weights:0' shape=(3, 768) dtype=float32>, <tf.Variable 'output_bias:0' shape=(3,) dtype=float32>]\n",
            "***** Finished training at 2019-05-16 14:55:34.050117 *****\n",
            "***** Started evaluation at 2019-05-16 14:55:34.050420 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-05-16 14:56:07.673278 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.60714287\n",
            "  eval_loss = 0.84202135\n",
            "  global_step = 93\n",
            "  loss = 0.92520523\n",
            ">>>>>>>>>>>>>>>>>>>>Dev Resutls\n",
            "[[  0  12  11]\n",
            " [  0  24  73]\n",
            " [  0  17 147]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.00      0.00      0.00        23\n",
            "     Neutral       0.45      0.25      0.32        97\n",
            "    Positive       0.64      0.90      0.74       164\n",
            "\n",
            "   micro avg       0.60      0.60      0.60       284\n",
            "   macro avg       0.36      0.38      0.35       284\n",
            "weighted avg       0.52      0.60      0.54       284\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>Train Results\n",
            "[[  0  86  59]\n",
            " [  0 171 272]\n",
            " [  0 129 784]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.00      0.00      0.00       145\n",
            "     Neutral       0.44      0.39      0.41       443\n",
            "    Positive       0.70      0.86      0.77       913\n",
            "\n",
            "   micro avg       0.64      0.64      0.64      1501\n",
            "   macro avg       0.38      0.41      0.40      1501\n",
            "weighted avg       0.56      0.64      0.59      1501\n",
            "\n",
            "----------------------------next epoch: 3----------------------------\n",
            "***** Started training at 2019-05-16 14:57:15.654123 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "excluded trainable variables: >> [<tf.Variable 'module/bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/output_bias:0' shape=(30522,) dtype=float32>, <tf.Variable 'output_weights:0' shape=(3, 768) dtype=float32>, <tf.Variable 'output_bias:0' shape=(3,) dtype=float32>]\n",
            "***** Finished training at 2019-05-16 15:00:10.996554 *****\n",
            "***** Started evaluation at 2019-05-16 15:00:10.997439 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-05-16 15:00:45.470161 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.58214283\n",
            "  eval_loss = 0.8116534\n",
            "  global_step = 140\n",
            "  loss = 0.8467648\n",
            ">>>>>>>>>>>>>>>>>>>>Dev Resutls\n",
            "[[  0  15   8]\n",
            " [  0  32  65]\n",
            " [  0  32 132]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.00      0.00      0.00        23\n",
            "     Neutral       0.41      0.33      0.36        97\n",
            "    Positive       0.64      0.80      0.72       164\n",
            "\n",
            "   micro avg       0.58      0.58      0.58       284\n",
            "   macro avg       0.35      0.38      0.36       284\n",
            "weighted avg       0.51      0.58      0.54       284\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>Train Results\n",
            "[[  0 119  26]\n",
            " [  0 228 215]\n",
            " [  0 173 740]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.00      0.00      0.00       145\n",
            "     Neutral       0.44      0.51      0.47       443\n",
            "    Positive       0.75      0.81      0.78       913\n",
            "\n",
            "   micro avg       0.64      0.64      0.64      1501\n",
            "   macro avg       0.40      0.44      0.42      1501\n",
            "weighted avg       0.59      0.64      0.62      1501\n",
            "\n",
            "----------------------------next epoch: 4----------------------------\n",
            "***** Started training at 2019-05-16 15:01:54.008055 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "excluded trainable variables: >> [<tf.Variable 'module/bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/output_bias:0' shape=(30522,) dtype=float32>, <tf.Variable 'output_weights:0' shape=(3, 768) dtype=float32>, <tf.Variable 'output_bias:0' shape=(3,) dtype=float32>]\n",
            "***** Finished training at 2019-05-16 15:04:38.105867 *****\n",
            "***** Started evaluation at 2019-05-16 15:04:38.106286 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-05-16 15:05:15.797944 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.5928571\n",
            "  eval_loss = 0.8239863\n",
            "  global_step = 187\n",
            "  loss = 0.74229306\n",
            ">>>>>>>>>>>>>>>>>>>>Dev Resutls\n",
            "[[  0  21   2]\n",
            " [  0  56  41]\n",
            " [  0  52 112]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.00      0.00      0.00        23\n",
            "     Neutral       0.43      0.58      0.50        97\n",
            "    Positive       0.72      0.68      0.70       164\n",
            "\n",
            "   micro avg       0.59      0.59      0.59       284\n",
            "   macro avg       0.39      0.42      0.40       284\n",
            "weighted avg       0.57      0.59      0.57       284\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>Train Results\n",
            "[[  7 128  10]\n",
            " [  0 309 134]\n",
            " [  0 234 679]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       1.00      0.05      0.09       145\n",
            "     Neutral       0.46      0.70      0.55       443\n",
            "    Positive       0.83      0.74      0.78       913\n",
            "\n",
            "   micro avg       0.66      0.66      0.66      1501\n",
            "   macro avg       0.76      0.50      0.48      1501\n",
            "weighted avg       0.73      0.66      0.65      1501\n",
            "\n",
            "----------------------------next epoch: 5----------------------------\n",
            "***** Started training at 2019-05-16 15:06:20.663863 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "excluded trainable variables: >> [<tf.Variable 'module/bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/output_bias:0' shape=(30522,) dtype=float32>, <tf.Variable 'output_weights:0' shape=(3, 768) dtype=float32>, <tf.Variable 'output_bias:0' shape=(3,) dtype=float32>]\n",
            "***** Finished training at 2019-05-16 15:09:19.356010 *****\n",
            "***** Started evaluation at 2019-05-16 15:09:19.356345 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-05-16 15:09:55.137766 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.61785716\n",
            "  eval_loss = 0.8575965\n",
            "  global_step = 234\n",
            "  loss = 0.8026446\n",
            ">>>>>>>>>>>>>>>>>>>>Dev Resutls\n",
            "[[  2  19   2]\n",
            " [  2  46  49]\n",
            " [  0  38 126]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.50      0.09      0.15        23\n",
            "     Neutral       0.45      0.47      0.46        97\n",
            "    Positive       0.71      0.77      0.74       164\n",
            "\n",
            "   micro avg       0.61      0.61      0.61       284\n",
            "   macro avg       0.55      0.44      0.45       284\n",
            "weighted avg       0.60      0.61      0.60       284\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>Train Results\n",
            "[[ 43  89  13]\n",
            " [ 16 289 138]\n",
            " [ 10 132 771]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.62      0.30      0.40       145\n",
            "     Neutral       0.57      0.65      0.61       443\n",
            "    Positive       0.84      0.84      0.84       913\n",
            "\n",
            "   micro avg       0.73      0.73      0.73      1501\n",
            "   macro avg       0.68      0.60      0.62      1501\n",
            "weighted avg       0.74      0.73      0.73      1501\n",
            "\n",
            "----------------------------next epoch: 6----------------------------\n",
            "***** Started training at 2019-05-16 15:11:03.941247 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "excluded trainable variables: >> [<tf.Variable 'module/bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/output_bias:0' shape=(30522,) dtype=float32>, <tf.Variable 'output_weights:0' shape=(3, 768) dtype=float32>, <tf.Variable 'output_bias:0' shape=(3,) dtype=float32>]\n",
            "***** Finished training at 2019-05-16 15:13:59.694265 *****\n",
            "***** Started evaluation at 2019-05-16 15:13:59.694664 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-05-16 15:14:33.283168 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.58214283\n",
            "  eval_loss = 0.9222658\n",
            "  global_step = 281\n",
            "  loss = 0.80499816\n",
            ">>>>>>>>>>>>>>>>>>>>Dev Resutls\n",
            "[[  3  19   1]\n",
            " [  7  44  46]\n",
            " [  2  45 117]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.25      0.13      0.17        23\n",
            "     Neutral       0.41      0.45      0.43        97\n",
            "    Positive       0.71      0.71      0.71       164\n",
            "\n",
            "   micro avg       0.58      0.58      0.58       284\n",
            "   macro avg       0.46      0.43      0.44       284\n",
            "weighted avg       0.57      0.58      0.57       284\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>Train Results\n",
            "[[ 68  66  11]\n",
            " [ 45 291 107]\n",
            " [ 10 147 756]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.55      0.47      0.51       145\n",
            "     Neutral       0.58      0.66      0.61       443\n",
            "    Positive       0.86      0.83      0.85       913\n",
            "\n",
            "   micro avg       0.74      0.74      0.74      1501\n",
            "   macro avg       0.67      0.65      0.66      1501\n",
            "weighted avg       0.75      0.74      0.75      1501\n",
            "\n",
            "----------------------------next epoch: 7----------------------------\n",
            "***** Started training at 2019-05-16 15:15:41.233315 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "excluded trainable variables: >> [<tf.Variable 'module/bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/output_bias:0' shape=(30522,) dtype=float32>, <tf.Variable 'output_weights:0' shape=(3, 768) dtype=float32>, <tf.Variable 'output_bias:0' shape=(3,) dtype=float32>]\n",
            "***** Finished training at 2019-05-16 15:18:38.351908 *****\n",
            "***** Started evaluation at 2019-05-16 15:18:38.352244 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-05-16 15:19:15.995955 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.5714286\n",
            "  eval_loss = 0.94937176\n",
            "  global_step = 328\n",
            "  loss = 0.81656176\n",
            ">>>>>>>>>>>>>>>>>>>>Dev Resutls\n",
            "[[  3  19   1]\n",
            " [  6  44  47]\n",
            " [  1  49 114]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.30      0.13      0.18        23\n",
            "     Neutral       0.39      0.45      0.42        97\n",
            "    Positive       0.70      0.70      0.70       164\n",
            "\n",
            "   micro avg       0.57      0.57      0.57       284\n",
            "   macro avg       0.47      0.43      0.43       284\n",
            "weighted avg       0.56      0.57      0.56       284\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>Train Results\n",
            "[[ 69  67   9]\n",
            " [ 29 322  92]\n",
            " [  8 131 774]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.65      0.48      0.55       145\n",
            "     Neutral       0.62      0.73      0.67       443\n",
            "    Positive       0.88      0.85      0.87       913\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      1501\n",
            "   macro avg       0.72      0.68      0.69      1501\n",
            "weighted avg       0.78      0.78      0.78      1501\n",
            "\n",
            "----------------------------next epoch: 8----------------------------\n",
            "***** Started training at 2019-05-16 15:20:22.303457 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "excluded trainable variables: >> [<tf.Variable 'module/bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/output_bias:0' shape=(30522,) dtype=float32>, <tf.Variable 'output_weights:0' shape=(3, 768) dtype=float32>, <tf.Variable 'output_bias:0' shape=(3,) dtype=float32>]\n",
            "***** Finished training at 2019-05-16 15:23:26.661868 *****\n",
            "***** Started evaluation at 2019-05-16 15:23:26.662492 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-05-16 15:24:06.892117 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.5642857\n",
            "  eval_loss = 0.97906584\n",
            "  global_step = 375\n",
            "  loss = 0.8241759\n",
            ">>>>>>>>>>>>>>>>>>>>Dev Resutls\n",
            "[[  3  19   1]\n",
            " [  6  45  46]\n",
            " [  1  52 111]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.30      0.13      0.18        23\n",
            "     Neutral       0.39      0.46      0.42        97\n",
            "    Positive       0.70      0.68      0.69       164\n",
            "\n",
            "   micro avg       0.56      0.56      0.56       284\n",
            "   macro avg       0.46      0.42      0.43       284\n",
            "weighted avg       0.56      0.56      0.56       284\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>Train Results\n",
            "[[ 77  60   8]\n",
            " [ 33 326  84]\n",
            " [  8 113 792]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.65      0.53      0.59       145\n",
            "     Neutral       0.65      0.74      0.69       443\n",
            "    Positive       0.90      0.87      0.88       913\n",
            "\n",
            "   micro avg       0.80      0.80      0.80      1501\n",
            "   macro avg       0.73      0.71      0.72      1501\n",
            "weighted avg       0.80      0.80      0.80      1501\n",
            "\n",
            "----------------------------next epoch: 9----------------------------\n",
            "***** Started training at 2019-05-16 15:25:11.865777 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "excluded trainable variables: >> [<tf.Variable 'module/bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/output_bias:0' shape=(30522,) dtype=float32>, <tf.Variable 'output_weights:0' shape=(3, 768) dtype=float32>, <tf.Variable 'output_bias:0' shape=(3,) dtype=float32>]\n",
            "***** Finished training at 2019-05-16 15:28:08.605904 *****\n",
            "***** Started evaluation at 2019-05-16 15:28:08.606263 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-05-16 15:28:44.140755 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.54285717\n",
            "  eval_loss = 1.0648602\n",
            "  global_step = 422\n",
            "  loss = 0.81883526\n",
            ">>>>>>>>>>>>>>>>>>>>Dev Resutls\n",
            "[[  4  18   1]\n",
            " [ 11  50  36]\n",
            " [  5  58 101]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.20      0.17      0.19        23\n",
            "     Neutral       0.40      0.52      0.45        97\n",
            "    Positive       0.73      0.62      0.67       164\n",
            "\n",
            "   micro avg       0.55      0.55      0.55       284\n",
            "   macro avg       0.44      0.44      0.43       284\n",
            "weighted avg       0.57      0.55      0.55       284\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>Train Results\n",
            "[[ 97  45   3]\n",
            " [ 51 328  64]\n",
            " [  9 168 736]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.62      0.67      0.64       145\n",
            "     Neutral       0.61      0.74      0.67       443\n",
            "    Positive       0.92      0.81      0.86       913\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      1501\n",
            "   macro avg       0.71      0.74      0.72      1501\n",
            "weighted avg       0.80      0.77      0.78      1501\n",
            "\n",
            "----------------------------next epoch: 10----------------------------\n",
            "***** Started training at 2019-05-16 15:29:54.020329 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "excluded trainable variables: >> [<tf.Variable 'module/bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/output_bias:0' shape=(30522,) dtype=float32>, <tf.Variable 'output_weights:0' shape=(3, 768) dtype=float32>, <tf.Variable 'output_bias:0' shape=(3,) dtype=float32>]\n",
            "***** Finished training at 2019-05-16 15:32:43.912553 *****\n",
            "***** Started evaluation at 2019-05-16 15:32:43.913073 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-05-16 15:33:18.460587 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.525\n",
            "  eval_loss = 1.1095262\n",
            "  global_step = 469\n",
            "  loss = 0.8347334\n",
            ">>>>>>>>>>>>>>>>>>>>Dev Resutls\n",
            "[[ 6 16  1]\n",
            " [14 46 37]\n",
            " [ 6 60 98]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.23      0.26      0.24        23\n",
            "     Neutral       0.38      0.47      0.42        97\n",
            "    Positive       0.72      0.60      0.65       164\n",
            "\n",
            "   micro avg       0.53      0.53      0.53       284\n",
            "   macro avg       0.44      0.44      0.44       284\n",
            "weighted avg       0.56      0.53      0.54       284\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>Train Results\n",
            "[[103  39   3]\n",
            " [ 53 331  59]\n",
            " [  9 163 741]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.62      0.71      0.66       145\n",
            "     Neutral       0.62      0.75      0.68       443\n",
            "    Positive       0.92      0.81      0.86       913\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      1501\n",
            "   macro avg       0.72      0.76      0.74      1501\n",
            "weighted avg       0.80      0.78      0.79      1501\n",
            "\n",
            "----------------------------next epoch: 11----------------------------\n",
            "***** Started training at 2019-05-16 15:34:30.739683 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "excluded trainable variables: >> [<tf.Variable 'module/bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/output_bias:0' shape=(30522,) dtype=float32>, <tf.Variable 'output_weights:0' shape=(3, 768) dtype=float32>, <tf.Variable 'output_bias:0' shape=(3,) dtype=float32>]\n",
            "***** Finished training at 2019-05-16 15:37:22.629191 *****\n",
            "***** Started evaluation at 2019-05-16 15:37:22.629527 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-05-16 15:38:03.276706 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.5321429\n",
            "  eval_loss = 1.1602745\n",
            "  global_step = 515\n",
            "  loss = 0.8474498\n",
            ">>>>>>>>>>>>>>>>>>>>Dev Resutls\n",
            "[[11 11  1]\n",
            " [17 43 37]\n",
            " [10 56 98]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.29      0.48      0.36        23\n",
            "     Neutral       0.39      0.44      0.42        97\n",
            "    Positive       0.72      0.60      0.65       164\n",
            "\n",
            "   micro avg       0.54      0.54      0.54       284\n",
            "   macro avg       0.47      0.51      0.48       284\n",
            "weighted avg       0.57      0.54      0.55       284\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>Train Results\n",
            "[[116  26   3]\n",
            " [ 99 289  55]\n",
            " [ 13 145 755]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.51      0.80      0.62       145\n",
            "     Neutral       0.63      0.65      0.64       443\n",
            "    Positive       0.93      0.83      0.87       913\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      1501\n",
            "   macro avg       0.69      0.76      0.71      1501\n",
            "weighted avg       0.80      0.77      0.78      1501\n",
            "\n",
            "----------------------------next epoch: 12----------------------------\n",
            "***** Started training at 2019-05-16 15:39:08.749189 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "excluded trainable variables: >> [<tf.Variable 'module/bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/output_bias:0' shape=(30522,) dtype=float32>, <tf.Variable 'output_weights:0' shape=(3, 768) dtype=float32>, <tf.Variable 'output_bias:0' shape=(3,) dtype=float32>]\n",
            "***** Finished training at 2019-05-16 15:42:10.495706 *****\n",
            "***** Started evaluation at 2019-05-16 15:42:10.496438 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-05-16 15:42:44.171355 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.5392857\n",
            "  eval_loss = 1.1520472\n",
            "  global_step = 562\n",
            "  loss = 0.87402564\n",
            ">>>>>>>>>>>>>>>>>>>>Dev Resutls\n",
            "[[  5  17   1]\n",
            " [ 13  48  36]\n",
            " [  5  59 100]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.22      0.22      0.22        23\n",
            "     Neutral       0.39      0.49      0.43        97\n",
            "    Positive       0.73      0.61      0.66       164\n",
            "\n",
            "   micro avg       0.54      0.54      0.54       284\n",
            "   macro avg       0.44      0.44      0.44       284\n",
            "weighted avg       0.57      0.54      0.55       284\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>Train Results\n",
            "[[103  39   3]\n",
            " [ 53 336  54]\n",
            " [  8 137 768]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.63      0.71      0.67       145\n",
            "     Neutral       0.66      0.76      0.70       443\n",
            "    Positive       0.93      0.84      0.88       913\n",
            "\n",
            "   micro avg       0.80      0.80      0.80      1501\n",
            "   macro avg       0.74      0.77      0.75      1501\n",
            "weighted avg       0.82      0.80      0.81      1501\n",
            "\n",
            "----------------------------next epoch: 13----------------------------\n",
            "***** Started training at 2019-05-16 15:43:50.132976 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "excluded trainable variables: >> [<tf.Variable 'module/bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/output_bias:0' shape=(30522,) dtype=float32>, <tf.Variable 'output_weights:0' shape=(3, 768) dtype=float32>, <tf.Variable 'output_bias:0' shape=(3,) dtype=float32>]\n",
            "***** Finished training at 2019-05-16 15:46:48.125301 *****\n",
            "***** Started evaluation at 2019-05-16 15:46:48.126019 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-05-16 15:47:22.421969 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.525\n",
            "  eval_loss = 1.2097143\n",
            "  global_step = 609\n",
            "  loss = 0.9012195\n",
            ">>>>>>>>>>>>>>>>>>>>Dev Resutls\n",
            "[[ 7 15  1]\n",
            " [15 43 39]\n",
            " [ 8 57 99]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.23      0.30      0.26        23\n",
            "     Neutral       0.37      0.44      0.41        97\n",
            "    Positive       0.71      0.60      0.65       164\n",
            "\n",
            "   micro avg       0.52      0.52      0.52       284\n",
            "   macro avg       0.44      0.45      0.44       284\n",
            "weighted avg       0.56      0.52      0.54       284\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>Train Results\n",
            "[[112  30   3]\n",
            " [ 74 318  51]\n",
            " [ 10 125 778]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.57      0.77      0.66       145\n",
            "     Neutral       0.67      0.72      0.69       443\n",
            "    Positive       0.94      0.85      0.89       913\n",
            "\n",
            "   micro avg       0.80      0.80      0.80      1501\n",
            "   macro avg       0.73      0.78      0.75      1501\n",
            "weighted avg       0.82      0.80      0.81      1501\n",
            "\n",
            "----------------------------next epoch: 14----------------------------\n",
            "***** Started training at 2019-05-16 15:48:28.452184 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "excluded trainable variables: >> [<tf.Variable 'module/bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'module/cls/predictions/output_bias:0' shape=(30522,) dtype=float32>, <tf.Variable 'output_weights:0' shape=(3, 768) dtype=float32>, <tf.Variable 'output_bias:0' shape=(3,) dtype=float32>]\n",
            "***** Finished training at 2019-05-16 15:51:27.021885 *****\n",
            "***** Started evaluation at 2019-05-16 15:51:27.022202 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-05-16 15:52:00.799676 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.53571427\n",
            "  eval_loss = 1.2299111\n",
            "  global_step = 656\n",
            "  loss = 0.9055754\n",
            ">>>>>>>>>>>>>>>>>>>>Dev Resutls\n",
            "[[10 12  1]\n",
            " [16 44 37]\n",
            " [ 9 56 99]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.29      0.43      0.34        23\n",
            "     Neutral       0.39      0.45      0.42        97\n",
            "    Positive       0.72      0.60      0.66       164\n",
            "\n",
            "   micro avg       0.54      0.54      0.54       284\n",
            "   macro avg       0.47      0.50      0.47       284\n",
            "weighted avg       0.57      0.54      0.55       284\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>Train Results\n",
            "[[117  25   3]\n",
            " [ 81 314  48]\n",
            " [ 10 125 778]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.56      0.81      0.66       145\n",
            "     Neutral       0.68      0.71      0.69       443\n",
            "    Positive       0.94      0.85      0.89       913\n",
            "\n",
            "   micro avg       0.81      0.81      0.81      1501\n",
            "   macro avg       0.73      0.79      0.75      1501\n",
            "weighted avg       0.82      0.81      0.81      1501\n",
            "\n",
            "----------------------------next epoch: 15----------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-266efd97bd02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mlabels_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m   \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1501, 284]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khuNEnMw2wiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# labels_val = []\n",
        "# for item in predictions:\n",
        "#   labels_val.append(labels[np.argmax(item[1])])\n",
        "# true_label = list(dev['sentiment'])\n",
        "# print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "# print(metrics.classification_report(y_pred=labels_val,y_true = true_label))\n",
        "# predictions = model_predict(estimator_from_tfhub,dev_InputExamples)\n",
        "# labels_val = []\n",
        "# for item in predictions:\n",
        "#   labels_val.append(labels[np.argmax(item[1])])\n",
        "# true_label = list(dev['sentiment'])\n",
        "# print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "# print(metrics.classification_report(y_pred=labels_val,y_true = true_label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txu5R3dU7VsK",
        "colab_type": "code",
        "outputId": "9ac60202-b448-42ad-cc9a-743c24303da2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "for ckpt in range(920,921,46):\n",
        "  predictions = model_predict(estimator_from_tfhub,train_InputExamples)#,checkpoint_path=OUTPUT_DIR+'/model.ckpt-%d'%ckpt)\n",
        "  labels_val = []\n",
        "  for item in predictions:\n",
        "    labels_val.append(labels[np.argmax(item[1])])\n",
        "  true_label = list(train['sentiment'])\n",
        "  print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "  print(metrics.classification_report(y_pred=labels_val,y_true = true_label))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0  99  46]\n",
            " [  0 216 227]\n",
            " [  0 116 797]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.00      0.00      0.00       145\n",
            "     Neutral       0.50      0.49      0.49       443\n",
            "    Positive       0.74      0.87      0.80       913\n",
            "\n",
            "   micro avg       0.67      0.67      0.67      1501\n",
            "   macro avg       0.42      0.45      0.43      1501\n",
            "weighted avg       0.60      0.67      0.63      1501\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_UcjXvneJD8",
        "colab_type": "code",
        "outputId": "bc4e78bc-631e-4005-d55b-068a4829c087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11648
        }
      },
      "source": [
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.855226 140091562080128 run_classifier.py:774] Writing example 0 of 284\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.865693 140091562080128 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.869920 140091562080128 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] lu ##go fired his army navy and air force commanders on wednesday a day after claiming there were ` ` pockets of coup - plot ##ters ' ' in the armed forces . \" , \" lu ##go ' s opponents in congress are hoping to gather a two - thirds majority to remove him from office under the constitution . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.875982 140091562080128 run_classifier.py:464] tokens: [CLS] lu ##go fired his army navy and air force commanders on wednesday a day after claiming there were ` ` pockets of coup - plot ##ters ' ' in the armed forces . \" , \" lu ##go ' s opponents in congress are hoping to gather a two - thirds majority to remove him from office under the constitution . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 11320 3995 5045 2010 2390 3212 1998 2250 2486 11437 2006 9317 1037 2154 2044 6815 2045 2020 1036 1036 10306 1997 8648 1011 5436 7747 1005 1005 1999 1996 4273 2749 1012 1000 1010 1000 11320 3995 1005 1055 7892 1999 3519 2024 5327 2000 8587 1037 2048 1011 12263 3484 2000 6366 2032 2013 2436 2104 1996 4552 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.882638 140091562080128 run_classifier.py:465] input_ids: 101 11320 3995 5045 2010 2390 3212 1998 2250 2486 11437 2006 9317 1037 2154 2044 6815 2045 2020 1036 1036 10306 1997 8648 1011 5436 7747 1005 1005 1999 1996 4273 2749 1012 1000 1010 1000 11320 3995 1005 1055 7892 1999 3519 2024 5327 2000 8587 1037 2048 1011 12263 3484 2000 6366 2032 2013 2436 2104 1996 4552 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.885298 140091562080128 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.888370 140091562080128 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.891571 140091562080128 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.896246 140091562080128 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.899049 140091562080128 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] rafael nad ##al said he would love to go to the football world cup and watch spain lift the trophy . ' , ' nad ##al said he was due to have treatment on his troubles ##ome knees ahead of the us hard court season . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.903264 140091562080128 run_classifier.py:464] tokens: [CLS] rafael nad ##al said he would love to go to the football world cup and watch spain lift the trophy . ' , ' nad ##al said he was due to have treatment on his troubles ##ome knees ahead of the us hard court season . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 10999 23233 2389 2056 2002 2052 2293 2000 2175 2000 1996 2374 2088 2452 1998 3422 3577 6336 1996 5384 1012 1005 1010 1005 23233 2389 2056 2002 2001 2349 2000 2031 3949 2006 2010 13460 8462 5042 3805 1997 1996 2149 2524 2457 2161 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.905543 140091562080128 run_classifier.py:465] input_ids: 101 10999 23233 2389 2056 2002 2052 2293 2000 2175 2000 1996 2374 2088 2452 1998 3422 3577 6336 1996 5384 1012 1005 1010 1005 23233 2389 2056 2002 2001 2349 2000 2031 3949 2006 2010 13460 8462 5042 3805 1997 1996 2149 2524 2457 2161 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.908771 140091562080128 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.911950 140091562080128 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.915232 140091562080128 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.920871 140091562080128 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.925867 140091562080128 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] schmidt ' s selection comes more than 10 months after obama declared cyber security a priority and ordered a broad administration review . \" , \" schmidt ' s selection suggests that economic and business interests in the white house held more sway in the selection process . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.929264 140091562080128 run_classifier.py:464] tokens: [CLS] schmidt ' s selection comes more than 10 months after obama declared cyber security a priority and ordered a broad administration review . \" , \" schmidt ' s selection suggests that economic and business interests in the white house held more sway in the selection process . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 12940 1005 1055 4989 3310 2062 2084 2184 2706 2044 8112 4161 16941 3036 1037 9470 1998 3641 1037 5041 3447 3319 1012 1000 1010 1000 12940 1005 1055 4989 6083 2008 3171 1998 2449 5426 1999 1996 2317 2160 2218 2062 17812 1999 1996 4989 2832 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.932399 140091562080128 run_classifier.py:465] input_ids: 101 12940 1005 1055 4989 3310 2062 2084 2184 2706 2044 8112 4161 16941 3036 1037 9470 1998 3641 1037 5041 3447 3319 1012 1000 1010 1000 12940 1005 1055 4989 6083 2008 3171 1998 2449 5426 1999 1996 2317 2160 2218 2062 17812 1999 1996 4989 2832 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.935471 140091562080128 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.938620 140091562080128 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.941519 140091562080128 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.946455 140091562080128 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.949655 140091562080128 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] ra ##hee ##m morris declined to name his choice between byron left ##wich and luke mcc ##own on friday until after one last consultation with his coaching staff . ' , ' players were off friday so an announcement could come this morning . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.950999 140091562080128 run_classifier.py:464] tokens: [CLS] ra ##hee ##m morris declined to name his choice between byron left ##wich and luke mcc ##own on friday until after one last consultation with his coaching staff . ' , ' players were off friday so an announcement could come this morning . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 10958 21030 2213 6384 6430 2000 2171 2010 3601 2090 12234 2187 12414 1998 5355 23680 12384 2006 5958 2127 2044 2028 2197 16053 2007 2010 7748 3095 1012 1005 1010 1005 2867 2020 2125 5958 2061 2019 8874 2071 2272 2023 2851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.954091 140091562080128 run_classifier.py:465] input_ids: 101 10958 21030 2213 6384 6430 2000 2171 2010 3601 2090 12234 2187 12414 1998 5355 23680 12384 2006 5958 2127 2044 2028 2197 16053 2007 2010 7748 3095 1012 1005 1010 1005 2867 2020 2125 5958 2061 2019 8874 2071 2272 2023 2851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.957293 140091562080128 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.960699 140091562080128 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.963871 140091562080128 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.968486 140091562080128 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.973494 140091562080128 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] o ##ve ##ch ##kin mal ##kin scored just seconds after the play to give russia a 3 - 1 lead only 1 : 49 into the third period . ' , \" o ##ve ##ch ##kin ' s hit seized momentum for russia and confidence from the czech star in a centre - ice smackdown . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.976593 140091562080128 run_classifier.py:464] tokens: [CLS] o ##ve ##ch ##kin mal ##kin scored just seconds after the play to give russia a 3 - 1 lead only 1 : 49 into the third period . ' , \" o ##ve ##ch ##kin ' s hit seized momentum for russia and confidence from the czech star in a centre - ice smackdown . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1051 3726 2818 4939 15451 4939 3195 2074 3823 2044 1996 2377 2000 2507 3607 1037 1017 1011 1015 2599 2069 1015 1024 4749 2046 1996 2353 2558 1012 1005 1010 1000 1051 3726 2818 4939 1005 1055 2718 8243 11071 2005 3607 1998 7023 2013 1996 5569 2732 1999 1037 2803 1011 3256 22120 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.979393 140091562080128 run_classifier.py:465] input_ids: 101 1051 3726 2818 4939 15451 4939 3195 2074 3823 2044 1996 2377 2000 2507 3607 1037 1017 1011 1015 2599 2069 1015 1024 4749 2046 1996 2353 2558 1012 1005 1010 1000 1051 3726 2818 4939 1005 1055 2718 8243 11071 2005 3607 1998 7023 2013 1996 5569 2732 1999 1037 2803 1011 3256 22120 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.982182 140091562080128 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.985152 140091562080128 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:58.987485 140091562080128 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:37:59.567962 140091562080128 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Features ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:00.519913 140091562080128 <ipython-input-15-803c1b1dc593>:58] *** Features ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = input_ids, shape = (1, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:00.526272 140091562080128 <ipython-input-15-803c1b1dc593>:60]   name = input_ids, shape = (1, 512)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = input_mask, shape = (1, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:00.528106 140091562080128 <ipython-input-15-803c1b1dc593>:60]   name = input_mask, shape = (1, 512)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = label_ids, shape = (1,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:00.529807 140091562080128 <ipython-input-15-803c1b1dc593>:60]   name = label_ids, shape = (1,)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = segment_ids, shape = (1, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:00.531467 140091562080128 <ipython-input-15-803c1b1dc593>:60]   name = segment_ids, shape = (1, 512)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.079229 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.087209 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.093404 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.096971 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.110743 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.130584 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.153541 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.165730 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.172842 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.208750 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.212840 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.224462 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.232605 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.243904 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.252022 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.278029 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.282887 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.294049 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.303219 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.329487 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.336963 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.353475 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.359698 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.366723 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.373500 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.393970 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.400188 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.410840 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.419210 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.434473 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.441649 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.476942 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.482372 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.494415 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.504818 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.524115 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.530622 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.550363 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.555598 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.565763 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.572627 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.601628 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.607945 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.624444 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.629743 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.645636 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.650846 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.675532 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.681684 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.696187 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.705030 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.725759 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.733354 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.751985 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.757056 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.764811 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.773380 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.794020 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.799384 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.809482 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.814821 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.824064 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.831928 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.857409 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.862735 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.871133 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.880337 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.897232 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.907571 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.922868 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.929810 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.938731 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.944698 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.964960 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.973432 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.984359 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:07.989828 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.003529 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.008980 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.038912 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.044025 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.051572 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.056997 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.076462 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.083882 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.099499 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.104803 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.114223 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.120117 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.139574 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.147923 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.158143 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.164275 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.177911 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.183542 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.214996 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.220565 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.229008 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.234905 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.252873 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.262226 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.280015 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.287075 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.295227 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.300741 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.323740 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.331064 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.340720 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.347343 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.360876 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.368588 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.398150 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.404628 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.413191 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.420111 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.437753 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.444202 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.458641 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.465408 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.473510 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.479541 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.501326 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.508364 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.517132 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.522093 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.532192 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.538177 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.563488 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.568219 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.578067 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.583578 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.597058 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.605885 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.622692 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.628945 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.635987 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.642462 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.662249 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.668549 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.681284 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.687423 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.695702 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.706484 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.732640 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.738852 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.747421 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.752018 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.765333 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.772325 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.790015 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.796658 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.804862 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.812408 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.832720 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.839238 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.850848 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.856288 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.866640 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.875353 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.905277 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.911911 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.918967 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.925373 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.946831 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.955534 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.971225 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.979208 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.986553 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:08.994091 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.016267 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.021394 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.030328 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.037487 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.049019 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.056588 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.084439 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.089348 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.099345 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.104757 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.124052 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.132986 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.147350 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.155114 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.164922 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.170428 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.192713 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.200798 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.212984 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.220211 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.233227 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.239499 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.266834 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.272742 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.281358 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.287874 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.305221 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.313142 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.326653 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.332237 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.341331 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.345972 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.403892 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.409063 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.428976 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.435466 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.447779 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.452929 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:38:09.464509 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:09.607867 140091562080128 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:10.246510 140091562080128 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:TPU job name worker\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:10.265635 140091562080128 tpu_estimator.py:447] TPU job name worker\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:10.845268 140091562080128 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from gs://bert_example/bert-tfhub/models/smallBERT-docLevel-seq512/model.ckpt-690\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:10.934354 140091562080128 saver.py:1270] Restoring parameters from gs://bert_example/bert-tfhub/models/smallBERT-docLevel-seq512/model.ckpt-690\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:12.836256 140091562080128 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:13.111696 140091562080128 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Init TPU system\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:13.748660 140091562080128 tpu_estimator.py:504] Init TPU system\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initialized TPU in 7 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:21.315031 140091562080128 tpu_estimator.py:510] Initialized TPU in 7 seconds\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting infeed thread controller.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:21.319279 140089657333504 tpu_estimator.py:463] Starting infeed thread controller.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting outfeed thread controller.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:21.325361 140089648940800 tpu_estimator.py:482] Starting outfeed thread controller.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:21.688081 140091562080128 util.py:51] Initialized dataset iterators in 0 seconds\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:21.971436 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:21.974092 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.632292 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.635029 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.650532 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.658319 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.673890 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.678086 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.692862 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.697355 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.709585 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.712506 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.725132 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.734554 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.743918 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.749017 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.772437 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.775127 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.790405 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.797585 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.807440 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.813872 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.824229 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.832504 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.844888 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.848917 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.859627 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.862801 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.871329 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.874492 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.880450 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.883193 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.891505 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.894738 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.904722 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.908351 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.914937 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.917593 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.923974 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.926935 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.933794 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.936043 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.941135 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.943593 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.949681 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.952873 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.959613 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.962811 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.969105 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.972909 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.983649 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:27.988955 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.000345 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.005194 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.013216 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.016803 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.023988 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.027439 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.034821 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.038541 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.045809 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.049247 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.057823 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.065465 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.076097 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.082494 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.094867 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.099582 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.106988 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.111512 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.118968 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.123375 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:38:28.286058 140091562080128 error_handling.py:93] prediction_loop marked as finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[ 9 14  0]\n",
            " [25 33 39]\n",
            " [16 50 98]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.18      0.39      0.25        23\n",
            "     Neutral       0.34      0.34      0.34        97\n",
            "    Positive       0.72      0.60      0.65       164\n",
            "\n",
            "   micro avg       0.49      0.49      0.49       284\n",
            "   macro avg       0.41      0.44      0.41       284\n",
            "weighted avg       0.54      0.49      0.51       284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1iRIomptlcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNNNZmf5xokl",
        "colab_type": "code",
        "outputId": "772813db-5d9e-432a-cf63-9772a5dd8607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11648
        }
      },
      "source": [
        "ckpt = 690\n",
        "df_doc = dev.copy()\n",
        "predictions = model_predict(estimator_from_tfhub,dev_InputExamples,checkpoint_path=OUTPUT_DIR+'/model.ckpt-%d'%ckpt)\n",
        "labels_val = []\n",
        "for item in predictions:\n",
        "    labels_val.append(labels[np.argmax(item[1])])\n",
        "df_doc['doc_predicted'] = labels_val\n",
        "true_label = list(dev['sentiment'])\n",
        "print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "print(metrics.classification_report(y_pred=labels_val,y_true = true_label))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.245764 140091562080128 run_classifier.py:774] Writing example 0 of 284\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.262032 140091562080128 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.265032 140091562080128 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] lu ##go a former catholic bishop who assumed office in august 2008 sacked rear admiral ci ##ber ben ##ite ##z . he will be replaced by general juan oscar ve ##la ##zquez a former army commander and a lu ##go con ##fi ##dant an official statement said . lu ##go fired his army navy and air force commanders on wednesday a day after claiming there were \" pockets of coup - plot ##ters \" in the armed forces . opponents accuse lu ##go of styling himself after venezuelan president hugo chavez in his focus on helping the poor in this land - locked south american country . lu ##go ' s opponents in congress are hoping to gather a two - thirds majority to remove him from office under the constitution . opponents say that lu ##go has been inc ##omp ##ete ##nt in failing to focus on a crime wave that includes kidnapping ##s and robbery as well as administrative imp ##rop ##rie ##ties . lu ##go ' s support base has been er ##od ##ing under a growing scandal in which three women claim he father ##ed their children while he was a priest . in may he admitted responsibility for one of the children . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.267699 140091562080128 run_classifier.py:464] tokens: [CLS] lu ##go a former catholic bishop who assumed office in august 2008 sacked rear admiral ci ##ber ben ##ite ##z . he will be replaced by general juan oscar ve ##la ##zquez a former army commander and a lu ##go con ##fi ##dant an official statement said . lu ##go fired his army navy and air force commanders on wednesday a day after claiming there were \" pockets of coup - plot ##ters \" in the armed forces . opponents accuse lu ##go of styling himself after venezuelan president hugo chavez in his focus on helping the poor in this land - locked south american country . lu ##go ' s opponents in congress are hoping to gather a two - thirds majority to remove him from office under the constitution . opponents say that lu ##go has been inc ##omp ##ete ##nt in failing to focus on a crime wave that includes kidnapping ##s and robbery as well as administrative imp ##rop ##rie ##ties . lu ##go ' s support base has been er ##od ##ing under a growing scandal in which three women claim he father ##ed their children while he was a priest . in may he admitted responsibility for one of the children . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 11320 3995 1037 2280 3234 3387 2040 5071 2436 1999 2257 2263 14159 4373 5902 25022 5677 3841 4221 2480 1012 2002 2097 2022 2999 2011 2236 5348 7436 2310 2721 22938 1037 2280 2390 3474 1998 1037 11320 3995 9530 8873 28210 2019 2880 4861 2056 1012 11320 3995 5045 2010 2390 3212 1998 2250 2486 11437 2006 9317 1037 2154 2044 6815 2045 2020 1000 10306 1997 8648 1011 5436 7747 1000 1999 1996 4273 2749 1012 7892 26960 11320 3995 1997 20724 2370 2044 15332 2343 9395 16860 1999 2010 3579 2006 5094 1996 3532 1999 2023 2455 1011 5299 2148 2137 2406 1012 11320 3995 1005 1055 7892 1999 3519 2024 5327 2000 8587 1037 2048 1011 12263 3484 2000 6366 2032 2013 2436 2104 1996 4552 1012 7892 2360 2008 11320 3995 2038 2042 4297 25377 12870 3372 1999 7989 2000 3579 2006 1037 4126 4400 2008 2950 15071 2015 1998 13742 2004 2092 2004 3831 17727 18981 7373 7368 1012 11320 3995 1005 1055 2490 2918 2038 2042 9413 7716 2075 2104 1037 3652 9446 1999 2029 2093 2308 4366 2002 2269 2098 2037 2336 2096 2002 2001 1037 5011 1012 1999 2089 2002 4914 5368 2005 2028 1997 1996 2336 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.271424 140091562080128 run_classifier.py:465] input_ids: 101 11320 3995 1037 2280 3234 3387 2040 5071 2436 1999 2257 2263 14159 4373 5902 25022 5677 3841 4221 2480 1012 2002 2097 2022 2999 2011 2236 5348 7436 2310 2721 22938 1037 2280 2390 3474 1998 1037 11320 3995 9530 8873 28210 2019 2880 4861 2056 1012 11320 3995 5045 2010 2390 3212 1998 2250 2486 11437 2006 9317 1037 2154 2044 6815 2045 2020 1000 10306 1997 8648 1011 5436 7747 1000 1999 1996 4273 2749 1012 7892 26960 11320 3995 1997 20724 2370 2044 15332 2343 9395 16860 1999 2010 3579 2006 5094 1996 3532 1999 2023 2455 1011 5299 2148 2137 2406 1012 11320 3995 1005 1055 7892 1999 3519 2024 5327 2000 8587 1037 2048 1011 12263 3484 2000 6366 2032 2013 2436 2104 1996 4552 1012 7892 2360 2008 11320 3995 2038 2042 4297 25377 12870 3372 1999 7989 2000 3579 2006 1037 4126 4400 2008 2950 15071 2015 1998 13742 2004 2092 2004 3831 17727 18981 7373 7368 1012 11320 3995 1005 1055 2490 2918 2038 2042 9413 7716 2075 2104 1037 3652 9446 1999 2029 2093 2308 4366 2002 2269 2098 2037 2336 2096 2002 2001 1037 5011 1012 1999 2089 2002 4914 5368 2005 2028 1997 1996 2336 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.274502 140091562080128 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.277048 140091562080128 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.280070 140091562080128 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.289273 140091562080128 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.292098 140091562080128 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] spanish wimbledon winner rafael nad ##al said sunday he would love to go to the football world cup and watch spain lift the trophy . nad ##al said he was due to have treatment on his troubles ##ome knees ahead of the us hard court season but might be able to jet out to south africa to cheer on his com ##pa ##tri ##ots . \" i would love to be there it ' s my favourite sport \" nad ##al said after winning his second wimbledon title . \" i have to think . i don ' t know it ' s very far . if the world cup was in europe it would be much easier for me . but in south africa it ' s a very long trip so i don ' t know . \" but for me it would be a pleasure to be there . i am a crazy fan of football and for sure a big supporter of our team . i am in contact with the players . i just wish the team all the best . \" [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.294814 140091562080128 run_classifier.py:464] tokens: [CLS] spanish wimbledon winner rafael nad ##al said sunday he would love to go to the football world cup and watch spain lift the trophy . nad ##al said he was due to have treatment on his troubles ##ome knees ahead of the us hard court season but might be able to jet out to south africa to cheer on his com ##pa ##tri ##ots . \" i would love to be there it ' s my favourite sport \" nad ##al said after winning his second wimbledon title . \" i have to think . i don ' t know it ' s very far . if the world cup was in europe it would be much easier for me . but in south africa it ' s a very long trip so i don ' t know . \" but for me it would be a pleasure to be there . i am a crazy fan of football and for sure a big supporter of our team . i am in contact with the players . i just wish the team all the best . \" [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3009 13411 3453 10999 23233 2389 2056 4465 2002 2052 2293 2000 2175 2000 1996 2374 2088 2452 1998 3422 3577 6336 1996 5384 1012 23233 2389 2056 2002 2001 2349 2000 2031 3949 2006 2010 13460 8462 5042 3805 1997 1996 2149 2524 2457 2161 2021 2453 2022 2583 2000 6892 2041 2000 2148 3088 2000 15138 2006 2010 4012 4502 18886 12868 1012 1000 1045 2052 2293 2000 2022 2045 2009 1005 1055 2026 8837 4368 1000 23233 2389 2056 2044 3045 2010 2117 13411 2516 1012 1000 1045 2031 2000 2228 1012 1045 2123 1005 1056 2113 2009 1005 1055 2200 2521 1012 2065 1996 2088 2452 2001 1999 2885 2009 2052 2022 2172 6082 2005 2033 1012 2021 1999 2148 3088 2009 1005 1055 1037 2200 2146 4440 2061 1045 2123 1005 1056 2113 1012 1000 2021 2005 2033 2009 2052 2022 1037 5165 2000 2022 2045 1012 1045 2572 1037 4689 5470 1997 2374 1998 2005 2469 1037 2502 10129 1997 2256 2136 1012 1045 2572 1999 3967 2007 1996 2867 1012 1045 2074 4299 1996 2136 2035 1996 2190 1012 1000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.297549 140091562080128 run_classifier.py:465] input_ids: 101 3009 13411 3453 10999 23233 2389 2056 4465 2002 2052 2293 2000 2175 2000 1996 2374 2088 2452 1998 3422 3577 6336 1996 5384 1012 23233 2389 2056 2002 2001 2349 2000 2031 3949 2006 2010 13460 8462 5042 3805 1997 1996 2149 2524 2457 2161 2021 2453 2022 2583 2000 6892 2041 2000 2148 3088 2000 15138 2006 2010 4012 4502 18886 12868 1012 1000 1045 2052 2293 2000 2022 2045 2009 1005 1055 2026 8837 4368 1000 23233 2389 2056 2044 3045 2010 2117 13411 2516 1012 1000 1045 2031 2000 2228 1012 1045 2123 1005 1056 2113 2009 1005 1055 2200 2521 1012 2065 1996 2088 2452 2001 1999 2885 2009 2052 2022 2172 6082 2005 2033 1012 2021 1999 2148 3088 2009 1005 1055 1037 2200 2146 4440 2061 1045 2123 1005 1056 2113 1012 1000 2021 2005 2033 2009 2052 2022 1037 5165 2000 2022 2045 1012 1045 2572 1037 4689 5470 1997 2374 1998 2005 2469 1037 2502 10129 1997 2256 2136 1012 1045 2572 1999 3967 2007 1996 2867 1012 1045 2074 4299 1996 2136 2035 1996 2190 1012 1000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.300092 140091562080128 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.302508 140091562080128 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.304653 140091562080128 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.318891 140091562080128 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.321793 140091562080128 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] in a letter posted on the white house web site tuesday john brennan assistant to president barack obama for homeland security and counter ##ter ##ror ##ism said schmidt will have regular access to the president and play a vital role in the country ' s security . schmidt ' s selection comes more than 10 months after obama declared cyber security a priority and ordered a broad administration review . a senior white house official said obama was personally involved in the selection process and chose schmidt because of his unique background and skills . schmidt will have regular and direct access to the president for cyber security issues the official said . the official spoke on the condition of an ##ony ##mity to discuss the selection process . at the same time cyber experts and potential job candidates have complained that the position lacks the budget ##ary and policy - making authority needed to be successful . schmidt will report to the national security council and closely support the national economic council on cyber issues . schmidt ' s selection suggests that economic and business interests in the white house held more sway in the selection process . schmidt president and ceo of the information security forum a nonprofit international consortium that conducts research in information security has served as chief security officer for microsoft and as cyber security chief for online auction giant e ##bay . he was reportedly preferred by lawrence summers director of the economic council . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.324518 140091562080128 run_classifier.py:464] tokens: [CLS] in a letter posted on the white house web site tuesday john brennan assistant to president barack obama for homeland security and counter ##ter ##ror ##ism said schmidt will have regular access to the president and play a vital role in the country ' s security . schmidt ' s selection comes more than 10 months after obama declared cyber security a priority and ordered a broad administration review . a senior white house official said obama was personally involved in the selection process and chose schmidt because of his unique background and skills . schmidt will have regular and direct access to the president for cyber security issues the official said . the official spoke on the condition of an ##ony ##mity to discuss the selection process . at the same time cyber experts and potential job candidates have complained that the position lacks the budget ##ary and policy - making authority needed to be successful . schmidt will report to the national security council and closely support the national economic council on cyber issues . schmidt ' s selection suggests that economic and business interests in the white house held more sway in the selection process . schmidt president and ceo of the information security forum a nonprofit international consortium that conducts research in information security has served as chief security officer for microsoft and as cyber security chief for online auction giant e ##bay . he was reportedly preferred by lawrence summers director of the economic council . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1999 1037 3661 6866 2006 1996 2317 2160 4773 2609 9857 2198 13962 3353 2000 2343 13857 8112 2005 10759 3036 1998 4675 3334 29165 2964 2056 12940 2097 2031 3180 3229 2000 1996 2343 1998 2377 1037 8995 2535 1999 1996 2406 1005 1055 3036 1012 12940 1005 1055 4989 3310 2062 2084 2184 2706 2044 8112 4161 16941 3036 1037 9470 1998 3641 1037 5041 3447 3319 1012 1037 3026 2317 2160 2880 2056 8112 2001 7714 2920 1999 1996 4989 2832 1998 4900 12940 2138 1997 2010 4310 4281 1998 4813 1012 12940 2097 2031 3180 1998 3622 3229 2000 1996 2343 2005 16941 3036 3314 1996 2880 2056 1012 1996 2880 3764 2006 1996 4650 1997 2019 16585 16383 2000 6848 1996 4989 2832 1012 2012 1996 2168 2051 16941 8519 1998 4022 3105 5347 2031 10865 2008 1996 2597 14087 1996 5166 5649 1998 3343 1011 2437 3691 2734 2000 2022 3144 1012 12940 2097 3189 2000 1996 2120 3036 2473 1998 4876 2490 1996 2120 3171 2473 2006 16941 3314 1012 12940 1005 1055 4989 6083 2008 3171 1998 2449 5426 1999 1996 2317 2160 2218 2062 17812 1999 1996 4989 2832 1012 12940 2343 1998 5766 1997 1996 2592 3036 7057 1037 14495 2248 12360 2008 17976 2470 1999 2592 3036 2038 2366 2004 2708 3036 2961 2005 7513 1998 2004 16941 3036 2708 2005 3784 10470 5016 1041 15907 1012 2002 2001 7283 6871 2011 5623 10945 2472 1997 1996 3171 2473 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.326922 140091562080128 run_classifier.py:465] input_ids: 101 1999 1037 3661 6866 2006 1996 2317 2160 4773 2609 9857 2198 13962 3353 2000 2343 13857 8112 2005 10759 3036 1998 4675 3334 29165 2964 2056 12940 2097 2031 3180 3229 2000 1996 2343 1998 2377 1037 8995 2535 1999 1996 2406 1005 1055 3036 1012 12940 1005 1055 4989 3310 2062 2084 2184 2706 2044 8112 4161 16941 3036 1037 9470 1998 3641 1037 5041 3447 3319 1012 1037 3026 2317 2160 2880 2056 8112 2001 7714 2920 1999 1996 4989 2832 1998 4900 12940 2138 1997 2010 4310 4281 1998 4813 1012 12940 2097 2031 3180 1998 3622 3229 2000 1996 2343 2005 16941 3036 3314 1996 2880 2056 1012 1996 2880 3764 2006 1996 4650 1997 2019 16585 16383 2000 6848 1996 4989 2832 1012 2012 1996 2168 2051 16941 8519 1998 4022 3105 5347 2031 10865 2008 1996 2597 14087 1996 5166 5649 1998 3343 1011 2437 3691 2734 2000 2022 3144 1012 12940 2097 3189 2000 1996 2120 3036 2473 1998 4876 2490 1996 2120 3171 2473 2006 16941 3314 1012 12940 1005 1055 4989 6083 2008 3171 1998 2449 5426 1999 1996 2317 2160 2218 2062 17812 1999 1996 4989 2832 1012 12940 2343 1998 5766 1997 1996 2592 3036 7057 1037 14495 2248 12360 2008 17976 2470 1999 2592 3036 2038 2366 2004 2708 3036 2961 2005 7513 1998 2004 16941 3036 2708 2005 3784 10470 5016 1041 15907 1012 2002 2001 7283 6871 2011 5623 10945 2472 1997 1996 3171 2473 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.329663 140091562080128 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.331855 140091562080128 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.334073 140091562080128 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.342345 140091562080128 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.345189 140091562080128 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] tampa at least ra ##hee ##m morris finally has the name of the bu ##cs ' starting quarterback in the back of his mind . he wants to make sure he made the decision with his head and not just his heart . that ' s why morris declined to name his choice between byron left ##wich and luke mcc ##own on friday until after one last consultation with his coaching staff . after that morris said he would inform the owners then his team before making the eagerly awaited announcement . players were off friday so an announcement could come this morning . \" we ' ll have a decision here in the near future \" morris said . \" i think we ' ve got to go with who we think gives us the best chance to win . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.354633 140091562080128 run_classifier.py:464] tokens: [CLS] tampa at least ra ##hee ##m morris finally has the name of the bu ##cs ' starting quarterback in the back of his mind . he wants to make sure he made the decision with his head and not just his heart . that ' s why morris declined to name his choice between byron left ##wich and luke mcc ##own on friday until after one last consultation with his coaching staff . after that morris said he would inform the owners then his team before making the eagerly awaited announcement . players were off friday so an announcement could come this morning . \" we ' ll have a decision here in the near future \" morris said . \" i think we ' ve got to go with who we think gives us the best chance to win . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 9925 2012 2560 10958 21030 2213 6384 2633 2038 1996 2171 1997 1996 20934 6169 1005 3225 9074 1999 1996 2067 1997 2010 2568 1012 2002 4122 2000 2191 2469 2002 2081 1996 3247 2007 2010 2132 1998 2025 2074 2010 2540 1012 2008 1005 1055 2339 6384 6430 2000 2171 2010 3601 2090 12234 2187 12414 1998 5355 23680 12384 2006 5958 2127 2044 2028 2197 16053 2007 2010 7748 3095 1012 2044 2008 6384 2056 2002 2052 12367 1996 5608 2059 2010 2136 2077 2437 1996 17858 19605 8874 1012 2867 2020 2125 5958 2061 2019 8874 2071 2272 2023 2851 1012 1000 2057 1005 2222 2031 1037 3247 2182 1999 1996 2379 2925 1000 6384 2056 1012 1000 1045 2228 2057 1005 2310 2288 2000 2175 2007 2040 2057 2228 3957 2149 1996 2190 3382 2000 2663 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.357296 140091562080128 run_classifier.py:465] input_ids: 101 9925 2012 2560 10958 21030 2213 6384 2633 2038 1996 2171 1997 1996 20934 6169 1005 3225 9074 1999 1996 2067 1997 2010 2568 1012 2002 4122 2000 2191 2469 2002 2081 1996 3247 2007 2010 2132 1998 2025 2074 2010 2540 1012 2008 1005 1055 2339 6384 6430 2000 2171 2010 3601 2090 12234 2187 12414 1998 5355 23680 12384 2006 5958 2127 2044 2028 2197 16053 2007 2010 7748 3095 1012 2044 2008 6384 2056 2002 2052 12367 1996 5608 2059 2010 2136 2077 2437 1996 17858 19605 8874 1012 2867 2020 2125 5958 2061 2019 8874 2071 2272 2023 2851 1012 1000 2057 1005 2222 2031 1037 3247 2182 1999 1996 2379 2925 1000 6384 2056 1012 1000 1045 2228 2057 1005 2310 2288 2000 2175 2007 2040 2057 2228 3957 2149 1996 2190 3382 2000 2663 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.359647 140091562080128 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.362076 140091562080128 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.364209 140091562080128 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.376499 140091562080128 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.379235 140091562080128 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] o ##ve ##ch ##kin the star of a new generation simply devastated ja ##gr a 1990s nhl superstar playing in russia with a body slam into the upper chest that broke ja ##gr ' s helmet vis ##or and sent a spirit - crushing message to the other czech ##s . \" it is just a moment \" o ##ve ##ch ##kin said . \" if i have a chance to hit somebody it does not matter who it is . \" o ##ve ##ch ##kin ' s hit seized momentum for russia and confidence from the czech star in a centre - ice smackdown . ev ##gen ##i mal ##kin scored just seconds after the play to give russia a 3 - 1 lead only 1 : 49 into the third period . o ##ve ##ch ##kin watched the videos ##creen replay of his check along with an audience that repeated o ##oh ##s and aa ##hs with each look . ja ##gr skate ##d off after the russian goal and slammed the door to the team bench in frustration . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.381659 140091562080128 run_classifier.py:464] tokens: [CLS] o ##ve ##ch ##kin the star of a new generation simply devastated ja ##gr a 1990s nhl superstar playing in russia with a body slam into the upper chest that broke ja ##gr ' s helmet vis ##or and sent a spirit - crushing message to the other czech ##s . \" it is just a moment \" o ##ve ##ch ##kin said . \" if i have a chance to hit somebody it does not matter who it is . \" o ##ve ##ch ##kin ' s hit seized momentum for russia and confidence from the czech star in a centre - ice smackdown . ev ##gen ##i mal ##kin scored just seconds after the play to give russia a 3 - 1 lead only 1 : 49 into the third period . o ##ve ##ch ##kin watched the videos ##creen replay of his check along with an audience that repeated o ##oh ##s and aa ##hs with each look . ja ##gr skate ##d off after the russian goal and slammed the door to the team bench in frustration . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1051 3726 2818 4939 1996 2732 1997 1037 2047 4245 3432 13879 14855 16523 1037 4134 7097 18795 2652 1999 3607 2007 1037 2303 9555 2046 1996 3356 3108 2008 3631 14855 16523 1005 1055 10412 25292 2953 1998 2741 1037 4382 1011 14527 4471 2000 1996 2060 5569 2015 1012 1000 2009 2003 2074 1037 2617 1000 1051 3726 2818 4939 2056 1012 1000 2065 1045 2031 1037 3382 2000 2718 8307 2009 2515 2025 3043 2040 2009 2003 1012 1000 1051 3726 2818 4939 1005 1055 2718 8243 11071 2005 3607 1998 7023 2013 1996 5569 2732 1999 1037 2803 1011 3256 22120 1012 23408 6914 2072 15451 4939 3195 2074 3823 2044 1996 2377 2000 2507 3607 1037 1017 1011 1015 2599 2069 1015 1024 4749 2046 1996 2353 2558 1012 1051 3726 2818 4939 3427 1996 6876 24410 15712 1997 2010 4638 2247 2007 2019 4378 2008 5567 1051 11631 2015 1998 9779 7898 2007 2169 2298 1012 14855 16523 17260 2094 2125 2044 1996 2845 3125 1998 7549 1996 2341 2000 1996 2136 6847 1999 9135 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.384181 140091562080128 run_classifier.py:465] input_ids: 101 1051 3726 2818 4939 1996 2732 1997 1037 2047 4245 3432 13879 14855 16523 1037 4134 7097 18795 2652 1999 3607 2007 1037 2303 9555 2046 1996 3356 3108 2008 3631 14855 16523 1005 1055 10412 25292 2953 1998 2741 1037 4382 1011 14527 4471 2000 1996 2060 5569 2015 1012 1000 2009 2003 2074 1037 2617 1000 1051 3726 2818 4939 2056 1012 1000 2065 1045 2031 1037 3382 2000 2718 8307 2009 2515 2025 3043 2040 2009 2003 1012 1000 1051 3726 2818 4939 1005 1055 2718 8243 11071 2005 3607 1998 7023 2013 1996 5569 2732 1999 1037 2803 1011 3256 22120 1012 23408 6914 2072 15451 4939 3195 2074 3823 2044 1996 2377 2000 2507 3607 1037 1017 1011 1015 2599 2069 1015 1024 4749 2046 1996 2353 2558 1012 1051 3726 2818 4939 3427 1996 6876 24410 15712 1997 2010 4638 2247 2007 2019 4378 2008 5567 1051 11631 2015 1998 9779 7898 2007 2169 2298 1012 14855 16523 17260 2094 2125 2044 1996 2845 3125 1998 7549 1996 2341 2000 1996 2136 6847 1999 9135 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.386728 140091562080128 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.389074 140091562080128 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:33.391138 140091562080128 run_classifier.py:468] label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:36.130336 140091562080128 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Features ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:37.100954 140091562080128 <ipython-input-15-803c1b1dc593>:58] *** Features ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = input_ids, shape = (1, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:37.103066 140091562080128 <ipython-input-15-803c1b1dc593>:60]   name = input_ids, shape = (1, 512)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = input_mask, shape = (1, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:37.115503 140091562080128 <ipython-input-15-803c1b1dc593>:60]   name = input_mask, shape = (1, 512)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = label_ids, shape = (1,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:37.124032 140091562080128 <ipython-input-15-803c1b1dc593>:60]   name = label_ids, shape = (1,)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = segment_ids, shape = (1, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:37.129062 140091562080128 <ipython-input-15-803c1b1dc593>:60]   name = segment_ids, shape = (1, 512)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.475286 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.478106 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.487035 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.507276 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.520284 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.536127 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.552182 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.563360 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.568428 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.596995 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.601186 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.613204 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.624281 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.632601 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.637217 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.657938 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.663057 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.669409 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.674734 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.690701 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.697362 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.712286 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.716995 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.725372 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.730375 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.746843 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.753964 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.762444 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.770513 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.782198 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.788069 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.813894 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.820890 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.829361 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.834609 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.849247 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.857223 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.874469 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.883467 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.893151 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.898653 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.917550 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.923594 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.936115 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.941817 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.952713 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.959423 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.986054 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:42.994451 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.001493 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.006891 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.021423 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.028641 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.044343 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.050434 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.058808 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.064481 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.086205 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.095458 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.105643 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.111968 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.125756 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.133383 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.160257 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.167402 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.175082 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.181190 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.196626 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.205825 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.222506 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.228785 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.238137 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.243324 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.267175 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.273430 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.283530 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.291249 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.301621 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.308134 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.334007 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.340322 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.347042 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.353013 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.368211 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.376811 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.392523 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.399130 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.405580 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.414035 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.433383 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.439290 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.450932 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.456338 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.469444 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.476066 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.503077 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.508935 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.517520 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.522372 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.537192 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.544382 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.559268 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.565200 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.574454 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.581665 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.601907 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.607506 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.618396 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.623744 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.631977 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.638976 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.666950 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.673176 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.682543 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.687881 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.702639 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.711891 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.727566 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.732074 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.741334 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.745629 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.763334 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.770441 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.785250 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.789702 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.797727 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.804847 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.828778 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.833956 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.841361 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.847044 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.859062 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.864579 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.879769 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.885338 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.892899 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.897133 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.917331 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.922213 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.931814 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.936711 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.945135 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.951051 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.974486 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.980088 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.987943 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:43.995138 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.010853 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.016500 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.030215 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.037961 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.045485 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.051876 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.071564 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.076466 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.086174 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.091317 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.103923 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.108649 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.131373 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.138223 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.144753 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.152007 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.165147 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.171374 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.186408 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.192930 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.201773 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.206788 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.225735 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.231116 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.239831 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.244129 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.254743 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.259609 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.285024 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.291958 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.301304 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.308384 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.322658 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.328489 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.343274 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.350666 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.359302 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.364043 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.384762 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.391752 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.403120 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.410656 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.420229 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.425084 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.450839 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.456660 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.463587 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.468077 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.481651 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.488828 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.504663 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.512707 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.519512 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.526040 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.583560 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.590045 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.612966 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.618304 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.632545 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.637727 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0501 21:40:44.649821 140091562080128 tpu.py:330] Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:44.822707 140091562080128 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:47.183670 140091562080128 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:TPU job name worker\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:47.195955 140091562080128 tpu_estimator.py:447] TPU job name worker\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:47.771687 140091562080128 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from gs://bert_example/bert-tfhub/models/smallBERT-docLevel-seq512/model.ckpt-690\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:47.863957 140091562080128 saver.py:1270] Restoring parameters from gs://bert_example/bert-tfhub/models/smallBERT-docLevel-seq512/model.ckpt-690\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:49.795025 140091562080128 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:50.092113 140091562080128 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Init TPU system\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:50.723706 140091562080128 tpu_estimator.py:504] Init TPU system\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initialized TPU in 7 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:58.099781 140091562080128 tpu_estimator.py:510] Initialized TPU in 7 seconds\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting infeed thread controller.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:58.106923 140089545377536 tpu_estimator.py:463] Starting infeed thread controller.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting outfeed thread controller.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:58.110433 140089536984832 tpu_estimator.py:482] Starting outfeed thread controller.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:58.444339 140091562080128 util.py:51] Initialized dataset iterators in 0 seconds\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:58.732636 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:40:58.735471 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.018963 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.021318 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.030359 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.046613 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.058530 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.061877 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.069677 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.073035 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.079898 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.083796 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.090647 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.094270 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.102579 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.106128 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.114093 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.118592 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.126298 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.130748 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.138542 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.142227 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.150120 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.154093 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.163431 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.167062 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.177408 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.181296 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.189738 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.193730 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.202233 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.205823 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.219558 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.224005 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.234838 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.241700 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.255172 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.260459 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.276246 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.282423 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.294018 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.302232 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.320142 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.324856 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.337232 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.343600 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.356185 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.359935 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.375703 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.380125 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.391808 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.398472 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.413861 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.418365 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.426717 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.430145 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.438225 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.442575 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.449827 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.453473 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.460536 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.465193 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.471502 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.475146 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.481990 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.485480 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.493530 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.497874 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.505868 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.509459 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.517671 140091562080128 tpu_estimator.py:536] Enqueue next (1) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.523036 140091562080128 tpu_estimator.py:540] Dequeue next (1) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0501 21:41:04.697737 140091562080128 error_handling.py:93] prediction_loop marked as finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[ 11   9   3]\n",
            " [  9  34  54]\n",
            " [  9  30 125]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.38      0.48      0.42        23\n",
            "     Neutral       0.47      0.35      0.40        97\n",
            "    Positive       0.69      0.76      0.72       164\n",
            "\n",
            "   micro avg       0.60      0.60      0.60       284\n",
            "   macro avg       0.51      0.53      0.52       284\n",
            "weighted avg       0.59      0.60      0.59       284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o3ecaNzePB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # df_summary['doc_predicted']=list(df_doc['doc_predicted'])\n",
        "# print(metrics.classification_report(y_pred=df_summary['doc_predicted'],y_true=df_summary['sentiment']))\n",
        "# print(metrics.classification_report(y_pred=df_summary['summary_predicted'],y_true = df_summary['sentiment']))\n",
        "\n",
        "df_summary.to_csv('summary_classified.csv',encoding='latin1')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV5SpMUg7b9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.logging.set_verbosity(tf.logging.DEBUG) #DEBUG,ERROR,FATAL,INFO,WARN\n",
        "# predictions = model_predict(estimator_from_tfhub,test_InputExamples)\n",
        "labels_val = []\n",
        "for item in predictions:\n",
        "  labels_val.append(labels[np.argmax(item[1])])\n",
        "true_label = list(test['sentiment'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqh11HPVAsvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####seq 128, Small BERT, Batchsize 32 for train, 8 for dev and test\n",
        "# 1)I0423 16:57:01.507206 140076901431168 basic_session_run_hooks.py:249] loss = 0.40919852, step = 46\n",
        "# 2)I0423 18:08:31.116359 140500355729280 basic_session_run_hooks.py:249] loss = 0.7756149, step = 92\n",
        "# 4)Loss for final step: 0.6891643.\n",
        "# 5)Loss for final step: 0.9730371\n",
        "# 6)Loss for final step: 0.4775733\n",
        "# 7)Loss for final step: 1.2802429.\n",
        "# 8)Loss for final step: 0.509207\n",
        "# 9)loss = 0.29262337, step = 414\n",
        "# 10)Loss for final step: 0.47267017\n",
        "\n",
        "\n",
        "# 2)***** Eval results *****\n",
        "#   eval_accuracy = 0.5857143\n",
        "#   eval_loss = 0.8630275\n",
        "#   global_step = 92\n",
        "#   loss = 0.79767215\n",
        "# 3)***** Eval results *****\n",
        "#   eval_accuracy = 0.5857143\n",
        "#   eval_loss = 0.8630275\n",
        "#   global_step = 138\n",
        "#   loss = 0.79767215\n",
        "# 4)***** Eval results *****\n",
        "#   eval_accuracy = 0.5857143\n",
        "#   eval_loss = 0.86550355\n",
        "#   global_step = 184\n",
        "#   loss = 0.83540887\n",
        "# 5)***** Eval results *****\n",
        "#   eval_accuracy = 0.5964286\n",
        "#   eval_loss = 0.88053304\n",
        "#   global_step = 230\n",
        "#   loss = 0.91362196\n",
        "# 6)***** Eval results *****\n",
        "#   eval_accuracy = 0.5857143\n",
        "#   eval_loss = 0.90498805\n",
        "#   global_step = 276\n",
        "#   loss = 1.0806552\n",
        "# 7)***** Eval results *****\n",
        "#   eval_accuracy = 0.56785715\n",
        "#   eval_loss = 0.92742974\n",
        "#   global_step = 322\n",
        "#   loss = 1.0180835\n",
        "# 8)***** Eval results *****\n",
        "#   eval_accuracy = 0.5607143\n",
        "#   eval_loss = 0.9436406\n",
        "#   global_step = 368\n",
        "#   loss = 0.9721719\n",
        "# 9)***** Eval results *****\n",
        "#   eval_accuracy = 0.5607143\n",
        "#   eval_loss = 0.9714315\n",
        "#   global_step = 414\n",
        "#   loss = 0.5798999\n",
        "# 10)***** Eval results *****\n",
        "#   eval_accuracy = 0.54285717\n",
        "#   eval_loss = 1.0072392\n",
        "#   global_step = 460\n",
        "#   loss = 1.053762\n",
        "  \n",
        "#   DEV Info:\n",
        "# 1)[[  0   0  23]\n",
        "#  [  0   0  97]\n",
        "#  [  0   0 164]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.00      0.00      0.00        97\n",
        "#     Positive       0.58      1.00      0.73       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.19      0.33      0.24       284\n",
        "# weighted avg       0.33      0.58      0.42       284\n",
        "# 2)[[  0   9  14]\n",
        "#  [  0  25  72]\n",
        "#  [  0  21 143]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.45      0.26      0.33        97\n",
        "#     Positive       0.62      0.87      0.73       164\n",
        "\n",
        "#    micro avg       0.59      0.59      0.59       284\n",
        "#    macro avg       0.36      0.38      0.35       284\n",
        "# weighted avg       0.52      0.59      0.53       284\n",
        "# 3)[[  0   9  14]\n",
        "#  [  0  25  72]\n",
        "#  [  0  21 143]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.45      0.26      0.33        97\n",
        "#     Positive       0.62      0.87      0.73       164\n",
        "\n",
        "#    micro avg       0.59      0.59      0.59       284\n",
        "#    macro avg       0.36      0.38      0.35       284\n",
        "# weighted avg       0.52      0.59      0.53       284\n",
        "# 4)[[  0   8  42]\n",
        "#  [  0  16 100]\n",
        "#  [  0  17 157]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        50\n",
        "#      Neutral       0.39      0.14      0.20       116\n",
        "#     Positive       0.53      0.90      0.66       174\n",
        "\n",
        "#    micro avg       0.51      0.51      0.51       340\n",
        "#    macro avg       0.31      0.35      0.29       340\n",
        "# weighted avg       0.40      0.51      0.41       340\n",
        "# 5)[[  0  17   6]\n",
        "#  [  0  40  57]\n",
        "#  [  0  35 129]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.43      0.41      0.42        97\n",
        "#     Positive       0.67      0.79      0.72       164\n",
        "\n",
        "#    micro avg       0.60      0.60      0.60       284\n",
        "#    macro avg       0.37      0.40      0.38       284\n",
        "# weighted avg       0.54      0.60      0.56       284\n",
        "# 6)[[  0  19   4]\n",
        "#  [  0  44  53]\n",
        "#  [  0  42 122]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.42      0.45      0.44        97\n",
        "#     Positive       0.68      0.74      0.71       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.37      0.40      0.38       284\n",
        "# weighted avg       0.54      0.58      0.56       284\n",
        "# 7)[[  0  18   5]\n",
        "#  [  0  46  51]\n",
        "#  [  0  47 117]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.41      0.47      0.44        97\n",
        "#     Positive       0.68      0.71      0.69       164\n",
        "\n",
        "#    micro avg       0.57      0.57      0.57       284\n",
        "#    macro avg       0.36      0.40      0.38       284\n",
        "# weighted avg       0.53      0.57      0.55       284\n",
        "# 8)[[  0  18   5]\n",
        "#  [  0  48  49]\n",
        "#  [  0  53 111]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.40      0.49      0.44        97\n",
        "#     Positive       0.67      0.68      0.67       164\n",
        "\n",
        "#    micro avg       0.56      0.56      0.56       284\n",
        "#    macro avg       0.36      0.39      0.37       284\n",
        "# weighted avg       0.53      0.56      0.54       284\n",
        "# 9)[[  0  18   5]\n",
        "#  [  0  48  49]\n",
        "#  [  0  54 110]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.40      0.49      0.44        97\n",
        "#     Positive       0.67      0.67      0.67       164\n",
        "\n",
        "#    micro avg       0.56      0.56      0.56       284\n",
        "#    macro avg       0.36      0.39      0.37       284\n",
        "# weighted avg       0.52      0.56      0.54       284\n",
        "# 10)[[  0  18   5]\n",
        "#  [  0  51  46]\n",
        "#  [  0  62 102]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.39      0.53      0.45        97\n",
        "#     Positive       0.67      0.62      0.64       164\n",
        "\n",
        "#    micro avg       0.54      0.54      0.54       284\n",
        "#    macro avg       0.35      0.38      0.36       284\n",
        "# weighted avg       0.52      0.54      0.52       284\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0h7wMprmvyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### Seq:256, small BERT, batch size 32 for train, 8 for test and dev\n",
        "# 3) {'loss': 0.79650426, 'eval_accuracy': 0.58214283, 'eval_loss': 0.86125755, 'global_step': 138}\n",
        "# [[  0   0  23]\n",
        "#  [  0   0  97]\n",
        "#  [  0   0 164]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.00      0.00      0.00        97\n",
        "#     Positive       0.58      1.00      0.73       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.19      0.33      0.24       284\n",
        "# weighted avg       0.33      0.58      0.42       284\n",
        "\n",
        "# 4) {'loss': 0.73700047, 'eval_accuracy': 0.5928571, 'eval_loss': 0.8223035, 'global_step': 184}\n",
        "# [[  0  11  12]\n",
        "#  [  0  20  77]\n",
        "#  [  0  17 147]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.42      0.21      0.28        97\n",
        "#     Positive       0.62      0.90      0.73       164\n",
        "\n",
        "#    micro avg       0.59      0.59      0.59       284\n",
        "#    macro avg       0.35      0.37      0.34       284\n",
        "# weighted avg       0.50      0.59      0.52       284\n",
        "\n",
        "# 5) {'loss': 0.71594626, 'eval_accuracy': 0.5928571, 'eval_loss': 0.82239425, 'global_step': 230}\n",
        "# [[  0  19   4]\n",
        "#  [  0  51  46]\n",
        "#  [  0  48 116]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.43      0.53      0.47        97\n",
        "#     Positive       0.70      0.71      0.70       164\n",
        "\n",
        "#    micro avg       0.59      0.59      0.59       284\n",
        "#    macro avg       0.38      0.41      0.39       284\n",
        "# weighted avg       0.55      0.59      0.57       284\n",
        "\n",
        "# 6) {'loss': 0.7227276, 'eval_accuracy': 0.5857143, 'eval_loss': 0.8479867, 'global_step': 276}\n",
        "# [[  0  21   2]\n",
        "#  [  2  51  44]\n",
        "#  [  1  49 114]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.42      0.53      0.47        97\n",
        "#     Positive       0.71      0.70      0.70       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.38      0.41      0.39       284\n",
        "# weighted avg       0.56      0.58      0.57       284\n",
        "\n",
        "# 7){'loss': 0.83304703, 'eval_accuracy': 0.5642857, 'eval_loss': 0.90589315, 'global_step': 322}\n",
        "# [[  0  19   4]\n",
        "#  [  4  40  53]\n",
        "#  [  3  42 119]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.40      0.41      0.40        97\n",
        "#     Positive       0.68      0.73      0.70       164\n",
        "\n",
        "#    micro avg       0.56      0.56      0.56       284\n",
        "#    macro avg       0.36      0.38      0.37       284\n",
        "# weighted avg       0.53      0.56      0.54       284\n",
        "\n",
        "# 8){'loss': 0.84049994, 'eval_accuracy': 0.575, 'eval_loss': 0.93640614, 'global_step': 368}\n",
        "# [[  2  18   3]\n",
        "#  [  5  42  50]\n",
        "#  [  2  44 118]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.22      0.09      0.12        23\n",
        "#      Neutral       0.40      0.43      0.42        97\n",
        "#     Positive       0.69      0.72      0.70       164\n",
        "\n",
        "#    micro avg       0.57      0.57      0.57       284\n",
        "#    macro avg       0.44      0.41      0.42       284\n",
        "# weighted avg       0.55      0.57      0.56       284\n",
        "\n",
        "# 9){'loss': 0.8601472, 'eval_accuracy': 0.5642857, 'eval_loss': 0.95250976, 'global_step': 414}\n",
        "# [[  0  18   5]\n",
        "#  [  4  37  56]\n",
        "#  [  1  41 122]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.39      0.38      0.38        97\n",
        "#     Positive       0.67      0.74      0.70       164\n",
        "\n",
        "#    micro avg       0.56      0.56      0.56       284\n",
        "#    macro avg       0.35      0.38      0.36       284\n",
        "# weighted avg       0.52      0.56      0.54       284\n",
        "\n",
        "\n",
        "# 10){'loss': 0.9091368, 'eval_accuracy': 0.5535714, 'eval_loss': 0.9715489, 'global_step': 460}\n",
        "# [[  0  19   4]\n",
        "#  [  4  37  56]\n",
        "#  [  1  44 119]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.37      0.38      0.38        97\n",
        "#     Positive       0.66      0.73      0.69       164\n",
        "\n",
        "#    micro avg       0.55      0.55      0.55       284\n",
        "#    macro avg       0.34      0.37      0.36       284\n",
        "# weighted avg       0.51      0.55      0.53       284\n",
        "\n",
        "# 11){'loss': 0.9756337, 'eval_accuracy': 0.5714286, 'eval_loss': 1.0129306, 'global_step': 506}\n",
        "# [[  3  16   4]\n",
        "#  [  5  36  56]\n",
        "#  [  1  41 122]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.33      0.13      0.19        23\n",
        "#      Neutral       0.39      0.37      0.38        97\n",
        "#     Positive       0.67      0.74      0.71       164\n",
        "\n",
        "#    micro avg       0.57      0.57      0.57       284\n",
        "#    macro avg       0.46      0.42      0.42       284\n",
        "# weighted avg       0.55      0.57      0.55       284\n",
        "\n",
        "# 12){'loss': 0.9551747, 'eval_accuracy': 0.56785715, 'eval_loss': 1.0222387, 'global_step': 552}\n",
        "# [[  3  17   3]\n",
        "#  [  5  38  54]\n",
        "#  [  2  43 119]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.30      0.13      0.18        23\n",
        "#      Neutral       0.39      0.39      0.39        97\n",
        "#     Positive       0.68      0.73      0.70       164\n",
        "\n",
        "#    micro avg       0.56      0.56      0.56       284\n",
        "#    macro avg       0.45      0.42      0.42       284\n",
        "# weighted avg       0.55      0.56      0.55       284\n",
        "\n",
        "# 13){'loss': 1.0276382, 'eval_accuracy': 0.5714286, 'eval_loss': 1.0547612, 'global_step': 598}\n",
        "# [[  3  17   3]\n",
        "#  [  5  36  56]\n",
        "#  [  1  41 122]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.33      0.13      0.19        23\n",
        "#      Neutral       0.38      0.37      0.38        97\n",
        "#     Positive       0.67      0.74      0.71       164\n",
        "\n",
        "#    micro avg       0.57      0.57      0.57       284\n",
        "#    macro avg       0.46      0.42      0.42       284\n",
        "# weighted avg       0.55      0.57      0.55       284\n",
        "\n",
        "# 14){'loss': 1.0036505, 'eval_accuracy': 0.55714285, 'eval_loss': 1.0697843, 'global_step': 644}\n",
        "# [[  3  17   3]\n",
        "#  [  7  36  54]\n",
        "#  [  2  44 118]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.25      0.13      0.17        23\n",
        "#      Neutral       0.37      0.37      0.37        97\n",
        "#     Positive       0.67      0.72      0.70       164\n",
        "\n",
        "#    micro avg       0.55      0.55      0.55       284\n",
        "#    macro avg       0.43      0.41      0.41       284\n",
        "# weighted avg       0.54      0.55      0.54       284\n",
        "\n",
        "# 15){'loss': 1.0295725, 'eval_accuracy': 0.5642857, 'eval_loss': 1.0809377, 'global_step': 690}\n",
        "# [[  3  17   3]\n",
        "#  [  5  39  53]\n",
        "#  [  1  46 117]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.33      0.13      0.19        23\n",
        "#      Neutral       0.38      0.40      0.39        97\n",
        "#     Positive       0.68      0.71      0.69       164\n",
        "\n",
        "#    micro avg       0.56      0.56      0.56       284\n",
        "#    macro avg       0.46      0.42      0.42       284\n",
        "# weighted avg       0.55      0.56      0.55       284\n",
        "\n",
        "# 16){'loss': 1.0889318, 'eval_accuracy': 0.54642856, 'eval_loss': 1.1056138, 'global_step': 736}\n",
        "# [[  3  17   3]\n",
        "#  [  8  33  56]\n",
        "#  [  2  44 118]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.23      0.13      0.17        23\n",
        "#      Neutral       0.35      0.34      0.35        97\n",
        "#     Positive       0.67      0.72      0.69       164\n",
        "\n",
        "#    micro avg       0.54      0.54      0.54       284\n",
        "#    macro avg       0.42      0.40      0.40       284\n",
        "# weighted avg       0.52      0.54      0.53       284\n",
        "\n",
        "# 17){'loss': 1.1312778, 'eval_accuracy': 0.54642856, 'eval_loss': 1.1440269, 'global_step': 782}\n",
        "# [[  3  17   3]\n",
        "#  [  9  33  55]\n",
        "#  [  2  44 118]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.21      0.13      0.16        23\n",
        "#      Neutral       0.35      0.34      0.35        97\n",
        "#     Positive       0.67      0.72      0.69       164\n",
        "\n",
        "#    micro avg       0.54      0.54      0.54       284\n",
        "#    macro avg       0.41      0.40      0.40       284\n",
        "# weighted avg       0.52      0.54      0.53       284\n",
        "\n",
        "# 18){'loss': 1.1436831, 'eval_accuracy': 0.55, 'eval_loss': 1.1613237, 'global_step': 828}\n",
        "# [[  3  16   4]\n",
        "#  [  8  35  54]\n",
        "#  [  2  45 117]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.23      0.13      0.17        23\n",
        "#      Neutral       0.36      0.36      0.36        97\n",
        "#     Positive       0.67      0.71      0.69       164\n",
        "\n",
        "#    micro avg       0.55      0.55      0.55       284\n",
        "#    macro avg       0.42      0.40      0.41       284\n",
        "# weighted avg       0.53      0.55      0.54       284\n",
        "\n",
        "# 19){'loss': 1.1817628, 'eval_accuracy': 0.55, 'eval_loss': 1.1834545, 'global_step': 874}\n",
        "# [[  3  16   4]\n",
        "#  [  8  34  55]\n",
        "#  [  1  45 118]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.25      0.13      0.17        23\n",
        "#      Neutral       0.36      0.35      0.35        97\n",
        "#     Positive       0.67      0.72      0.69       164\n",
        "\n",
        "#    micro avg       0.55      0.55      0.55       284\n",
        "#    macro avg       0.42      0.40      0.41       284\n",
        "# weighted avg       0.53      0.55      0.53       284\n",
        "\n",
        "# 20){'loss': 1.1921012, 'eval_accuracy': 0.54642856, 'eval_loss': 1.1976833, 'global_step': 920}\n",
        "# [[  3  16   4]\n",
        "#  [  9  35  53]\n",
        "#  [  2  47 115]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.21      0.13      0.16        23\n",
        "#      Neutral       0.36      0.36      0.36        97\n",
        "#     Positive       0.67      0.70      0.68       164\n",
        "\n",
        "#    micro avg       0.54      0.54      0.54       284\n",
        "#    macro avg       0.41      0.40      0.40       284\n",
        "# weighted avg       0.53      0.54      0.53       284\n",
        "\n",
        "# 21){'loss': 1.2514663, 'eval_accuracy': 0.53571427, 'eval_loss': 1.2244278, 'global_step': 966}\n",
        "# [[  3  16   4]\n",
        "#  [ 11  32  54]\n",
        "#  [  2  47 115]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.19      0.13      0.15        23\n",
        "#      Neutral       0.34      0.33      0.33        97\n",
        "#     Positive       0.66      0.70      0.68       164\n",
        "\n",
        "#    micro avg       0.53      0.53      0.53       284\n",
        "#    macro avg       0.40      0.39      0.39       284\n",
        "# weighted avg       0.51      0.53      0.52       284\n",
        "\n",
        "# 22){'loss': 1.2630298, 'eval_accuracy': 0.5321429, 'eval_loss': 1.2527977, 'global_step': 1012}\n",
        "# [[  5  14   4]\n",
        "#  [ 14  32  51]\n",
        "#  [  9  43 112]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.18      0.22      0.20        23\n",
        "#      Neutral       0.36      0.33      0.34        97\n",
        "#     Positive       0.67      0.68      0.68       164\n",
        "\n",
        "#    micro avg       0.52      0.52      0.52       284\n",
        "#    macro avg       0.40      0.41      0.41       284\n",
        "# weighted avg       0.52      0.52      0.52       284\n",
        "\n",
        "# 23){'loss': 1.3330169, 'eval_accuracy': 0.53571427, 'eval_loss': 1.2815608, 'global_step': 1058}\n",
        "# [[  6  13   4]\n",
        "#  [ 14  31  52]\n",
        "#  [  9  42 113]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.21      0.26      0.23        23\n",
        "#      Neutral       0.36      0.32      0.34        97\n",
        "#     Positive       0.67      0.69      0.68       164\n",
        "\n",
        "#    micro avg       0.53      0.53      0.53       284\n",
        "#    macro avg       0.41      0.42      0.42       284\n",
        "# weighted avg       0.53      0.53      0.53       284\n",
        "\n",
        "# 24){'loss': 1.3111317, 'eval_accuracy': 0.5321429, 'eval_loss': 1.2898273, 'global_step': 1104}\n",
        "# [[  5  14   4]\n",
        "#  [ 14  32  51]\n",
        "#  [  9  43 112]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.18      0.22      0.20        23\n",
        "#      Neutral       0.36      0.33      0.34        97\n",
        "#     Positive       0.67      0.68      0.68       164\n",
        "\n",
        "#    micro avg       0.52      0.52      0.52       284\n",
        "#    macro avg       0.40      0.41      0.41       284\n",
        "# weighted avg       0.52      0.52      0.52       284"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUqSe326lwHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Larg BERT seq:256, batchsize 8 for train, dev , test\n",
        "# {'loss': 1.0679293, 'eval_accuracy': 0.5955882, 'eval_loss': 0.8965841, 'global_step': 93}\n",
        "# [[  0   0  23]\n",
        "#  [  0   0  97]\n",
        "#  [  0   0 164]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.00      0.00      0.00        97\n",
        "#     Positive       0.58      1.00      0.73       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.19      0.33      0.24       284\n",
        "# weighted avg       0.33      0.58      0.42       284\n",
        "\n",
        "# {'loss': 1.0362501, 'eval_accuracy': 0.5955882, 'eval_loss': 0.88540924, 'global_step': 186}\n",
        "# [[  0   0  23]\n",
        "#  [  0   0  97]\n",
        "#  [  0   0 164]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.00      0.00      0.00        97\n",
        "#     Positive       0.58      1.00      0.73       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.19      0.33      0.24       284\n",
        "# weighted avg       0.33      0.58      0.42       284\n",
        "\n",
        "# {'loss': 1.0290864, 'eval_accuracy': 0.5955882, 'eval_loss': 0.8812368, 'global_step': 279}\n",
        "# [[  0   0  23]\n",
        "#  [  0   0  97]\n",
        "#  [  0   0 164]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.00      0.00      0.00        97\n",
        "#     Positive       0.58      1.00      0.73       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.19      0.33      0.24       284\n",
        "# weighted avg       0.33      0.58      0.42       284\n",
        "\n",
        "# {'loss': 1.0271251, 'eval_accuracy': 0.5955882, 'eval_loss': 0.88323754, 'global_step': 372}\n",
        "# [[  0   0  23]\n",
        "#  [  0   0  97]\n",
        "#  [  0   0 164]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.00      0.00      0.00        97\n",
        "#     Positive       0.58      1.00      0.73       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.19      0.33      0.24       284\n",
        "# weighted avg       0.33      0.58      0.42       284\n",
        "\n",
        "# {'loss': 1.02654, 'eval_accuracy': 0.5955882, 'eval_loss': 0.8804489, 'global_step': 465}\n",
        "# [[  0   0  23]\n",
        "#  [  0   0  97]\n",
        "#  [  0   0 164]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.00      0.00      0.00        97\n",
        "#     Positive       0.58      1.00      0.73       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.19      0.33      0.24       284\n",
        "# weighted avg       0.33      0.58      0.42       284\n",
        "\n",
        "# SAME FOR 10 EPOCHS!!!!!"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}