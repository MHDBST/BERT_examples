{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyBert_document_TPU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MHDBST/BERT_examples/blob/master/MyBert_document_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rN2obM4ocF_p",
        "colab_type": "code",
        "outputId": "c9bf0e1d-e6b6-4bef-cca5-2546535e27bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "!pip install bert-tensorflow\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python2.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "('TPU address is', 'grpc://10.26.93.186:8470')\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 12690508427458736334),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 16203115377378444841),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 17879316257458164133),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 17143706759747131924),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 3111776084791170922),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 11418182598355356184),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 16258728155362305611),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 15406828482894591040),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 10059853102624495087),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17634002558693322950),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 18317746407663200010)]\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AYYgxPTVc5u7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "cfc3ab60-25dd-4504-84ea-c4af29c25f8a"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "  sys.path += ['bert_repo']\n",
        "\n",
        "# import python modules defined by BERT\n",
        "from bert import modeling\n",
        "# import optimization\n",
        "# import run_classifier\n",
        "from bert import run_classifier_with_tfhub\n",
        "# import tokenization\n",
        "\n",
        "# import tfhub \n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0429 17:01:15.358141 139835214985088 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0yIQhrSUdE-H",
        "colab_type": "code",
        "outputId": "aa104c2a-f252-4231-bb59-4616c366d38a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "BUCKET = 'bert_example' #@param {type:\"string\"}\n",
        "TASK = 'MASKED_DOCUMENT'\n",
        "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
        "OUTPUT_DIR = 'gs://{}/bert-tfhub/models/{}/smallBERT-docLevel-seq512'.format(BUCKET,TASK)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "# Available pretrained model checkpoints:\n",
        "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
        "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
        "#   cased_L-12_H-768_A-12: cased BERT large model\n",
        "BERT_MODEL = 'uncased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
        "BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: gs://bert_example/bert-tfhub/models/MASKED_DOCUMENT/smallBERT-docLevel-seq512 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3VLhRyWYdPN-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "e3e26270-b064-497a-eb9b-86ea8c7684d3"
      },
      "cell_type": "code",
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization\n",
        "\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\" ##Small Bert\n",
        "# BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-24_H-1024_A-16/1\" ##Big Bert\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0429 17:01:18.887702 139835214985088 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0429 17:01:21.334295 139835214985088 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_eLjuUqLdR_b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TRAIN_BATCH_SIZE = 32\n",
        "EVAL_BATCH_SIZE = 8\n",
        "PREDICT_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 18.0  ## Activate if ** is ACTIVATED\n",
        "MAX_SEQ_LENGTH = 512\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 200\n",
        "SAVE_SUMMARY_STEPS = 100\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2yAPypEOdgpq",
        "colab_type": "code",
        "outputId": "78ed5f91-8a90-4335-8159-f6b14ad23478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "\n",
        "# data_train = pd.read_csv('/content/alldata_3Dec_7Dec_PS_reindex_train_v3.csv', encoding='latin-1')\n",
        "# data_dev = pd.read_csv('/content/alldata_3Dec_7Dec_PS_reindex_dev_v3.csv', encoding='latin-1')\n",
        "# data_test = pd.read_csv('/content/alldata_3Dec_7Dec_PS_reindex_random_test_v3.csv', encoding='latin-1')\n",
        "# data_test_fixed = pd.read_csv('/content/alldata_3Dec_7Dec_PS_reindex_fixed_test_v3.csv', encoding='latin-1')\n",
        "\n",
        "data_train = pd.read_csv('/content/alldata_3Dec_7Dec_PS_reindex_enclosed_masked_train_v3.csv', encoding='latin-1')\n",
        "data_dev = pd.read_csv('/content/alldata_3Dec_7Dec_PS_reindex_enclosed_masked_dev_v3.csv', encoding='latin-1')\n",
        "data_test = pd.read_csv('/content/alldata_3Dec_7Dec_PS_reindex_enclosed_masked_random_test_v3.csv', encoding='latin-1')\n",
        "data_test_fixed = pd.read_csv('/content/alldata_3Dec_7Dec_PS_reindex_enclosed_masked_fixed_test_v3.csv', encoding='latin-1')\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Load all files from a directory in a DataFrame.\n",
        "def load_directory_data(df):\n",
        "  data = {}\n",
        "  data[\"sentence\"] = df[TASK] ## could be DOCUMENT, ENCLOSED_DOCUMENT, MASKED_DOCUMENT\n",
        "  data[\"sentiment\"] =df[\"TRUE_SENTIMENT\"]\n",
        "  return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(df,index = None):\n",
        "  df_new = load_directory_data(df[:index])\n",
        "  pos_df = df_new[df_new['sentiment'] == 'Positive']\n",
        "  neg_df = df_new[df_new['sentiment'] == 'Negative']\n",
        "  neu_df = df_new[df_new['sentiment'] == 'Neutral']\n",
        "  pos_df[\"polarity\"] = 1\n",
        "  neg_df[\"polarity\"] = -1\n",
        "  neu_df[\"polarity\"] = 0\n",
        "  return pd.concat([pos_df, neg_df,neu_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "train = load_dataset(data_train)\n",
        "test = load_dataset(data_test)\n",
        "dev = load_dataset(data_dev)\n",
        "test_fixed = load_dataset(data_test_fixed)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4fMNSsUHdsbY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATA_COLUMN = 'sentence'\n",
        "LABEL_COLUMN = 'polarity'\n",
        "label_list = [-1, 0, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0HjkshmOdyI5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "dev_InputExamples = dev.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "\n",
        "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "test_InputExamples_fixed = test_fixed.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "\n",
        "\n",
        "## These two lines should be activated if ** is not activated\n",
        "num_train_steps = int(len(train_InputExamples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "# Setup TPU related config\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "NUM_TPU_CORES = 8\n",
        "# ITERATIONS_PER_LOOP = 1000 # I don't know what it is doing just decrease it to smaller value\n",
        "ITERATIONS_PER_LOOP = int(len(train_InputExamples) / TRAIN_BATCH_SIZE) ## set as the number of iterations in each epoch \n",
        "\n",
        "def get_run_config(output_dir):\n",
        "  return tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=output_dir,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1WEcWYt6jjaf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model(is_training, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels, bert_hub_module_handle):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "  tags = set()\n",
        "  if is_training:\n",
        "    tags.add(\"train\")\n",
        "  bert_module = hub.Module(bert_hub_module_handle, tags=tags, trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # In the demo, we are doing a simple classification task on the entire\n",
        "  # segment.\n",
        "  #\n",
        "  # If you want to use the token-level output, use\n",
        "  # bert_outputs[\"sequence_output\"] instead.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "    if is_training:\n",
        "      # I.e., 0.1 dropout\n",
        "      output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "    return (loss, per_example_loss, logits, probabilities)\n",
        "\n",
        "\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps, use_tpu, bert_hub_module_handle):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    tf.logging.info(\"*** Features ***\")\n",
        "    for name in sorted(features.keys()):\n",
        "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    (total_loss, per_example_loss, logits, probabilities) = create_model(\n",
        "        is_training, input_ids, input_mask, segment_ids, label_ids, num_labels,\n",
        "        bert_hub_module_handle)\n",
        "\n",
        "    output_spec = None\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      train_op = optimization.create_optimizer(\n",
        "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          train_op=train_op)\n",
        "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "\n",
        "      def metric_fn(per_example_loss, label_ids, logits):\n",
        "        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predictions)\n",
        "        loss = tf.metrics.mean(per_example_loss)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"eval_loss\": loss,\n",
        "        }\n",
        "\n",
        "      eval_metrics = (metric_fn, [per_example_loss, label_ids, logits])\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          eval_metrics=eval_metrics)\n",
        "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode, predictions={\"probabilities\": probabilities})\n",
        "    else:\n",
        "      raise ValueError(\n",
        "          \"Only TRAIN, EVAL and PREDICT modes are supported: %s\" % (mode))\n",
        "\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ROg74SGti91n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "e79af705-00dc-4343-fad0-cb43a722f6a9"
      },
      "cell_type": "code",
      "source": [
        "# Force TF Hub writes to the GS bucket we provide.\n",
        "os.environ['TFHUB_CACHE_DIR'] = OUTPUT_DIR\n",
        "### Activate it if ** part is not activated \n",
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps,\n",
        "  use_tpu=True,\n",
        "  bert_hub_module_handle=BERT_MODEL_HUB\n",
        ")\n",
        "\n",
        "estimator_from_tfhub = tf.contrib.tpu.TPUEstimator(\n",
        "  use_tpu=True,\n",
        "  model_fn=model_fn,\n",
        "  config=get_run_config(OUTPUT_DIR),\n",
        "  train_batch_size=TRAIN_BATCH_SIZE,\n",
        "  eval_batch_size=EVAL_BATCH_SIZE,\n",
        "  predict_batch_size=PREDICT_BATCH_SIZE,\n",
        ")\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7f2dad9a8d70>) includes params argument, but params are not passed to Estimator.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0429 17:01:24.878014 139835214985088 estimator.py:1924] Estimator's model_fn (<function model_fn at 0x7f2dad9a8d70>) includes params argument, but params are not passed to Estimator.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.26.93.186:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2dac27be90>, '_model_dir': 'gs://bert_example/bert-tfhub/models/MASKED_DOCUMENT/smallBERT-docLevel-seq512', '_protocol': None, '_save_checkpoints_steps': 200, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tpu_config': TPUConfig(iterations_per_loop=46, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f2dad842090>, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': None, '_evaluation_master': 'grpc://10.26.93.186:8470', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': 'grpc://10.26.93.186:8470'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0429 17:01:24.881578 139835214985088 estimator.py:201] Using config: {'_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.26.93.186:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2dac27be90>, '_model_dir': 'gs://bert_example/bert-tfhub/models/MASKED_DOCUMENT/smallBERT-docLevel-seq512', '_protocol': None, '_save_checkpoints_steps': 200, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tpu_config': TPUConfig(iterations_per_loop=46, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f2dad842090>, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': None, '_evaluation_master': 'grpc://10.26.93.186:8470', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': 'grpc://10.26.93.186:8470'}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0429 17:01:24.885636 139835214985088 tpu_context.py:202] _TPUContext: eval_on_tpu True\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-LiIFIsqg3I2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "tf.logging.set_verbosity(tf.logging.FATAL) #DEBUG,ERROR,FATAL,INFO,WARN\n",
        "def model_train(estimator):\n",
        "  # We'll set sequences to be at most 128 tokens long.\n",
        "  train_features = run_classifier.convert_examples_to_features(\n",
        "      train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
        "  print('  Num examples = {}'.format(len(train_InputExamples)))\n",
        "  print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
        "  tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "  train_input_fn = run_classifier.input_fn_builder(\n",
        "      features=train_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=True,\n",
        "      drop_remainder=True)\n",
        "  md = estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "  print('***** Finished training at {} *****'.format(datetime.datetime.now()))\n",
        "  return md\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qatznvlRsQ-2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Evaluation and Prediction "
      ]
    },
    {
      "metadata": {
        "id": "xkmmTPdYsTSE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_eval(estimator):\n",
        "  # Eval the model.\n",
        "  eval_examples = dev_InputExamples#processor.get_dev_examples(TASK_DATA_DIR)\n",
        "  eval_features = run_classifier.convert_examples_to_features(\n",
        "      eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  print('  Num examples = {}'.format(len(eval_examples)))\n",
        "  print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "\n",
        "  # Eval will be slightly WRONG on the TPU because it will truncate\n",
        "  # the last batch.\n",
        "  eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n",
        "  eval_input_fn = run_classifier.input_fn_builder(\n",
        "      features=eval_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=False,\n",
        "      drop_remainder=True)\n",
        "  result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "  print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "  with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "    print(\"***** Eval results *****\")\n",
        "    for key in sorted(result.keys()):\n",
        "      print('  {} = {}'.format(key, str(result[key])))\n",
        "      writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "      \n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tcCrUx2Esa7w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "labels = [\"Negative\",\"Neutral\", \"Positive\"]\n",
        "def model_predict(estimator,prediction_examples,checkpoint_path=None):\n",
        "  # Make predictions on a subset of eval examples\n",
        "#   prediction_examples = processor.get_dev_examples(TASK_DATA_DIR)[:PREDICT_BATCH_SIZE]\n",
        "  input_features = run_classifier.convert_examples_to_features(prediction_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=True)\n",
        "  if not checkpoint_path == None: \n",
        "    predictions = estimator.predict(predict_input_fn,checkpoint_path=checkpoint_path)\n",
        "  else:\n",
        "    predictions = estimator.predict(predict_input_fn)\n",
        "  return [(sentence, prediction['probabilities']) for sentence, prediction in zip(prediction_examples, predictions)]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KJ1fsOEQ1Mgs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd = model_predict(estimator_from_tfhub,dev_InputExamples,checkpoint_path=OUTPUT_DIR+'/model.ckpt-966')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6hyQ56ij3K3E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "8cf09765-a0d9-4736-e532-22b59925d4bc"
      },
      "cell_type": "code",
      "source": [
        "labels_val = []\n",
        "true_label = list(dev['sentiment'])\n",
        "for item in pd:\n",
        "    labels_val.append(labels[np.argmax(item[1])])\n",
        "print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "print(metrics.classification_report(y_pred=labels_val,y_true = true_label))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  7  13   3]\n",
            " [  7  37  53]\n",
            " [  7  36 121]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.33      0.30      0.32        23\n",
            "     Neutral       0.43      0.38      0.40        97\n",
            "    Positive       0.68      0.74      0.71       164\n",
            "\n",
            "   micro avg       0.58      0.58      0.58       284\n",
            "   macro avg       0.48      0.47      0.48       284\n",
            "weighted avg       0.57      0.58      0.57       284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9sOXm0fT3awW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        },
        "outputId": "f4fa8e74-4c11-4a2b-e9f9-7bebc3100b0d"
      },
      "cell_type": "code",
      "source": [
        "for chkp in range(506,700,46):\n",
        "  pd = model_predict(estimator_from_tfhub,dev_InputExamples,checkpoint_path=OUTPUT_DIR+'/model-ckpt.%d'%ckpt))\n",
        "  labels_val = []\n",
        "  true_label = list(dev['sentiment'])\n",
        "  for item in pd:\n",
        "      labels_val.append(labels[np.argmax(item[1])])\n",
        "  print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "  print(metrics.classification_report(y_pred=labels_val,y_true = true_label))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  7  13   3]\n",
            " [  8  40  49]\n",
            " [  5  41 118]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.35      0.30      0.33        23\n",
            "     Neutral       0.43      0.41      0.42        97\n",
            "    Positive       0.69      0.72      0.71       164\n",
            "\n",
            "   micro avg       0.58      0.58      0.58       284\n",
            "   macro avg       0.49      0.48      0.48       284\n",
            "weighted avg       0.57      0.58      0.58       284\n",
            "\n",
            "[[  4  15   4]\n",
            " [  2  42  53]\n",
            " [  4  37 123]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.40      0.17      0.24        23\n",
            "     Neutral       0.45      0.43      0.44        97\n",
            "    Positive       0.68      0.75      0.72       164\n",
            "\n",
            "   micro avg       0.60      0.60      0.60       284\n",
            "   macro avg       0.51      0.45      0.47       284\n",
            "weighted avg       0.58      0.60      0.58       284\n",
            "\n",
            "[[  7  13   3]\n",
            " [  6  42  49]\n",
            " [  5  36 123]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.39      0.30      0.34        23\n",
            "     Neutral       0.46      0.43      0.45        97\n",
            "    Positive       0.70      0.75      0.73       164\n",
            "\n",
            "   micro avg       0.61      0.61      0.61       284\n",
            "   macro avg       0.52      0.50      0.50       284\n",
            "weighted avg       0.60      0.61      0.60       284\n",
            "\n",
            "[[  8  12   3]\n",
            " [  9  39  49]\n",
            " [  7  35 122]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.33      0.35      0.34        23\n",
            "     Neutral       0.45      0.40      0.43        97\n",
            "    Positive       0.70      0.74      0.72       164\n",
            "\n",
            "   micro avg       0.60      0.60      0.60       284\n",
            "   macro avg       0.50      0.50      0.50       284\n",
            "weighted avg       0.59      0.60      0.59       284\n",
            "\n",
            "[[  7  13   3]\n",
            " [  8  40  49]\n",
            " [  6  37 121]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.33      0.30      0.32        23\n",
            "     Neutral       0.44      0.41      0.43        97\n",
            "    Positive       0.70      0.74      0.72       164\n",
            "\n",
            "   micro avg       0.59      0.59      0.59       284\n",
            "   macro avg       0.49      0.48      0.49       284\n",
            "weighted avg       0.58      0.59      0.59       284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ascfbXXbzEpw",
        "colab_type": "code",
        "outputId": "254a506c-48d6-4204-a80d-704b3d821556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "cell_type": "code",
      "source": [
        "## Run it if you want to train for a range of epochs and see the validation error and save the prediction on than\n",
        "## Part Name **\n",
        "mds = []\n",
        "evs = []\n",
        "pds = []\n",
        "from shutil import copyfile\n",
        "max_f1 = 0\n",
        "true_label = list(dev['sentiment'])\n",
        "for i in range(11,19):\n",
        "\n",
        "  NUM_TRAIN_EPOCHS = i\n",
        "  \n",
        "  num_train_steps = int(len(train_InputExamples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "  num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "  model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps,\n",
        "  use_tpu=True,\n",
        "  bert_hub_module_handle=BERT_MODEL_HUB)\n",
        "  \n",
        "  estimator_from_tfhub = tf.contrib.tpu.TPUEstimator(\n",
        "  use_tpu=True,\n",
        "  model_fn=model_fn,\n",
        "  config=get_run_config(OUTPUT_DIR),\n",
        "  train_batch_size=TRAIN_BATCH_SIZE,\n",
        "  eval_batch_size=EVAL_BATCH_SIZE,\n",
        "  predict_batch_size=PREDICT_BATCH_SIZE)\n",
        "  \n",
        "  md = model_train(estimator_from_tfhub)\n",
        "  ev = model_eval(estimator_from_tfhub)\n",
        "  pd = model_predict(estimator_from_tfhub,dev_InputExamples)\n",
        "  mds.append(md)\n",
        "  evs.append(ev)\n",
        "  pds.append(pd)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for pd,ev in zip(pds,evs):\n",
        "  print(ev)\n",
        "  labels_val = []\n",
        "  for item in pd:\n",
        "    labels_val.append(labels[np.argmax(item[1])])\n",
        "  print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "  print(metrics.classification_report(y_pred=labels_val,y_true = true_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Started training at 2019-04-29 17:17:12.017800 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Finished training at 2019-04-29 17:20:18.851581 *****\n",
            "***** Started evaluation at 2019-04-29 17:20:21.487703 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-29 17:21:00.558299 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.60714287\n",
            "  eval_loss = 0.98495996\n",
            "  global_step = 506\n",
            "  loss = 0.9331349\n",
            "***** Started training at 2019-04-29 17:21:52.554820 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "***** Finished training at 2019-04-29 17:24:44.780655 *****\n",
            "***** Started evaluation at 2019-04-29 17:24:47.412404 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-29 17:25:30.807250 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.57857144\n",
            "  eval_loss = 1.0090073\n",
            "  global_step = 552\n",
            "  loss = 0.9327236\n",
            "***** Started training at 2019-04-29 17:26:23.699987 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "***** Finished training at 2019-04-29 17:29:05.722022 *****\n",
            "***** Started evaluation at 2019-04-29 17:29:08.359563 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-29 17:29:43.123732 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.5964286\n",
            "  eval_loss = 1.027999\n",
            "  global_step = 598\n",
            "  loss = 0.96060616\n",
            "***** Started training at 2019-04-29 17:30:35.863638 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5YZ4cfccYh2z",
        "colab_type": "code",
        "outputId": "c50c7359-9300-4c1e-8180-2eaeca742772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2366
        }
      },
      "cell_type": "code",
      "source": [
        "## Run it if you want to train for a range of epochs and see the validation error and save the prediction on than\n",
        "## Part Name **\n",
        "mds = []\n",
        "evs = []\n",
        "pds = []\n",
        "for i in range(6,11):\n",
        "\n",
        "  NUM_TRAIN_EPOCHS = i\n",
        "  \n",
        "  num_train_steps = int(len(train_InputExamples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "  num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "  model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps,\n",
        "  use_tpu=True,\n",
        "  bert_hub_module_handle=BERT_MODEL_HUB)\n",
        "  \n",
        "  estimator_from_tfhub = tf.contrib.tpu.TPUEstimator(\n",
        "  use_tpu=True,\n",
        "  model_fn=model_fn,\n",
        "  config=get_run_config(OUTPUT_DIR),\n",
        "  train_batch_size=TRAIN_BATCH_SIZE,\n",
        "  eval_batch_size=EVAL_BATCH_SIZE,\n",
        "  predict_batch_size=PREDICT_BATCH_SIZE)\n",
        "  \n",
        "  md = model_train(estimator_from_tfhub)\n",
        "  ev = model_eval(estimator_from_tfhub)\n",
        "  pd = model_predict(estimator_from_tfhub,dev_InputExamples)\n",
        "  mds.append(md)\n",
        "  evs.append(ev)\n",
        "  pds.append(pd)\n",
        "\n",
        "\n",
        "true_label = list(dev['sentiment'])\n",
        "\n",
        "for pd,ev in zip(pds,evs):\n",
        "  print(ev)\n",
        "  labels_val = []\n",
        "  for item in pd:\n",
        "    labels_val.append(labels[np.argmax(item[1])])\n",
        "  print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "  print(metrics.classification_report(y_pred=labels_val,y_true = true_label))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Started training at 2019-04-28 15:12:28.538441 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "***** Finished training at 2019-04-28 15:12:29.213077 *****\n",
            "***** Started evaluation at 2019-04-28 15:12:31.842012 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-28 15:13:07.744505 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.5714286\n",
            "  eval_loss = 0.9440209\n",
            "  global_step = 368\n",
            "  loss = 1.1764531\n",
            "***** Started training at 2019-04-28 15:13:57.539700 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "***** Finished training at 2019-04-28 15:13:57.822070 *****\n",
            "***** Started evaluation at 2019-04-28 15:14:00.475048 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-28 15:14:22.995131 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.5714286\n",
            "  eval_loss = 0.9440209\n",
            "  global_step = 368\n",
            "  loss = 1.1764531\n",
            "***** Started training at 2019-04-28 15:15:17.300855 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "***** Finished training at 2019-04-28 15:15:17.636382 *****\n",
            "***** Started evaluation at 2019-04-28 15:15:20.325073 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-28 15:15:44.671400 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.5714286\n",
            "  eval_loss = 0.9440209\n",
            "  global_step = 368\n",
            "  loss = 1.1764531\n",
            "***** Started training at 2019-04-28 15:16:39.171346 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Finished training at 2019-04-28 15:19:23.023827 *****\n",
            "***** Started evaluation at 2019-04-28 15:19:25.856291 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-28 15:20:02.444724 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.5928571\n",
            "  eval_loss = 0.9171207\n",
            "  global_step = 414\n",
            "  loss = 1.2081399\n",
            "***** Started training at 2019-04-28 15:20:55.606916 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "***** Finished training at 2019-04-28 15:23:40.297414 *****\n",
            "***** Started evaluation at 2019-04-28 15:23:42.955700 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-28 15:24:18.059923 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.5857143\n",
            "  eval_loss = 0.9534051\n",
            "  global_step = 460\n",
            "  loss = 1.2671456\n",
            "{'loss': 1.1764531, 'eval_accuracy': 0.5714286, 'eval_loss': 0.9440209, 'global_step': 368}\n",
            "[[  3  17   3]\n",
            " [  8  45  44]\n",
            " [  5  45 114]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.19      0.13      0.15        23\n",
            "     Neutral       0.42      0.46      0.44        97\n",
            "    Positive       0.71      0.70      0.70       164\n",
            "\n",
            "   micro avg       0.57      0.57      0.57       284\n",
            "   macro avg       0.44      0.43      0.43       284\n",
            "weighted avg       0.57      0.57      0.57       284\n",
            "\n",
            "{'loss': 1.1764531, 'eval_accuracy': 0.5714286, 'eval_loss': 0.9440209, 'global_step': 368}\n",
            "[[  3  17   3]\n",
            " [  8  45  44]\n",
            " [  5  45 114]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.19      0.13      0.15        23\n",
            "     Neutral       0.42      0.46      0.44        97\n",
            "    Positive       0.71      0.70      0.70       164\n",
            "\n",
            "   micro avg       0.57      0.57      0.57       284\n",
            "   macro avg       0.44      0.43      0.43       284\n",
            "weighted avg       0.57      0.57      0.57       284\n",
            "\n",
            "{'loss': 1.1764531, 'eval_accuracy': 0.5714286, 'eval_loss': 0.9440209, 'global_step': 368}\n",
            "[[  3  17   3]\n",
            " [  8  45  44]\n",
            " [  5  45 114]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.19      0.13      0.15        23\n",
            "     Neutral       0.42      0.46      0.44        97\n",
            "    Positive       0.71      0.70      0.70       164\n",
            "\n",
            "   micro avg       0.57      0.57      0.57       284\n",
            "   macro avg       0.44      0.43      0.43       284\n",
            "weighted avg       0.57      0.57      0.57       284\n",
            "\n",
            "{'loss': 1.2081399, 'eval_accuracy': 0.5928571, 'eval_loss': 0.9171207, 'global_step': 414}\n",
            "[[  2  17   4]\n",
            " [  2  43  52]\n",
            " [  4  38 122]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.25      0.09      0.13        23\n",
            "     Neutral       0.44      0.44      0.44        97\n",
            "    Positive       0.69      0.74      0.71       164\n",
            "\n",
            "   micro avg       0.59      0.59      0.59       284\n",
            "   macro avg       0.46      0.42      0.43       284\n",
            "weighted avg       0.57      0.59      0.57       284\n",
            "\n",
            "{'loss': 1.2671456, 'eval_accuracy': 0.5857143, 'eval_loss': 0.9534051, 'global_step': 460}\n",
            "[[  4  15   4]\n",
            " [  4  42  51]\n",
            " [  4  41 119]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.33      0.17      0.23        23\n",
            "     Neutral       0.43      0.43      0.43        97\n",
            "    Positive       0.68      0.73      0.70       164\n",
            "\n",
            "   micro avg       0.58      0.58      0.58       284\n",
            "   macro avg       0.48      0.44      0.45       284\n",
            "weighted avg       0.57      0.58      0.57       284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YpgNJ6TkfXec",
        "colab_type": "code",
        "outputId": "ad7b1af2-9709-487c-bedb-455f9df3ff01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "cell_type": "code",
      "source": [
        "## Run it if you want to train for a range of epochs and see the validation error and save the prediction on than\n",
        "## Part Name **\n",
        "mds = []\n",
        "evs = []\n",
        "pds = []\n",
        "for i in range(11,16):\n",
        "\n",
        "  NUM_TRAIN_EPOCHS = i\n",
        "  \n",
        "  num_train_steps = int(len(train_InputExamples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "  num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "  model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps,\n",
        "  use_tpu=True,\n",
        "  bert_hub_module_handle=BERT_MODEL_HUB)\n",
        "  \n",
        "  estimator_from_tfhub = tf.contrib.tpu.TPUEstimator(\n",
        "  use_tpu=True,\n",
        "  model_fn=model_fn,\n",
        "  config=get_run_config(OUTPUT_DIR),\n",
        "  train_batch_size=TRAIN_BATCH_SIZE,\n",
        "  eval_batch_size=EVAL_BATCH_SIZE,\n",
        "  predict_batch_size=PREDICT_BATCH_SIZE)\n",
        "  \n",
        "  md = model_train(estimator_from_tfhub)\n",
        "  ev = model_eval(estimator_from_tfhub)\n",
        "  pd = model_predict(estimator_from_tfhub,dev_InputExamples)\n",
        "  mds.append(md)\n",
        "  evs.append(ev)\n",
        "  pds.append(pd)\n",
        "\n",
        "\n",
        "true_label = list(dev['sentiment'])\n",
        "\n",
        "for pd,ev in zip(pds,evs):\n",
        "  print(ev)\n",
        "  labels_val = []\n",
        "  for item in pd:\n",
        "    labels_val.append(labels[np.argmax(item[1])])\n",
        "  print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "  print(metrics.classification_report(y_pred=labels_val,y_true = true_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Started training at 2019-04-28 15:45:20.643538 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "***** Finished training at 2019-04-28 15:48:19.936165 *****\n",
            "***** Started evaluation at 2019-04-28 15:48:22.636459 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-28 15:48:58.825505 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.57857144\n",
            "  eval_loss = 0.97833145\n",
            "  global_step = 506\n",
            "  loss = 1.2721822\n",
            "***** Started training at 2019-04-28 15:49:52.790370 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "***** Finished training at 2019-04-28 15:52:31.865663 *****\n",
            "***** Started evaluation at 2019-04-28 15:52:34.516895 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-28 15:53:09.975229 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.6\n",
            "  eval_loss = 0.97125417\n",
            "  global_step = 552\n",
            "  loss = 1.3204917\n",
            "***** Started training at 2019-04-28 15:54:01.259711 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "***** Finished training at 2019-04-28 15:56:50.330957 *****\n",
            "***** Started evaluation at 2019-04-28 15:56:52.984305 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-28 15:57:26.380911 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.6035714\n",
            "  eval_loss = 1.0014101\n",
            "  global_step = 598\n",
            "  loss = 1.348728\n",
            "***** Started training at 2019-04-28 15:58:20.964778 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "***** Finished training at 2019-04-28 16:01:07.758938 *****\n",
            "***** Started evaluation at 2019-04-28 16:01:10.412514 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-28 16:01:48.246091 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.5928571\n",
            "  eval_loss = 1.0223936\n",
            "  global_step = 644\n",
            "  loss = 1.3660265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CfKoHABGqZIf",
        "colab_type": "code",
        "outputId": "c292693f-b2a5-4c13-84e4-b0a37c62889a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2312
        }
      },
      "cell_type": "code",
      "source": [
        "## Run it if you want to train for a range of epochs and see the validation error and save the prediction on than\n",
        "## Part Name **\n",
        "mds = []\n",
        "evs = []\n",
        "pds = []\n",
        "for i in range(21,26):\n",
        "\n",
        "  NUM_TRAIN_EPOCHS = i\n",
        "  \n",
        "  num_train_steps = int(len(train_InputExamples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "  num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "  model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps,\n",
        "  use_tpu=True,\n",
        "  bert_hub_module_handle=BERT_MODEL_HUB)\n",
        "  \n",
        "  estimator_from_tfhub = tf.contrib.tpu.TPUEstimator(\n",
        "  use_tpu=True,\n",
        "  model_fn=model_fn,\n",
        "  config=get_run_config(OUTPUT_DIR),\n",
        "  train_batch_size=TRAIN_BATCH_SIZE,\n",
        "  eval_batch_size=EVAL_BATCH_SIZE,\n",
        "  predict_batch_size=PREDICT_BATCH_SIZE)\n",
        "  \n",
        "  md = model_train(estimator_from_tfhub)\n",
        "  ev = model_eval(estimator_from_tfhub)\n",
        "  pd = model_predict(estimator_from_tfhub,dev_InputExamples)\n",
        "  mds.append(md)\n",
        "  evs.append(ev)\n",
        "  pds.append(pd)\n",
        "\n",
        "\n",
        "true_label = list(dev['sentiment'])\n",
        "\n",
        "for pd,ev in zip(pds,evs):\n",
        "  print(ev)\n",
        "  labels_val = []\n",
        "  for item in pd:\n",
        "    labels_val.append(labels[np.argmax(item[1])])\n",
        "  print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "  print(metrics.classification_report(y_pred=labels_val,y_true = true_label))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Started training at 2019-04-28 22:39:00.089148 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "***** Finished training at 2019-04-28 22:41:50.590199 *****\n",
            "***** Started evaluation at 2019-04-28 22:41:53.238824 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-28 22:42:26.407891 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.58214283\n",
            "  eval_loss = 1.0989323\n",
            "  global_step = 966\n",
            "  loss = 1.3001544\n",
            "***** Started training at 2019-04-28 22:43:22.400852 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "***** Finished training at 2019-04-28 22:46:06.143112 *****\n",
            "***** Started evaluation at 2019-04-28 22:46:08.792010 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-28 22:46:47.307760 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.5857143\n",
            "  eval_loss = 1.0933256\n",
            "  global_step = 1012\n",
            "  loss = 1.3238193\n",
            "***** Started training at 2019-04-28 22:47:36.138628 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "***** Finished training at 2019-04-28 22:50:28.568653 *****\n",
            "***** Started evaluation at 2019-04-28 22:50:31.248144 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-28 22:51:05.186723 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.57857144\n",
            "  eval_loss = 1.1125265\n",
            "  global_step = 1058\n",
            "  loss = 1.3201562\n",
            "***** Started training at 2019-04-28 22:51:56.106408 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "***** Finished training at 2019-04-28 22:54:51.022880 *****\n",
            "***** Started evaluation at 2019-04-28 22:54:53.720700 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-28 22:55:27.576205 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.58928573\n",
            "  eval_loss = 1.1310146\n",
            "  global_step = 1104\n",
            "  loss = 1.3485895\n",
            "***** Started training at 2019-04-28 22:56:18.223302 *****\n",
            "  Num examples = 1501\n",
            "  Batch size = 32\n",
            "***** Finished training at 2019-04-28 22:59:06.312185 *****\n",
            "***** Started evaluation at 2019-04-28 22:59:08.971758 *****\n",
            "  Num examples = 284\n",
            "  Batch size = 8\n",
            "***** Finished evaluation at 2019-04-28 22:59:41.669196 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.5928571\n",
            "  eval_loss = 1.1348958\n",
            "  global_step = 1150\n",
            "  loss = 1.3511995\n",
            "{'loss': 1.3001544, 'eval_accuracy': 0.58214283, 'eval_loss': 1.0989323, 'global_step': 966}\n",
            "[[  7  13   3]\n",
            " [  7  37  53]\n",
            " [  7  36 121]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.33      0.30      0.32        23\n",
            "     Neutral       0.43      0.38      0.40        97\n",
            "    Positive       0.68      0.74      0.71       164\n",
            "\n",
            "   micro avg       0.58      0.58      0.58       284\n",
            "   macro avg       0.48      0.47      0.48       284\n",
            "weighted avg       0.57      0.58      0.57       284\n",
            "\n",
            "{'loss': 1.3238193, 'eval_accuracy': 0.5857143, 'eval_loss': 1.0933256, 'global_step': 1012}\n",
            "[[  4  15   4]\n",
            " [  4  38  55]\n",
            " [  6  34 124]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.29      0.17      0.22        23\n",
            "     Neutral       0.44      0.39      0.41        97\n",
            "    Positive       0.68      0.76      0.71       164\n",
            "\n",
            "   micro avg       0.58      0.58      0.58       284\n",
            "   macro avg       0.47      0.44      0.45       284\n",
            "weighted avg       0.56      0.58      0.57       284\n",
            "\n",
            "{'loss': 1.3201562, 'eval_accuracy': 0.57857144, 'eval_loss': 1.1125265, 'global_step': 1058}\n",
            "[[  7  13   3]\n",
            " [  7  37  53]\n",
            " [  7  37 120]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.33      0.30      0.32        23\n",
            "     Neutral       0.43      0.38      0.40        97\n",
            "    Positive       0.68      0.73      0.71       164\n",
            "\n",
            "   micro avg       0.58      0.58      0.58       284\n",
            "   macro avg       0.48      0.47      0.48       284\n",
            "weighted avg       0.57      0.58      0.57       284\n",
            "\n",
            "{'loss': 1.3485895, 'eval_accuracy': 0.58928573, 'eval_loss': 1.1310146, 'global_step': 1104}\n",
            "[[  6  12   5]\n",
            " [  6  36  55]\n",
            " [  7  32 125]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.32      0.26      0.29        23\n",
            "     Neutral       0.45      0.37      0.41        97\n",
            "    Positive       0.68      0.76      0.72       164\n",
            "\n",
            "   micro avg       0.59      0.59      0.59       284\n",
            "   macro avg       0.48      0.46      0.47       284\n",
            "weighted avg       0.57      0.59      0.58       284\n",
            "\n",
            "{'loss': 1.3511995, 'eval_accuracy': 0.5928571, 'eval_loss': 1.1348958, 'global_step': 1150}\n",
            "[[  6  14   3]\n",
            " [  5  37  55]\n",
            " [  7  32 125]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.33      0.26      0.29        23\n",
            "     Neutral       0.45      0.38      0.41        97\n",
            "    Positive       0.68      0.76      0.72       164\n",
            "\n",
            "   micro avg       0.59      0.59      0.59       284\n",
            "   macro avg       0.49      0.47      0.47       284\n",
            "weighted avg       0.57      0.59      0.58       284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "khuNEnMw2wiv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# from sklearn import metrics\n",
        "\n",
        "# labels = [\"Negative\",\"Neutral\", \"Positive\"]\n",
        "# labels_val = []\n",
        "# for item in predictions:\n",
        "#   labels_val.append(labels[np.argmax(item[1])])\n",
        "# true_label = list(dev['sentiment'])\n",
        "# print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "# print(metrics.classification_report(y_pred=labels_val,y_true = true_label))\n",
        "# predictions = model_predict(estimator_from_tfhub,dev_InputExamples)\n",
        "# labels_val = []\n",
        "# for item in predictions:\n",
        "#   labels_val.append(labels[np.argmax(item[1])])\n",
        "# true_label = list(dev['sentiment'])\n",
        "# print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "# print(metrics.classification_report(y_pred=labels_val,y_true = true_label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Txu5R3dU7VsK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "274173b1-0906-4dde-e97a-7f92a0aeadd8"
      },
      "cell_type": "code",
      "source": [
        "for ckpt in range(966,967,46):\n",
        "  predictions = model_predict(estimator_from_tfhub,test_InputExamples_fixed,checkpoint_path=OUTPUT_DIR+'/model.ckpt-%d'%ckpt)\n",
        "  labels_val = []\n",
        "  for item in predictions:\n",
        "    labels_val.append(labels[np.argmax(item[1])])\n",
        "  true_label = list(test_fixed['sentiment'])\n",
        "  print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "  print(metrics.classification_report(y_pred=labels_val,y_true = true_label))\n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  8  26  16]\n",
            " [  5  48  63]\n",
            " [  8  52 114]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.38      0.16      0.23        50\n",
            "     Neutral       0.38      0.41      0.40       116\n",
            "    Positive       0.59      0.66      0.62       174\n",
            "\n",
            "   micro avg       0.50      0.50      0.50       340\n",
            "   macro avg       0.45      0.41      0.41       340\n",
            "weighted avg       0.49      0.50      0.49       340\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1o3ecaNzePB3",
        "colab_type": "code",
        "outputId": "11000f10-1a52-45bc-cdbc-7d8e2b3477e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "for ckpt in range(966,967,46):\n",
        "  predictions = model_predict(estimator_from_tfhub,test_InputExamples,checkpoint_path=OUTPUT_DIR+'/model.ckpt-%d'%ckpt)\n",
        "  labels_val = []\n",
        "  for item in predictions:\n",
        "    labels_val.append(labels[np.argmax(item[1])])\n",
        "  true_label = list(test['sentiment'])\n",
        "  print(metrics.confusion_matrix(y_pred=labels_val,y_true=true_label))\n",
        "  print(metrics.classification_report(y_pred=labels_val,y_true = true_label))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  5  12  11]\n",
            " [  6  37  44]\n",
            " [  5  48 117]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.31      0.18      0.23        28\n",
            "     Neutral       0.38      0.43      0.40        87\n",
            "    Positive       0.68      0.69      0.68       170\n",
            "\n",
            "   micro avg       0.56      0.56      0.56       285\n",
            "   macro avg       0.46      0.43      0.44       285\n",
            "weighted avg       0.55      0.56      0.55       285\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TV5SpMUg7b9V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tf.logging.set_verbosity(tf.logging.DEBUG) #DEBUG,ERROR,FATAL,INFO,WARN\n",
        "# predictions = model_predict(estimator_from_tfhub,test_InputExamples)\n",
        "labels_val = []\n",
        "for item in predictions:\n",
        "  labels_val.append(labels[np.argmax(item[1])])\n",
        "true_label = list(test['sentiment'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cqh11HPVAsvx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "####seq 128, Small BERT, Batchsize 32 for train, 8 for dev and test\n",
        "# 1)I0423 16:57:01.507206 140076901431168 basic_session_run_hooks.py:249] loss = 0.40919852, step = 46\n",
        "# 2)I0423 18:08:31.116359 140500355729280 basic_session_run_hooks.py:249] loss = 0.7756149, step = 92\n",
        "# 4)Loss for final step: 0.6891643.\n",
        "# 5)Loss for final step: 0.9730371\n",
        "# 6)Loss for final step: 0.4775733\n",
        "# 7)Loss for final step: 1.2802429.\n",
        "# 8)Loss for final step: 0.509207\n",
        "# 9)loss = 0.29262337, step = 414\n",
        "# 10)Loss for final step: 0.47267017\n",
        "\n",
        "\n",
        "# 2)***** Eval results *****\n",
        "#   eval_accuracy = 0.5857143\n",
        "#   eval_loss = 0.8630275\n",
        "#   global_step = 92\n",
        "#   loss = 0.79767215\n",
        "# 3)***** Eval results *****\n",
        "#   eval_accuracy = 0.5857143\n",
        "#   eval_loss = 0.8630275\n",
        "#   global_step = 138\n",
        "#   loss = 0.79767215\n",
        "# 4)***** Eval results *****\n",
        "#   eval_accuracy = 0.5857143\n",
        "#   eval_loss = 0.86550355\n",
        "#   global_step = 184\n",
        "#   loss = 0.83540887\n",
        "# 5)***** Eval results *****\n",
        "#   eval_accuracy = 0.5964286\n",
        "#   eval_loss = 0.88053304\n",
        "#   global_step = 230\n",
        "#   loss = 0.91362196\n",
        "# 6)***** Eval results *****\n",
        "#   eval_accuracy = 0.5857143\n",
        "#   eval_loss = 0.90498805\n",
        "#   global_step = 276\n",
        "#   loss = 1.0806552\n",
        "# 7)***** Eval results *****\n",
        "#   eval_accuracy = 0.56785715\n",
        "#   eval_loss = 0.92742974\n",
        "#   global_step = 322\n",
        "#   loss = 1.0180835\n",
        "# 8)***** Eval results *****\n",
        "#   eval_accuracy = 0.5607143\n",
        "#   eval_loss = 0.9436406\n",
        "#   global_step = 368\n",
        "#   loss = 0.9721719\n",
        "# 9)***** Eval results *****\n",
        "#   eval_accuracy = 0.5607143\n",
        "#   eval_loss = 0.9714315\n",
        "#   global_step = 414\n",
        "#   loss = 0.5798999\n",
        "# 10)***** Eval results *****\n",
        "#   eval_accuracy = 0.54285717\n",
        "#   eval_loss = 1.0072392\n",
        "#   global_step = 460\n",
        "#   loss = 1.053762\n",
        "  \n",
        "#   DEV Info:\n",
        "# 1)[[  0   0  23]\n",
        "#  [  0   0  97]\n",
        "#  [  0   0 164]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.00      0.00      0.00        97\n",
        "#     Positive       0.58      1.00      0.73       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.19      0.33      0.24       284\n",
        "# weighted avg       0.33      0.58      0.42       284\n",
        "# 2)[[  0   9  14]\n",
        "#  [  0  25  72]\n",
        "#  [  0  21 143]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.45      0.26      0.33        97\n",
        "#     Positive       0.62      0.87      0.73       164\n",
        "\n",
        "#    micro avg       0.59      0.59      0.59       284\n",
        "#    macro avg       0.36      0.38      0.35       284\n",
        "# weighted avg       0.52      0.59      0.53       284\n",
        "# 3)[[  0   9  14]\n",
        "#  [  0  25  72]\n",
        "#  [  0  21 143]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.45      0.26      0.33        97\n",
        "#     Positive       0.62      0.87      0.73       164\n",
        "\n",
        "#    micro avg       0.59      0.59      0.59       284\n",
        "#    macro avg       0.36      0.38      0.35       284\n",
        "# weighted avg       0.52      0.59      0.53       284\n",
        "# 4)[[  0   8  42]\n",
        "#  [  0  16 100]\n",
        "#  [  0  17 157]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        50\n",
        "#      Neutral       0.39      0.14      0.20       116\n",
        "#     Positive       0.53      0.90      0.66       174\n",
        "\n",
        "#    micro avg       0.51      0.51      0.51       340\n",
        "#    macro avg       0.31      0.35      0.29       340\n",
        "# weighted avg       0.40      0.51      0.41       340\n",
        "# 5)[[  0  17   6]\n",
        "#  [  0  40  57]\n",
        "#  [  0  35 129]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.43      0.41      0.42        97\n",
        "#     Positive       0.67      0.79      0.72       164\n",
        "\n",
        "#    micro avg       0.60      0.60      0.60       284\n",
        "#    macro avg       0.37      0.40      0.38       284\n",
        "# weighted avg       0.54      0.60      0.56       284\n",
        "# 6)[[  0  19   4]\n",
        "#  [  0  44  53]\n",
        "#  [  0  42 122]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.42      0.45      0.44        97\n",
        "#     Positive       0.68      0.74      0.71       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.37      0.40      0.38       284\n",
        "# weighted avg       0.54      0.58      0.56       284\n",
        "# 7)[[  0  18   5]\n",
        "#  [  0  46  51]\n",
        "#  [  0  47 117]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.41      0.47      0.44        97\n",
        "#     Positive       0.68      0.71      0.69       164\n",
        "\n",
        "#    micro avg       0.57      0.57      0.57       284\n",
        "#    macro avg       0.36      0.40      0.38       284\n",
        "# weighted avg       0.53      0.57      0.55       284\n",
        "# 8)[[  0  18   5]\n",
        "#  [  0  48  49]\n",
        "#  [  0  53 111]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.40      0.49      0.44        97\n",
        "#     Positive       0.67      0.68      0.67       164\n",
        "\n",
        "#    micro avg       0.56      0.56      0.56       284\n",
        "#    macro avg       0.36      0.39      0.37       284\n",
        "# weighted avg       0.53      0.56      0.54       284\n",
        "# 9)[[  0  18   5]\n",
        "#  [  0  48  49]\n",
        "#  [  0  54 110]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.40      0.49      0.44        97\n",
        "#     Positive       0.67      0.67      0.67       164\n",
        "\n",
        "#    micro avg       0.56      0.56      0.56       284\n",
        "#    macro avg       0.36      0.39      0.37       284\n",
        "# weighted avg       0.52      0.56      0.54       284\n",
        "# 10)[[  0  18   5]\n",
        "#  [  0  51  46]\n",
        "#  [  0  62 102]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.39      0.53      0.45        97\n",
        "#     Positive       0.67      0.62      0.64       164\n",
        "\n",
        "#    micro avg       0.54      0.54      0.54       284\n",
        "#    macro avg       0.35      0.38      0.36       284\n",
        "# weighted avg       0.52      0.54      0.52       284\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N0h7wMprmvyX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###### Seq:256, small BERT, batch size 32 for train, 8 for test and dev\n",
        "# 3) {'loss': 0.79650426, 'eval_accuracy': 0.58214283, 'eval_loss': 0.86125755, 'global_step': 138}\n",
        "# [[  0   0  23]\n",
        "#  [  0   0  97]\n",
        "#  [  0   0 164]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.00      0.00      0.00        97\n",
        "#     Positive       0.58      1.00      0.73       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.19      0.33      0.24       284\n",
        "# weighted avg       0.33      0.58      0.42       284\n",
        "\n",
        "# 4) {'loss': 0.73700047, 'eval_accuracy': 0.5928571, 'eval_loss': 0.8223035, 'global_step': 184}\n",
        "# [[  0  11  12]\n",
        "#  [  0  20  77]\n",
        "#  [  0  17 147]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.42      0.21      0.28        97\n",
        "#     Positive       0.62      0.90      0.73       164\n",
        "\n",
        "#    micro avg       0.59      0.59      0.59       284\n",
        "#    macro avg       0.35      0.37      0.34       284\n",
        "# weighted avg       0.50      0.59      0.52       284\n",
        "\n",
        "# 5) {'loss': 0.71594626, 'eval_accuracy': 0.5928571, 'eval_loss': 0.82239425, 'global_step': 230}\n",
        "# [[  0  19   4]\n",
        "#  [  0  51  46]\n",
        "#  [  0  48 116]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.43      0.53      0.47        97\n",
        "#     Positive       0.70      0.71      0.70       164\n",
        "\n",
        "#    micro avg       0.59      0.59      0.59       284\n",
        "#    macro avg       0.38      0.41      0.39       284\n",
        "# weighted avg       0.55      0.59      0.57       284\n",
        "\n",
        "# 6) {'loss': 0.7227276, 'eval_accuracy': 0.5857143, 'eval_loss': 0.8479867, 'global_step': 276}\n",
        "# [[  0  21   2]\n",
        "#  [  2  51  44]\n",
        "#  [  1  49 114]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.42      0.53      0.47        97\n",
        "#     Positive       0.71      0.70      0.70       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.38      0.41      0.39       284\n",
        "# weighted avg       0.56      0.58      0.57       284\n",
        "\n",
        "# 7){'loss': 0.83304703, 'eval_accuracy': 0.5642857, 'eval_loss': 0.90589315, 'global_step': 322}\n",
        "# [[  0  19   4]\n",
        "#  [  4  40  53]\n",
        "#  [  3  42 119]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.40      0.41      0.40        97\n",
        "#     Positive       0.68      0.73      0.70       164\n",
        "\n",
        "#    micro avg       0.56      0.56      0.56       284\n",
        "#    macro avg       0.36      0.38      0.37       284\n",
        "# weighted avg       0.53      0.56      0.54       284\n",
        "\n",
        "# 8){'loss': 0.84049994, 'eval_accuracy': 0.575, 'eval_loss': 0.93640614, 'global_step': 368}\n",
        "# [[  2  18   3]\n",
        "#  [  5  42  50]\n",
        "#  [  2  44 118]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.22      0.09      0.12        23\n",
        "#      Neutral       0.40      0.43      0.42        97\n",
        "#     Positive       0.69      0.72      0.70       164\n",
        "\n",
        "#    micro avg       0.57      0.57      0.57       284\n",
        "#    macro avg       0.44      0.41      0.42       284\n",
        "# weighted avg       0.55      0.57      0.56       284\n",
        "\n",
        "# 9){'loss': 0.8601472, 'eval_accuracy': 0.5642857, 'eval_loss': 0.95250976, 'global_step': 414}\n",
        "# [[  0  18   5]\n",
        "#  [  4  37  56]\n",
        "#  [  1  41 122]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.39      0.38      0.38        97\n",
        "#     Positive       0.67      0.74      0.70       164\n",
        "\n",
        "#    micro avg       0.56      0.56      0.56       284\n",
        "#    macro avg       0.35      0.38      0.36       284\n",
        "# weighted avg       0.52      0.56      0.54       284\n",
        "\n",
        "\n",
        "# 10){'loss': 0.9091368, 'eval_accuracy': 0.5535714, 'eval_loss': 0.9715489, 'global_step': 460}\n",
        "# [[  0  19   4]\n",
        "#  [  4  37  56]\n",
        "#  [  1  44 119]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.37      0.38      0.38        97\n",
        "#     Positive       0.66      0.73      0.69       164\n",
        "\n",
        "#    micro avg       0.55      0.55      0.55       284\n",
        "#    macro avg       0.34      0.37      0.36       284\n",
        "# weighted avg       0.51      0.55      0.53       284\n",
        "\n",
        "# 11){'loss': 0.9756337, 'eval_accuracy': 0.5714286, 'eval_loss': 1.0129306, 'global_step': 506}\n",
        "# [[  3  16   4]\n",
        "#  [  5  36  56]\n",
        "#  [  1  41 122]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.33      0.13      0.19        23\n",
        "#      Neutral       0.39      0.37      0.38        97\n",
        "#     Positive       0.67      0.74      0.71       164\n",
        "\n",
        "#    micro avg       0.57      0.57      0.57       284\n",
        "#    macro avg       0.46      0.42      0.42       284\n",
        "# weighted avg       0.55      0.57      0.55       284\n",
        "\n",
        "# 12){'loss': 0.9551747, 'eval_accuracy': 0.56785715, 'eval_loss': 1.0222387, 'global_step': 552}\n",
        "# [[  3  17   3]\n",
        "#  [  5  38  54]\n",
        "#  [  2  43 119]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.30      0.13      0.18        23\n",
        "#      Neutral       0.39      0.39      0.39        97\n",
        "#     Positive       0.68      0.73      0.70       164\n",
        "\n",
        "#    micro avg       0.56      0.56      0.56       284\n",
        "#    macro avg       0.45      0.42      0.42       284\n",
        "# weighted avg       0.55      0.56      0.55       284\n",
        "\n",
        "# 13){'loss': 1.0276382, 'eval_accuracy': 0.5714286, 'eval_loss': 1.0547612, 'global_step': 598}\n",
        "# [[  3  17   3]\n",
        "#  [  5  36  56]\n",
        "#  [  1  41 122]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.33      0.13      0.19        23\n",
        "#      Neutral       0.38      0.37      0.38        97\n",
        "#     Positive       0.67      0.74      0.71       164\n",
        "\n",
        "#    micro avg       0.57      0.57      0.57       284\n",
        "#    macro avg       0.46      0.42      0.42       284\n",
        "# weighted avg       0.55      0.57      0.55       284\n",
        "\n",
        "# 14){'loss': 1.0036505, 'eval_accuracy': 0.55714285, 'eval_loss': 1.0697843, 'global_step': 644}\n",
        "# [[  3  17   3]\n",
        "#  [  7  36  54]\n",
        "#  [  2  44 118]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.25      0.13      0.17        23\n",
        "#      Neutral       0.37      0.37      0.37        97\n",
        "#     Positive       0.67      0.72      0.70       164\n",
        "\n",
        "#    micro avg       0.55      0.55      0.55       284\n",
        "#    macro avg       0.43      0.41      0.41       284\n",
        "# weighted avg       0.54      0.55      0.54       284\n",
        "\n",
        "# 15){'loss': 1.0295725, 'eval_accuracy': 0.5642857, 'eval_loss': 1.0809377, 'global_step': 690}\n",
        "# [[  3  17   3]\n",
        "#  [  5  39  53]\n",
        "#  [  1  46 117]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.33      0.13      0.19        23\n",
        "#      Neutral       0.38      0.40      0.39        97\n",
        "#     Positive       0.68      0.71      0.69       164\n",
        "\n",
        "#    micro avg       0.56      0.56      0.56       284\n",
        "#    macro avg       0.46      0.42      0.42       284\n",
        "# weighted avg       0.55      0.56      0.55       284\n",
        "\n",
        "# 16){'loss': 1.0889318, 'eval_accuracy': 0.54642856, 'eval_loss': 1.1056138, 'global_step': 736}\n",
        "# [[  3  17   3]\n",
        "#  [  8  33  56]\n",
        "#  [  2  44 118]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.23      0.13      0.17        23\n",
        "#      Neutral       0.35      0.34      0.35        97\n",
        "#     Positive       0.67      0.72      0.69       164\n",
        "\n",
        "#    micro avg       0.54      0.54      0.54       284\n",
        "#    macro avg       0.42      0.40      0.40       284\n",
        "# weighted avg       0.52      0.54      0.53       284\n",
        "\n",
        "# 17){'loss': 1.1312778, 'eval_accuracy': 0.54642856, 'eval_loss': 1.1440269, 'global_step': 782}\n",
        "# [[  3  17   3]\n",
        "#  [  9  33  55]\n",
        "#  [  2  44 118]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.21      0.13      0.16        23\n",
        "#      Neutral       0.35      0.34      0.35        97\n",
        "#     Positive       0.67      0.72      0.69       164\n",
        "\n",
        "#    micro avg       0.54      0.54      0.54       284\n",
        "#    macro avg       0.41      0.40      0.40       284\n",
        "# weighted avg       0.52      0.54      0.53       284\n",
        "\n",
        "# 18){'loss': 1.1436831, 'eval_accuracy': 0.55, 'eval_loss': 1.1613237, 'global_step': 828}\n",
        "# [[  3  16   4]\n",
        "#  [  8  35  54]\n",
        "#  [  2  45 117]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.23      0.13      0.17        23\n",
        "#      Neutral       0.36      0.36      0.36        97\n",
        "#     Positive       0.67      0.71      0.69       164\n",
        "\n",
        "#    micro avg       0.55      0.55      0.55       284\n",
        "#    macro avg       0.42      0.40      0.41       284\n",
        "# weighted avg       0.53      0.55      0.54       284\n",
        "\n",
        "# 19){'loss': 1.1817628, 'eval_accuracy': 0.55, 'eval_loss': 1.1834545, 'global_step': 874}\n",
        "# [[  3  16   4]\n",
        "#  [  8  34  55]\n",
        "#  [  1  45 118]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.25      0.13      0.17        23\n",
        "#      Neutral       0.36      0.35      0.35        97\n",
        "#     Positive       0.67      0.72      0.69       164\n",
        "\n",
        "#    micro avg       0.55      0.55      0.55       284\n",
        "#    macro avg       0.42      0.40      0.41       284\n",
        "# weighted avg       0.53      0.55      0.53       284\n",
        "\n",
        "# 20){'loss': 1.1921012, 'eval_accuracy': 0.54642856, 'eval_loss': 1.1976833, 'global_step': 920}\n",
        "# [[  3  16   4]\n",
        "#  [  9  35  53]\n",
        "#  [  2  47 115]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.21      0.13      0.16        23\n",
        "#      Neutral       0.36      0.36      0.36        97\n",
        "#     Positive       0.67      0.70      0.68       164\n",
        "\n",
        "#    micro avg       0.54      0.54      0.54       284\n",
        "#    macro avg       0.41      0.40      0.40       284\n",
        "# weighted avg       0.53      0.54      0.53       284\n",
        "\n",
        "# 21){'loss': 1.2514663, 'eval_accuracy': 0.53571427, 'eval_loss': 1.2244278, 'global_step': 966}\n",
        "# [[  3  16   4]\n",
        "#  [ 11  32  54]\n",
        "#  [  2  47 115]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.19      0.13      0.15        23\n",
        "#      Neutral       0.34      0.33      0.33        97\n",
        "#     Positive       0.66      0.70      0.68       164\n",
        "\n",
        "#    micro avg       0.53      0.53      0.53       284\n",
        "#    macro avg       0.40      0.39      0.39       284\n",
        "# weighted avg       0.51      0.53      0.52       284\n",
        "\n",
        "# 22){'loss': 1.2630298, 'eval_accuracy': 0.5321429, 'eval_loss': 1.2527977, 'global_step': 1012}\n",
        "# [[  5  14   4]\n",
        "#  [ 14  32  51]\n",
        "#  [  9  43 112]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.18      0.22      0.20        23\n",
        "#      Neutral       0.36      0.33      0.34        97\n",
        "#     Positive       0.67      0.68      0.68       164\n",
        "\n",
        "#    micro avg       0.52      0.52      0.52       284\n",
        "#    macro avg       0.40      0.41      0.41       284\n",
        "# weighted avg       0.52      0.52      0.52       284\n",
        "\n",
        "# 23){'loss': 1.3330169, 'eval_accuracy': 0.53571427, 'eval_loss': 1.2815608, 'global_step': 1058}\n",
        "# [[  6  13   4]\n",
        "#  [ 14  31  52]\n",
        "#  [  9  42 113]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.21      0.26      0.23        23\n",
        "#      Neutral       0.36      0.32      0.34        97\n",
        "#     Positive       0.67      0.69      0.68       164\n",
        "\n",
        "#    micro avg       0.53      0.53      0.53       284\n",
        "#    macro avg       0.41      0.42      0.42       284\n",
        "# weighted avg       0.53      0.53      0.53       284\n",
        "\n",
        "# 24){'loss': 1.3111317, 'eval_accuracy': 0.5321429, 'eval_loss': 1.2898273, 'global_step': 1104}\n",
        "# [[  5  14   4]\n",
        "#  [ 14  32  51]\n",
        "#  [  9  43 112]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.18      0.22      0.20        23\n",
        "#      Neutral       0.36      0.33      0.34        97\n",
        "#     Positive       0.67      0.68      0.68       164\n",
        "\n",
        "#    micro avg       0.52      0.52      0.52       284\n",
        "#    macro avg       0.40      0.41      0.41       284\n",
        "# weighted avg       0.52      0.52      0.52       284"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aUqSe326lwHt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Larg BERT seq:256, batchsize 8 for train, dev , test\n",
        "# {'loss': 1.0679293, 'eval_accuracy': 0.5955882, 'eval_loss': 0.8965841, 'global_step': 93}\n",
        "# [[  0   0  23]\n",
        "#  [  0   0  97]\n",
        "#  [  0   0 164]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.00      0.00      0.00        97\n",
        "#     Positive       0.58      1.00      0.73       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.19      0.33      0.24       284\n",
        "# weighted avg       0.33      0.58      0.42       284\n",
        "\n",
        "# {'loss': 1.0362501, 'eval_accuracy': 0.5955882, 'eval_loss': 0.88540924, 'global_step': 186}\n",
        "# [[  0   0  23]\n",
        "#  [  0   0  97]\n",
        "#  [  0   0 164]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.00      0.00      0.00        97\n",
        "#     Positive       0.58      1.00      0.73       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.19      0.33      0.24       284\n",
        "# weighted avg       0.33      0.58      0.42       284\n",
        "\n",
        "# {'loss': 1.0290864, 'eval_accuracy': 0.5955882, 'eval_loss': 0.8812368, 'global_step': 279}\n",
        "# [[  0   0  23]\n",
        "#  [  0   0  97]\n",
        "#  [  0   0 164]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.00      0.00      0.00        97\n",
        "#     Positive       0.58      1.00      0.73       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.19      0.33      0.24       284\n",
        "# weighted avg       0.33      0.58      0.42       284\n",
        "\n",
        "# {'loss': 1.0271251, 'eval_accuracy': 0.5955882, 'eval_loss': 0.88323754, 'global_step': 372}\n",
        "# [[  0   0  23]\n",
        "#  [  0   0  97]\n",
        "#  [  0   0 164]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.00      0.00      0.00        97\n",
        "#     Positive       0.58      1.00      0.73       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.19      0.33      0.24       284\n",
        "# weighted avg       0.33      0.58      0.42       284\n",
        "\n",
        "# {'loss': 1.02654, 'eval_accuracy': 0.5955882, 'eval_loss': 0.8804489, 'global_step': 465}\n",
        "# [[  0   0  23]\n",
        "#  [  0   0  97]\n",
        "#  [  0   0 164]]\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     Negative       0.00      0.00      0.00        23\n",
        "#      Neutral       0.00      0.00      0.00        97\n",
        "#     Positive       0.58      1.00      0.73       164\n",
        "\n",
        "#    micro avg       0.58      0.58      0.58       284\n",
        "#    macro avg       0.19      0.33      0.24       284\n",
        "# weighted avg       0.33      0.58      0.42       284\n",
        "\n",
        "# SAME FOR 10 EPOCHS!!!!!"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}